{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting Data Into The Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO's\n",
    "\n",
    "## Step 0\n",
    "* COPY TSV data from S3 to our default bucket /prefix (!aws s3 cp...) (check if YEAR data was in TSV)\n",
    "* CONVERT TSV to Parquet (with Athena)\n",
    "\n",
    "## Step 2\n",
    "\n",
    "BI\n",
    "* LOAD TSV data from S3 to redshift \n",
    "* QUERY redshift (include YEAR to check if TSV has year)\n",
    "* UNLOAD Parquet data from redshift to S3\n",
    "\n",
    "Data Analytics\n",
    "* CTAS (Athena -- creating pointer to S3 location)\n",
    "* Query Athena\n",
    "* Check 01_create_database.sql && 02_create_table.sql from Athena Repo\n",
    "\n",
    "\n",
    "## Step 2/3 -- BATCH Automation\n",
    "Ingestion of TSV through Glue and/or StepFunction & DataWrangler (ie. S3 Trigger + Lambda or perhap S3 has native integration to invoke StepFunction?  or native integration to invoke Glue?  or Glue cron job)\n",
    "* Try to trigger upon simulating new data arrival into s3.  ie. we simulate adding a new partition for each year.\n",
    "* Convert TSV to Parquet as it arrives\n",
    "* LOAD TSV data from S3 to redshift as it arrives\n",
    "\n",
    "\n",
    "## Step 1 -- STREAMING Automation\n",
    "* Try to trigger upon simulating new data arrival into Kinesis.  ie. we simulate adding a new partition for each year (or smaller time frame)\n",
    "* Convert TSV to Parquet as it arrives\n",
    "* LOAD TSV data from S3 to redshift as it arrives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Settings\n",
    "import boto3\n",
    "# import botocore\n",
    "import sagemaker\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# Get region \n",
    "session = boto3.session.Session()\n",
    "region_name = session.region_name\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Set S3 prefixes\n",
    "tsv_prefix = 'amazon-reviews-pds/tsv'\n",
    "parquet_prefix = 'amazon-reviews-pds/parquet'\n",
    "\n",
    "# Set Redshift params \n",
    "database_name = 'dsoaws'\n",
    "table_name = 'amazon_reviews_parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 -- Copy Dataset To S3 Bucket & Convert To Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 source paths\n",
    "s3_source_path_tsv = 's3://amazon-reviews-pds/tsv'\n",
    "s3_source_path_parquet = 's3://amazon-reviews-pds/parquet'\n",
    "\n",
    "# Set S3 destination paths\n",
    "s3_destination_path_tsv = 's3://{}/{}'.format(bucket, tsv_prefix)\n",
    "s3_destination_path_parquet = 's3://{}/{}'.format(bucket, parquet_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!aws s3 cp --recursive $s3_source_path_tsv/ $s3_destination_path_tsv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files\n",
    "!aws s3 ls $s3_destination_path_tsv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove index.txt, sample and multilingual dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rm $s3_destination_path_tsv/index.txt\n",
    "!aws s3 rm $s3_destination_path_tsv/sample_fr.tsv\n",
    "!aws s3 rm $s3_destination_path_tsv/sample_us.tsv\n",
    "\n",
    "!aws s3 rm $s3_destination_path_tsv/amazon_reviews_multilingual_DE_v1_00.tsv.gz\n",
    "!aws s3 rm $s3_destination_path_tsv/amazon_reviews_multilingual_FR_v1_00.tsv.gz\n",
    "!aws s3 rm $s3_destination_path_tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz\n",
    "!aws s3 rm $s3_destination_path_tsv/amazon_reviews_multilingual_UK_v1_00.tsv.gz\n",
    "!aws s3 rm $s3_destination_path_tsv/amazon_reviews_multilingual_US_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT TSV to Parquet (with Athena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyAthena\n",
    "!pip install -q PyAthena==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyathena import connect\n",
    "from pyathena.pandas_cursor import PandasCursor\n",
    "from pyathena.util import as_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Athena database first\n",
    "database_name = 'dsoaws'\n",
    "table_name_tsv = 'amazon_reviews_tsv2'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 staging directory \n",
    "s3_staging_dir = 's3://{0}/staging/athena'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Athena Table from downloaded TSV Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"CREATE EXTERNAL TABLE {}.{}(\n",
    "         marketplace string,\n",
    "         customer_id string,\n",
    "         review_id string,\n",
    "         product_id string,\n",
    "         product_parent string,\n",
    "         product_title string,\n",
    "         product_category string,\n",
    "         star_rating int,\n",
    "         helpful_votes int,\n",
    "         total_votes int,\n",
    "         vine string,\n",
    "         verified_purchase string,\n",
    "         review_headline string,\n",
    "         review_body string,\n",
    "         review_date string\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\\\t' LINES TERMINATED BY '\\\\n' LOCATION '{}'\n",
    "TBLPROPERTIES ( 'compressionType'='gzip', 'skip.header.line.count'='1')\"\"\".format(database_name, table_name_tsv, s3_destination_path_tsv)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query using connection cursor\n",
    "cursor = connect(region_name=region_name, s3_staging_dir=s3_staging_dir).cursor()\n",
    "\n",
    "cursor.execute(statement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load query results into Pandas DataFrame and show results\n",
    "df  = as_pandas(cursor)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Parquet Files from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'CREATE TABLE amazon_reviews_parquet_from_tsv \\\n",
    "WITH ( format = 'PARQUET', external_location = 's3://{}' ) AS \\\n",
    "SELECT marketplace, \\\n",
    "         customer_id, \\\n",
    "         review_id, \\\n",
    "         product_id, \\\n",
    "         product_parent, \\\n",
    "         product_title, \\\n",
    "         product_category, \\\n",
    "         star_rating, \\\n",
    "         helpful_votes, \\\n",
    "         total_votes, \\\n",
    "         vine, \\\n",
    "         verified_purchase, \\\n",
    "         review_headline, \\\n",
    "         review_body, \\\n",
    "         review_date \\\n",
    "FROM amazon_reviews_tsv'.format(s3_destination_path_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
