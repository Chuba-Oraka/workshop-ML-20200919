{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Redshift - Unload Parquet Data To S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe scenario\n",
    "<img src=\"img/c3-11.png\" width=\"90%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# Connect to Redshift\n",
    "redshift = boto3.client('redshift')\n",
    "\n",
    "# Get SageMaker session & default S3 bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Set S3 prefixes\n",
    "parquet_prefix_unload = 'amazon-reviews-pds/parquet-from-redshift'\n",
    "\n",
    "# Set S3 destination paths\n",
    "s3_destination_path_parquet_unload = 's3://{}/{}'.format(bucket, parquet_prefix_unload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Redshift Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redshift configuration parameters\n",
    "redshift_cluster_identifier = 'dsoaws'\n",
    "database_name = 'dsoaws'\n",
    "\n",
    "master_user_name = 'dsoaws'\n",
    "master_user_pw = '<password>'\n",
    "\n",
    "redshift_port = '5439'\n",
    "\n",
    "schema = 'redshift'\n",
    "table_name_tsv = 'amazon_reviews_tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Redshift endpoint address & IAM Role\n",
    "response = redshift.describe_clusters(ClusterIdentifier=redshift_cluster_identifier)\n",
    "\n",
    "redshift_endpoint_address = response['Clusters'][0]['Endpoint']['Address']\n",
    "iam_role = response['Clusters'][0]['IamRoles'][0]['IamRoleArn']\n",
    "\n",
    "print(redshift_endpoint_address)\n",
    "print(iam_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Redshift Connection Via SQLAlchemy\n",
    "https://pypi.org/project/SQLAlchemy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q SQLAlchemy==1.3.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Redshift database engine\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(master_user_name, master_user_pw, redshift_endpoint_address, redshift_port, database_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Session\n",
    "session = sessionmaker()\n",
    "session.configure(bind=engine)\n",
    "s = session()\n",
    "#set_path = \"SET search_path TO %s\" % schema\n",
    "#s.execute(set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unload Parquet Data From Redshift To S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"\"\"UNLOAD ('SELECT marketplace, customer_id, review_id, product_id, product_parent, \n",
    "                        product_title, product_category, star_rating, helpful_votes, total_votes, \n",
    "                        vine, verified_purchase, review_headline, review_body, review_date FROM {}.{}')\n",
    "                TO '{}/'\n",
    "                IAM_ROLE '{}'\n",
    "                PARQUET PARALLEL ON \n",
    "                PARTITION BY (product_category)\"\"\".format(schema, table_name_tsv, s3_destination_path_parquet_unload, iam_role)\n",
    "\n",
    "print(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This query execution takes approx. 20min and might not show up as finished in the notebook (Check Redshift in the AWS console directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = session()\n",
    "s.execute(statement)\n",
    "s.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List S3 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $s3_destination_path_parquet_unload/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
