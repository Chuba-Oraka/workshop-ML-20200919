{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q xgboost==0.90\n",
    "!pip install -q scikit-learn==0.20.3\n",
    "!pip install -q nltk==3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "#sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ./data/amazon90000.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/amazon90000.tsv', delimiter='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean commas from raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed = df\n",
    "\n",
    "# TODO:  Is this in-place? \n",
    "\n",
    "df_scrubbed['marketplace'].replace(',', ' ')\n",
    "df_scrubbed['review_id'].replace(',', ' ')\n",
    "df_scrubbed['product_id'].replace(',', ' ')\n",
    "df_scrubbed['product_title'].replace(',', ' ')\n",
    "df_scrubbed['product_category'].replace(',', ' ')\n",
    "df_scrubbed['review_headline'].replace(',', ' ')\n",
    "df_scrubbed['review_body'].replace(',', ' ')\n",
    "df_scrubbed['review_date'].replace(',', ' ')\n",
    "\n",
    "df_scrubbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed = df.dropna()\n",
    "df_scrubbed = df_scrubbed.reset_index(drop=True)\n",
    "df_scrubbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_scrubbed['is_positive_sentiment'] = (df_scrubbed['star_rating'] >= 4).astype(int)\n",
    "df_scrubbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='is_positive_sentiment', data=df_scrubbed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the Dataset between Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "is_negative_sentiment_df = df_scrubbed.query('is_positive_sentiment == 0')\n",
    "is_positive_sentiment_df = df_scrubbed.query('is_positive_sentiment == 1')\n",
    "\n",
    "# TODO:  check which sentiment has the least number of samples\n",
    "\n",
    "is_positive_downsampled_df = resample(is_positive_sentiment_df,\n",
    "                                      replace = False,\n",
    "                                      n_samples = len(is_negative_sentiment_df),\n",
    "                                      random_state = 27)\n",
    "\n",
    "df_balanced_raw = pd.concat([is_negative_sentiment_df, is_positive_downsampled_df])\n",
    "df_balanced_raw = df_balanced_raw.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='is_positive_sentiment', data=df_balanced_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_raw_only_2_columns = df_balanced_raw[['is_positive_sentiment', 'review_body']]\n",
    "#df_y_balanced_raw = df_balanced_raw['is_positive_sentiment']\n",
    "\n",
    "df_balanced_raw_only_2_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the data file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/balanced-raw-with-header/data.csv\n",
    "\n",
    "prefix = 'feature-store/amazon-reviews/balanced-raw-with-header'\n",
    "\n",
    "balanced_raw_with_header_path = './{}/data.csv'.format(prefix)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "\n",
    "df_balanced_raw_only_2_columns.to_csv(balanced_raw_with_header_path, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_raw_with_header_s3_uri = sess.upload_data(path=balanced_raw_with_header_path, key_prefix=prefix)\n",
    "\n",
    "print(df_balanced_raw_with_header_s3_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF/IDF Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the raw text into TF/IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (X)\n",
    "df_X_balanced_raw = df_balanced_raw[['review_body']]\n",
    "# Labels (y)\n",
    "df_y_balanced_raw = df_balanced_raw['is_positive_sentiment']\n",
    "\n",
    "print('X.shape:  {}'.format(df_X_balanced_raw.shape))\n",
    "print('y.shape:  {}'.format(df_y_balanced_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-Learn==0.20.3\n",
    "# nltk==3.4.5\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, field):\n",
    "        self.field = field\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.field]\n",
    "    \n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "transformer = FeatureUnion([\n",
    "    ('body', Pipeline([\n",
    "        ('body_text_selector', TextSelector('review_body')),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer(tokenizer=Tokenizer, \n",
    "                                             stop_words=\"english\",\n",
    "                                             min_df=.0025, \n",
    "                                             max_df=0.25, \n",
    "                                             ngram_range=(1,3))),\n",
    "        ('svd', TruncatedSVD(algorithm='randomized', n_components=300)),\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#df_tfidf = vectorizer.fit_transform(text)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print(feature_names)\n",
    "\n",
    "#df_tfidf = pd.DataFrame(vectorizer.idf_, \n",
    "#                        index=vectorizer.get_feature_names(),\n",
    "#                        columns=['idf'])\n",
    "\n",
    "#df_tfidf = pd.DataFrame(X.todense(),columns=vectorizer.get_feature_names())\n",
    "#df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform just the features (X)\n",
    "_This will run for a minute or two.  Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_tfidf = transformer.fit_transform(df_X_balanced_raw)\n",
    "df_tfidf = pd.DataFrame(np_tfidf)\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add back the label (y) into the first column\n",
    "The label needs to be in the 1st column for some of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.insert(0, 'is_positive_sentiment', df_y_balanced_raw)\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly split the data into `train`, `validation`, and `test` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split all data into 90% train and 10% holdout\n",
    "df_tfidf_train, df_tfidf_holdout = train_test_split(df_tfidf, test_size=0.1, random_state=0)\n",
    "\n",
    "# Split the holdout into 50% validation and 50% test\n",
    "df_tfidf_validation, df_tfidf_test = train_test_split(df_tfidf_holdout, test_size=0.5, random_state=0)\n",
    "\n",
    "print('df_tfidf.shape={}'.format(df_tfidf.shape))\n",
    "print('df_tfidf_train.shape={}'.format(df_tfidf_train.shape))\n",
    "print('df_tfidf_validation.shape={}'.format(df_tfidf_validation.shape))\n",
    "print('df_tfidf_test.shape={}'.format(df_tfidf_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the datasets locally\n",
    "_Note the `header=False`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/balanced-tfidf-without-header/data.csv\n",
    "\n",
    "prefix_train = 'feature-store/amazon-reviews/balanced-tfidf-without-header/train'\n",
    "prefix_validation = 'feature-store/amazon-reviews/balanced-tfidf-without-header/validation'\n",
    "prefix_test = 'feature-store/amazon-reviews/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_train_path = './{}/data.csv'.format(prefix_train)\n",
    "balanced_tfidf_without_header_validation_path = './{}/data.csv'.format(prefix_validation)\n",
    "balanced_tfidf_without_header_test_path = './{}/data.csv'.format(prefix_test)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix_train, exist_ok=True)\n",
    "os.makedirs(prefix_validation, exist_ok=True)\n",
    "os.makedirs(prefix_test, exist_ok=True)\n",
    "\n",
    "df_tfidf_train.to_csv(balanced_tfidf_without_header_train_path, index=False, header=False)\n",
    "df_tfidf_validation.to_csv(balanced_tfidf_without_header_validation_path, index=False, header=False)\n",
    "df_tfidf_test.to_csv(balanced_tfidf_without_header_test_path, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_tfidf_without_header_train_s3_uri = sess.upload_data(path=balanced_tfidf_without_header_train_path, key_prefix=prefix_train)\n",
    "df_balanced_tfidf_without_header_validation_s3_uri = sess.upload_data(path=balanced_tfidf_without_header_train_path, key_prefix=prefix_validation)\n",
    "df_balanced_tfidf_without_header_test_s3_uri = sess.upload_data(path=balanced_tfidf_without_header_train_path, key_prefix=prefix_test)\n",
    "\n",
    "print(df_balanced_tfidf_without_header_train_s3_uri)\n",
    "print(df_balanced_tfidf_without_header_validation_s3_uri)\n",
    "print(df_balanced_tfidf_without_header_test_s3_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $df_balanced_tfidf_without_header_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
