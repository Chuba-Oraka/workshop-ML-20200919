{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformation with Amazon SageMaker Processing and SparkML\n",
    "\n",
    "Typically a machine learning (ML) process consists of few steps. First, gathering data with various ETL jobs, then pre-processing the data, featurizing the dataset by incorporating standard techniques or prior knowledge, and finally training an ML model using an algorithm.\n",
    "\n",
    "Often, distributed data processing frameworks such as Spark are used to pre-process data sets in order to prepare them for training. In this notebook we'll use Amazon SageMaker Processing, and leverage the power of Spark in a managed SageMaker environment to run our preprocessing workload. Then, we'll take our preprocessed dataset and train a regression model using XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/processing.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective:-predict-the-age-of-an-Abalone-from-its-physical-measurement)\n",
    "1. [Setup](#Setup)\n",
    "1. [Using Amazon SageMaker Processing to execute a SparkML Job](#Using-Amazon-SageMaker-Processing-to-execute-a-SparkML-Job)\n",
    "  1. [Downloading dataset and uploading to S3](#Downloading-dataset-and-uploading-to-S3)\n",
    "  1. [Build a Spark container for running the preprocessing job](#Build-a-Spark-container-for-running-the-preprocessing-job)\n",
    "  1. [Run the preprocessing job using Amazon SageMaker Processing](#Run-the-preprocessing-job-using-Amazon-SageMaker-Processing)\n",
    "    1. [Inspect the preprocessed dataset](#Inspect-the-preprocessed-dataset)\n",
    "1. [Train a regression model using the Amazon SageMaker XGBoost algorithm](#Train-a-regression-model-using-the-SageMaker-XGBoost-algorithm)\n",
    "  1. [Retrieve the XGBoost algorithm image](#Retrieve-the-XGBoost-algorithm-image)\n",
    "  1. [Set XGBoost model parameters and dataset details](#Set-XGBoost-model-parameters-and-dataset-details)\n",
    "  1. [Train the XGBoost model](#Train-the-XGBoost-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's start by specifying:\n",
    "* The S3 bucket and prefixes that you use for training and model data. Use the default bucket specified by the Amazon SageMaker session.\n",
    "* The IAM role ARN used to give processing and training access to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon SageMaker Processing to execute a SparkML job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the preprocessing job using Amazon SageMaker Processing\n",
    "\n",
    "Next, use the Amazon SageMaker Python SDK to submit a processing job. Use the Spark container that was just built, and a SparkML script for preprocessing in the job configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the Spark preprocessing script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import argparse\r\n",
      "import json\r\n",
      "import os\r\n",
      "import pandas as pd\r\n",
      "import csv\r\n",
      "import glob\r\n",
      "from pathlib import Path\r\n",
      "\r\n",
      "\r\n",
      "def list_arg(raw_value):\r\n",
      "    \"\"\"argparse type for a list of strings\"\"\"\r\n",
      "    return str(raw_value).split(',')\r\n",
      "\r\n",
      "\r\n",
      "def parse_args():\r\n",
      "    # Unlike SageMaker training jobs (which have `SM_HOSTS` and `SM_CURRENT_HOST` env vars), processing jobs to need to parse the resource config file directly\r\n",
      "    resconfig = {}\r\n",
      "    try:\r\n",
      "        with open('/opt/ml/config/resourceconfig.json', 'r') as cfgfile:\r\n",
      "            resconfig = json.load(cfgfile)\r\n",
      "    except FileNotFoundError:\r\n",
      "        print('/opt/ml/config/resourceconfig.json not found.  current_host is unknown.')\r\n",
      "        pass # Ignore\r\n",
      "\r\n",
      "    # Local testing with CLI args\r\n",
      "    parser = argparse.ArgumentParser(description='Process')\r\n",
      "\r\n",
      "    parser.add_argument('--hosts', type=list_arg,\r\n",
      "        default=resconfig.get('hosts', ['unknown']),\r\n",
      "        help='Comma-separated list of host names running the job'\r\n",
      "    )\r\n",
      "    parser.add_argument('--current-host', type=str,\r\n",
      "        default=resconfig.get('current_host', 'unknown'),\r\n",
      "        help='Name of this host running the job'\r\n",
      "    )\r\n",
      "    parser.add_argument('--input-data', type=str,\r\n",
      "        default='/opt/ml/processing/input/data',\r\n",
      "    )\r\n",
      "    parser.add_argument('--output-data', type=str,\r\n",
      "        default='/opt/ml/processing/output',\r\n",
      "    )\r\n",
      "    return parser.parse_args()\r\n",
      "\r\n",
      "\r\n",
      "def process(args):\r\n",
      "    print('Current host: {}'.format(args.current_host))\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(args.input_data))\r\n",
      "#    dirs_input = os.listdir(args.input_data)\r\n",
      "\r\n",
      "#    data = pd.concat([pd.read_csv(f, sep='\\t', header=header) for f in glob.glob('{}/*.csv'.format(path))], ignore_index = True)\r\n",
      "\r\n",
      "    # This would print all the files and directories\r\n",
      "    for file in glob.glob('{}/*.tsv.gz'.format(args.input_data)):\r\n",
      "        print(file)\r\n",
      "\r\n",
      "        df = pd.read_csv(file, \r\n",
      "                         delimiter='\\t', \r\n",
      "                         quoting=csv.QUOTE_NONE,\r\n",
      "                         compression='gzip')\r\n",
      "        df.shape\r\n",
      "\r\n",
      "        df_unbalanced_raw = df\r\n",
      "\r\n",
      "        df_unbalanced_raw['marketplace'] = df_unbalanced_raw['marketplace'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['review_id'] = df_unbalanced_raw['review_id'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['product_id'] = df_unbalanced_raw['product_id'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['product_title'] = df_unbalanced_raw['product_title'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['product_category'] = df_unbalanced_raw['product_category'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['review_headline'] = df_unbalanced_raw['review_headline'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['review_body'] = df_unbalanced_raw['review_body'].replace(',', ' ')\r\n",
      "        df_unbalanced_raw['review_date'] = df_unbalanced_raw['review_date'].replace(',', ' ')\r\n",
      "\r\n",
      "        df_unbalanced_raw.shape\r\n",
      "\r\n",
      "        df_unbalanced_raw.head(5)\r\n",
      "\r\n",
      "        df_unbalanced_raw.isna().values.any()\r\n",
      "\r\n",
      "        df_unbalanced_raw = df_unbalanced_raw.dropna()\r\n",
      "        df_unbalanced_raw = df_unbalanced_raw.reset_index(drop=True)\r\n",
      "        df_unbalanced_raw.shape\r\n",
      "\r\n",
      "        df_unbalanced_raw.head(5)\r\n",
      "\r\n",
      "        df_is_positive_sentiment = (df_unbalanced_raw['star_rating'] >= 4).astype(int)\r\n",
      "        df_unbalanced_raw.insert(0, 'is_positive_sentiment', df_is_positive_sentiment)\r\n",
      "        df_unbalanced_raw.shape\r\n",
      "\r\n",
      "        # Split train, test, validation\r\n",
      "\r\n",
      "        from sklearn.model_selection import train_test_split\r\n",
      "\r\n",
      "        # Split all data into 90% train and 10% holdout\r\n",
      "        df_unbalanced_raw_train, df_unbalanced_raw_holdout = train_test_split(df_unbalanced_raw, test_size=0.1, stratify=df_unbalanced_raw['is_positive_sentiment'])\r\n",
      "        df_unbalanced_raw_train = df_unbalanced_raw_train.reset_index(drop=True)\r\n",
      "        df_unbalanced_raw_holdout = df_unbalanced_raw_holdout.reset_index(drop=True)\r\n",
      "\r\n",
      "        # Split the holdout into 50% validation and 50% test\r\n",
      "        df_unbalanced_raw_validation, df_unbalanced_raw_test = train_test_split(df_unbalanced_raw_holdout, test_size=0.5, stratify=df_unbalanced_raw_holdout['is_positive_sentiment'])\r\n",
      "        df_unbalanced_raw_validation = df_unbalanced_raw_validation.reset_index(drop=True)\r\n",
      "        df_unbalanced_raw_test = df_unbalanced_raw_test.reset_index(drop=True)\r\n",
      "\r\n",
      "        print('df_unbalanced_raw.shape={}'.format(df_unbalanced_raw.shape))\r\n",
      "        print('df_unbalanced_raw_train.shape={}'.format(df_unbalanced_raw_train.shape))\r\n",
      "        print('df_unbalanced_raw_validation.shape={}'.format(df_unbalanced_raw_validation.shape))\r\n",
      "        print('df_unbalanced_raw_test.shape={}'.format(df_unbalanced_raw_test.shape))\r\n",
      "\r\n",
      "        unbalanced_train_data = '{}/raw/labeled/split/unbalanced/header/train'.format(args.output_data)\r\n",
      "        unbalanced_validation_data = '{}/raw/labeled/split/unbalanced/header/validation'.format(args.output_data)\r\n",
      "        unbalanced_test_data = '{}/raw/labeled/split/unbalanced/header/test'.format(args.output_data)\r\n",
      "\r\n",
      "        print('Creating directory {}'.format(unbalanced_train_data))\r\n",
      "        os.makedirs(unbalanced_train_data, exist_ok=True)\r\n",
      "        print('Creating directory {}'.format(unbalanced_validation_data))\r\n",
      "        os.makedirs(unbalanced_validation_data, exist_ok=True)\r\n",
      "        print('Creating directory {}'.format(unbalanced_test_data))\r\n",
      "        os.makedirs(unbalanced_test_data, exist_ok=True)\r\n",
      "\r\n",
      "        filename_without_extension = Path(Path(file).stem).stem\r\n",
      "\r\n",
      "        print('Writing to {}/part-{}-{}.csv'.format(unbalanced_train_data, args.current_host, filename_without_extension))\r\n",
      "        df_unbalanced_raw_train.to_csv('{}/part-{}-{}.csv'.format(unbalanced_train_data, args.current_host, filename_without_extension), sep=',', index=False, header=True)\r\n",
      "\r\n",
      "        print('Writing to {}/part-{}-{}.csv'.format(unbalanced_validation_data, args.current_host, filename_without_extension))\r\n",
      "        df_unbalanced_raw_validation.to_csv('{}/part-{}-{}.csv'.format(unbalanced_validation_data, args.current_host, filename_without_extension), sep=',', index=False, header=True)\r\n",
      "\r\n",
      "        print('Writing to {}/part-{}-{}.csv'.format(unbalanced_test_data, args.current_host, filename_without_extension))\r\n",
      "        df_unbalanced_raw_test.to_csv('{}/part-{}-{}.csv'.format(unbalanced_test_data, args.current_host, filename_without_extension), sep=',', index=False, header=True)\r\n",
      "\r\n",
      "\r\n",
      "        # Balanced the Dataset between Classes\r\n",
      "        from sklearn.utils import resample\r\n",
      "\r\n",
      "        is_negative_sentiment_df = df_unbalanced_raw.query('is_positive_sentiment == 0')\r\n",
      "        is_positive_sentiment_df = df_unbalanced_raw.query('is_positive_sentiment == 1')\r\n",
      "\r\n",
      "        # TODO:  check which sentiment has the least number of samples\r\n",
      "        is_positive_downsampled_df = resample(is_positive_sentiment_df,\r\n",
      "                                      replace = False,\r\n",
      "                                      n_samples = len(is_negative_sentiment_df),\r\n",
      "                                      random_state = 27)\r\n",
      "\r\n",
      "        df_balanced_raw = pd.concat([is_negative_sentiment_df, is_positive_downsampled_df])\r\n",
      "        df_balanced_raw = df_balanced_raw.reset_index(drop=True)\r\n",
      "\r\n",
      "        df_balanced_raw.head(5)\r\n",
      "\r\n",
      "        from sklearn.model_selection import train_test_split\r\n",
      "\r\n",
      "        # Split all data into 90% train and 10% holdout\r\n",
      "        df_balanced_raw_train, df_balanced_raw_holdout = train_test_split(df_balanced_raw, test_size=0.1, stratify=df_balanced_raw['is_positive_sentiment'])\r\n",
      "        df_balanced_raw_train = df_balanced_raw_train.reset_index(drop=True)\r\n",
      "        df_balanced_raw_holdout = df_balanced_raw_holdout.reset_index(drop=True)\r\n",
      "\r\n",
      "        # Split the holdout into 50% validation and 50% test\r\n",
      "        df_balanced_raw_validation, df_balanced_raw_test = train_test_split(df_balanced_raw_holdout, test_size=0.5, stratify=df_balanced_raw_holdout['is_positive_sentiment'])\r\n",
      "        df_balanced_raw_validation = df_balanced_raw_validation.reset_index(drop=True)\r\n",
      "        df_balanced_raw_test = df_balanced_raw_test.reset_index(drop=True)\r\n",
      "\r\n",
      "        print('df_balanced_raw.shape={}'.format(df_balanced_raw.shape))\r\n",
      "        print('df_balanced_raw_train.shape={}'.format(df_balanced_raw_train.shape))\r\n",
      "        print('df_balanced_raw_validation.shape={}'.format(df_balanced_raw_validation.shape))\r\n",
      "        print('df_balanced_raw_test.shape={}'.format(df_balanced_raw_test.shape))\r\n",
      "\r\n",
      "        balanced_train_data = '{}/raw/labeled/split/balanced/header/train'.format(args.output_data)\r\n",
      "        balanced_validation_data = '{}/raw/labeled/split/balanced/header/validation'.format(args.output_data)\r\n",
      "        balanced_test_data = '{}/raw/labeled/split/balanced/header/test'.format(args.output_data)\r\n",
      "\r\n",
      "        print('Creating directory {}'.format(balanced_train_data))\r\n",
      "        os.makedirs(balanced_train_data, exist_ok=True)\r\n",
      "\r\n",
      "        print('Creating directory {}'.format(balanced_validation_data))\r\n",
      "        os.makedirs(balanced_validation_data, exist_ok=True)\r\n",
      "\r\n",
      "        print('Creating directory {}'.format(balanced_test_data))\r\n",
      "        os.makedirs(balanced_test_data, exist_ok=True)\r\n",
      "\r\n",
      "        print('Writing to {}/part-{}-{}.csv'.format(balanced_train_data, args.current_host, filename_without_extension))\r\n",
      "        df_balanced_raw_train.to_csv('{}/part-{}-{}.csv'.format(balanced_train_data, args.current_host, filename_without_extension), sep=',', index=False, header=True)\r\n",
      "\r\n",
      "        print('Writing to {}/part-{}-{}.csv'.format(balanced_validation_data, args.current_host, filename_without_extension))      \r\n",
      "        df_balanced_raw_validation.to_csv('{}/part-{}-{}.csv'.format(balanced_validation_data, args.current_host, filename_without_extension), sep=',', index=False, header=True)\r\n",
      "\r\n",
      "        print('Writing to {}/part-{}-{}.csv'.format(balanced_test_data, args.current_host, filename_without_extension))\r\n",
      "        df_balanced_raw_test.to_csv('{}/part-{}-{}.csv'.format(balanced_test_data, args.current_host, filename_without_extension), sep=',', index=False, header=True)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(args.output_data))\r\n",
      "    dirs_output = os.listdir(args.output_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(unbalanced_train_data))\r\n",
      "    dirs_output = os.listdir(unbalanced_train_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(unbalanced_validation_data))\r\n",
      "    dirs_output = os.listdir(unbalanced_validation_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(unbalanced_test_data))\r\n",
      "    dirs_output = os.listdir(unbalanced_test_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(balanced_train_data))\r\n",
      "    dirs_output = os.listdir(balanced_train_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(balanced_validation_data))\r\n",
      "    dirs_output = os.listdir(balanced_validation_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Listing contents of {}'.format(balanced_test_data))\r\n",
      "    dirs_output = os.listdir(balanced_test_data)\r\n",
      "    for file in dirs_output:\r\n",
      "        print(file)\r\n",
      "\r\n",
      "    print('Complete')\r\n",
      "    \r\n",
      "    \r\n",
      "if __name__ == \"__main__\":\r\n",
      "    args = parse_args()\r\n",
      "    print('Loaded arguments:')\r\n",
      "    print(args)\r\n",
      "    \r\n",
      "    print('Environment variables:')\r\n",
      "    print(os.environ)\r\n",
      "\r\n",
      "    process(args)\r\n"
     ]
    }
   ],
   "source": [
    "cat preprocess-scikit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this script as a processing job.  You specify the command (`/opt/program/submit` for this Spark processor.)  You also need to specify one `ProcessingInput` with the `source` argument of the Amazon S3 bucket and `destination` is where the script reads this data from `/opt/ml/processing/input` (inside the Docker container.)  All local paths inside the processing container must begin with `/opt/ml/processing/`.\n",
    "\n",
    "Also give the `run()` method a `ProcessingOutput`, where the `source` is the path the script writes output data to.  For outputs, the `destination` defaults to an S3 bucket that the Amazon SageMaker Python SDK creates for you, following the format `s3://sagemaker-<region>-<account_id>/<processing_job_name>/output/<output_name>/`.  You also give the `ProcessingOutput` value for `output_name`, to make it easier to retrieve these output artifacts after the job is run.\n",
    "\n",
    "The arguments parameter in the `run()` method are command-line arguments in our `preprocess.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job name:  amazon-reviews-scikit-processor-2020-03-18-05-40-55\n"
     ]
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "output_prefix = 'amazon-reviews-scikit-processor-{}'.format(timestamp_prefix)\n",
    "processing_job_name = 'amazon-reviews-scikit-processor-{}'.format(timestamp_prefix)\n",
    "\n",
    "print('Processing job name:  {}'.format(processing_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    #base_job_name='amazon-reviews-processor-scikit',\n",
    "                                     framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.4xlarge',\n",
    "                                     instance_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/amazon-reviews-pds/tsv/\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "#s3_input_data = 's3://amazon-reviews-pds/tsv/'\n",
    "s3_input_data = 's3://{}/amazon-reviews-pds/tsv/'.format(bucket)\n",
    "print(s3_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-02 06:29:52  648641286 amazon_reviews_us_Apparel_v1_00.tsv.gz\n",
      "2020-03-02 06:29:52  582145299 amazon_reviews_us_Automotive_v1_00.tsv.gz\n",
      "2020-03-02 06:29:56  357392893 amazon_reviews_us_Baby_v1_00.tsv.gz\n",
      "2020-03-02 06:29:58  914070021 amazon_reviews_us_Beauty_v1_00.tsv.gz\n",
      "2020-03-02 06:30:07 2740337188 amazon_reviews_us_Books_v1_00.tsv.gz\n",
      "2020-03-02 06:30:09 2692708591 amazon_reviews_us_Books_v1_01.tsv.gz\n",
      "2020-03-02 06:30:10 1329539135 amazon_reviews_us_Books_v1_02.tsv.gz\n",
      "2020-03-02 06:30:23  442653086 amazon_reviews_us_Camera_v1_00.tsv.gz\n",
      "2020-03-02 06:30:27 2689739299 amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tsv.gz\n",
      "2020-03-02 06:30:34 1294879074 amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz\n",
      "2020-03-02 06:30:43  253570168 amazon_reviews_us_Digital_Music_Purchase_v1_00.tsv.gz\n",
      "2020-03-02 06:30:50   18997559 amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "2020-03-02 06:30:51  506979922 amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz\n",
      "2020-03-02 06:31:05   27442648 amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n",
      "2020-03-02 06:31:06  698828243 amazon_reviews_us_Electronics_v1_00.tsv.gz\n",
      "2020-03-02 06:31:08  148982796 amazon_reviews_us_Furniture_v1_00.tsv.gz\n",
      "2020-03-02 06:31:12   12134676 amazon_reviews_us_Gift_Card_v1_00.tsv.gz\n",
      "2020-03-02 06:31:13  401337166 amazon_reviews_us_Grocery_v1_00.tsv.gz\n",
      "2020-03-02 06:31:16 1011180212 amazon_reviews_us_Health_Personal_Care_v1_00.tsv.gz\n",
      "2020-03-02 06:31:16  193168458 amazon_reviews_us_Home_Entertainment_v1_00.tsv.gz\n",
      "2020-03-02 06:31:22  503339178 amazon_reviews_us_Home_Improvement_v1_00.tsv.gz\n",
      "2020-03-02 06:31:24 1081002012 amazon_reviews_us_Home_v1_00.tsv.gz\n",
      "2020-03-02 06:31:25  247022254 amazon_reviews_us_Jewelry_v1_00.tsv.gz\n",
      "2020-03-02 06:31:34  930744854 amazon_reviews_us_Kitchen_v1_00.tsv.gz\n",
      "2020-03-02 06:31:39  486772662 amazon_reviews_us_Lawn_and_Garden_v1_00.tsv.gz\n",
      "2020-03-02 06:31:40   60320191 amazon_reviews_us_Luggage_v1_00.tsv.gz\n",
      "2020-03-02 06:31:42   24359816 amazon_reviews_us_Major_Appliances_v1_00.tsv.gz\n",
      "2020-03-02 06:31:43  557959415 amazon_reviews_us_Mobile_Apps_v1_00.tsv.gz\n",
      "2020-03-02 06:31:46   22870508 amazon_reviews_us_Mobile_Electronics_v1_00.tsv.gz\n",
      "2020-03-02 06:31:47 1521994296 amazon_reviews_us_Music_v1_00.tsv.gz\n",
      "2020-03-02 06:31:51  193389086 amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\n",
      "2020-03-02 06:31:54  512323500 amazon_reviews_us_Office_Products_v1_00.tsv.gz\n",
      "2020-03-02 06:31:57  448963100 amazon_reviews_us_Outdoors_v1_00.tsv.gz\n",
      "2020-03-02 06:31:57 1512903923 amazon_reviews_us_PC_v1_00.tsv.gz\n",
      "2020-03-02 06:31:58   17634794 amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv.gz\n",
      "2020-03-02 06:31:59  515815253 amazon_reviews_us_Pet_Products_v1_00.tsv.gz\n",
      "2020-03-02 06:32:07  642255314 amazon_reviews_us_Shoes_v1_00.tsv.gz\n",
      "2020-03-02 06:32:08   94010685 amazon_reviews_us_Software_v1_00.tsv.gz\n",
      "2020-03-02 06:32:10  872478735 amazon_reviews_us_Sports_v1_00.tsv.gz\n",
      "2020-03-02 06:32:10  333782939 amazon_reviews_us_Tools_v1_00.tsv.gz\n",
      "2020-03-02 06:32:19  838451398 amazon_reviews_us_Toys_v1_00.tsv.gz\n",
      "2020-03-02 06:32:23 1512355451 amazon_reviews_us_Video_DVD_v1_00.tsv.gz\n",
      "2020-03-02 06:32:23  475199894 amazon_reviews_us_Video_Games_v1_00.tsv.gz\n",
      "2020-03-02 06:32:35  138929896 amazon_reviews_us_Video_v1_00.tsv.gz\n",
      "2020-03-02 06:32:36  162973819 amazon_reviews_us_Watches_v1_00.tsv.gz\n",
      "2020-03-02 06:32:39 1704713674 amazon_reviews_us_Wireless_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Outputs\n",
    "# s3_output_train_data = 's3://{}/{}/train'.format(bucket, output_prefix)\n",
    "# s3_output_validation_data = 's3://{}/{}/validation'.format(bucket, output_prefix)\n",
    "# s3_output_test_data = 's3://{}/{}/test'.format(bucket, output_prefix)\n",
    "\n",
    "# print(s3_output_train_data)\n",
    "# print(s3_output_validation_data)\n",
    "# print(s3_output_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-03-18-05-40-57-007\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/amazon-reviews-pds/tsv/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/input/code/preprocess-scikit.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'raw-labeled-split-unbalanced-header-train', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-train', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-unbalanced-header-validation', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-validation', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-unbalanced-header-test', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-test', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-balanced-header-train', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-train', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-balanced-header-validation', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-validation', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-balanced-header-test', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-test', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/test', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "# ShardedS3Key to spread the transformations across all nodes\n",
    "processor.run(code='preprocess-scikit.py',\n",
    "                      inputs=[ProcessingInput(source=s3_input_data,\n",
    "                                              destination='/opt/ml/processing/input/data/',\n",
    "                                              s3_data_distribution_type='ShardedByS3Key')],\n",
    "                      outputs=[\n",
    "                               ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                                output_name='raw-labeled-split-unbalanced-header-train',\n",
    "                                                source='/opt/ml/processing/output/raw/labeled/split/unbalanced/header/train'),\n",
    "                               ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                                output_name='raw-labeled-split-unbalanced-header-validation',\n",
    "                                                source='/opt/ml/processing/output/raw/labeled/split/unbalanced/header/validation'),\n",
    "                               ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                                output_name='raw-labeled-split-unbalanced-header-test',\n",
    "                                                source='/opt/ml/processing/output/raw/labeled/split/unbalanced/header/test'),\n",
    "                               ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                                output_name='raw-labeled-split-balanced-header-train',\n",
    "                                                source='/opt/ml/processing/output/raw/labeled/split/balanced/header/train'),\n",
    "                               ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                                output_name='raw-labeled-split-balanced-header-validation',\n",
    "                                                source='/opt/ml/processing/output/raw/labeled/split/balanced/header/validation'),\n",
    "                               ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                                output_name='raw-labeled-split-balanced-header-test',\n",
    "                                                source='/opt/ml/processing/output/raw/labeled/split/balanced/header/test'),\n",
    "                      ],\n",
    "                      logs=True,\n",
    "                      wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProcessingInputs': [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/amazon-reviews-pds/tsv/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/input/code/preprocess-scikit.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'raw-labeled-split-unbalanced-header-train', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-train', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-unbalanced-header-validation', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-validation', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-unbalanced-header-test', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-test', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-balanced-header-train', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-train', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-balanced-header-validation', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-validation', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/validation', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'raw-labeled-split-balanced-header-test', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-test', 'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/test', 'S3UploadMode': 'EndOfJob'}}]}, 'ProcessingJobName': 'sagemaker-scikit-learn-2020-03-18-05-40-57-007', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 10, 'InstanceType': 'ml.m5.4xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocess-scikit.py']}, 'RoleArn': 'arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/sagemaker-scikit-learn-2020-03-18-05-40-57-007', 'ProcessingJobStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 3, 18, 5, 40, 57, 577000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 3, 18, 5, 40, 57, 577000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'b779632c-e344-4438-92e8-129bb20d38cf', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b779632c-e344-4438-92e8-129bb20d38cf', 'content-type': 'application/x-amz-json-1.1', 'content-length': '3361', 'date': 'Wed, 18 Mar 2020 05:40:56 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "preprocessing_job_description = processor.jobs[-1].describe()\n",
    "print(preprocessing_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/ProcessingJobs;prefix=sagemaker-scikit-learn-2020-03-18-05-40-57-007;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processing_job_name = preprocessing_job_description['ProcessingJobName']\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(region, processing_job_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n"
     ]
    }
   ],
   "source": [
    "processing_job_status = preprocessing_job_description['ProcessingJobStatus']\n",
    "if (processing_job_status in ['Completed', 'Stopped']):\n",
    "    # TODO:  Do something interesting...\n",
    "    print('Complete')\n",
    "else:\n",
    "    print(processing_job_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please wait until the Processing Job Completes above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'input-1',\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/amazon-reviews-pds/tsv/',\n",
       "    'LocalPath': '/opt/ml/processing/input/data/',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'ShardedByS3Key',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'code',\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/input/code/preprocess-scikit.py',\n",
       "    'LocalPath': '/opt/ml/processing/input/code',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'raw-labeled-split-unbalanced-header-train',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-train',\n",
       "     'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/train',\n",
       "     'S3UploadMode': 'EndOfJob'}},\n",
       "   {'OutputName': 'raw-labeled-split-unbalanced-header-validation',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-validation',\n",
       "     'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/validation',\n",
       "     'S3UploadMode': 'EndOfJob'}},\n",
       "   {'OutputName': 'raw-labeled-split-unbalanced-header-test',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-test',\n",
       "     'LocalPath': '/opt/ml/processing/output/raw/labeled/split/unbalanced/header/test',\n",
       "     'S3UploadMode': 'EndOfJob'}},\n",
       "   {'OutputName': 'raw-labeled-split-balanced-header-train',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-train',\n",
       "     'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/train',\n",
       "     'S3UploadMode': 'EndOfJob'}},\n",
       "   {'OutputName': 'raw-labeled-split-balanced-header-validation',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-validation',\n",
       "     'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/validation',\n",
       "     'S3UploadMode': 'EndOfJob'}},\n",
       "   {'OutputName': 'raw-labeled-split-balanced-header-test',\n",
       "    'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-test',\n",
       "     'LocalPath': '/opt/ml/processing/output/raw/labeled/split/balanced/header/test',\n",
       "     'S3UploadMode': 'EndOfJob'}}]},\n",
       " 'ProcessingJobName': 'sagemaker-scikit-learn-2020-03-18-05-40-57-007',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 10,\n",
       "   'InstanceType': 'ml.m5.4xlarge',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3',\n",
       "  'ContainerEntrypoint': ['python3',\n",
       "   '/opt/ml/processing/input/code/preprocess-scikit.py']},\n",
       " 'RoleArn': 'arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:835319576252:processing-job/sagemaker-scikit-learn-2020-03-18-05-40-57-007',\n",
       " 'ProcessingJobStatus': 'InProgress',\n",
       " 'LastModifiedTime': datetime.datetime(2020, 3, 18, 5, 40, 57, 577000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2020, 3, 18, 5, 40, 57, 577000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '5c70a303-5ba9-4fa2-8c1f-0f63c06c520e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5c70a303-5ba9-4fa2-8c1f-0f63c06c520e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3361',\n",
       "   'date': 'Wed, 18 Mar 2020 05:40:57 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(processing_job_name=processing_job_name,\n",
    "                                                                            sagemaker_session=sagemaker_session)\n",
    "running_processor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/?region=us-east-1&tab=overview\">S3 Output Data</a> After The Spark Job Has Completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<b>Review <a href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Spark Job Has Completed</b>'.format(bucket, processing_job_name, region)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-train\n",
      "s3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-validation\n",
      "s3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-unbalanced-header-test\n",
      "s3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-train\n",
      "s3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-validation\n",
      "s3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-18-05-40-57-007/output/raw-labeled-split-balanced-header-test\n"
     ]
    }
   ],
   "source": [
    "output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'raw-labeled-split-unbalanced-header-train':\n",
    "        preprocessed_unbalanced_train_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'raw-labeled-split-unbalanced-header-validation':\n",
    "        preprocessed_unbalanced_validation_data = output['S3Output']['S3Uri']        \n",
    "    if output['OutputName'] == 'raw-labeled-split-unbalanced-header-test':\n",
    "        preprocessed_unbalanced_test_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'raw-labeled-split-balanced-header-train':\n",
    "        preprocessed_balanced_train_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'raw-labeled-split-balanced-header-validation':\n",
    "        preprocessed_balanced_validation_data = output['S3Output']['S3Uri']        \n",
    "    if output['OutputName'] == 'raw-labeled-split-balanced-header-test':\n",
    "        preprocessed_balanced_test_data = output['S3Output']['S3Uri']\n",
    "        \n",
    "print(preprocessed_unbalanced_train_data)\n",
    "print(preprocessed_unbalanced_validation_data)\n",
    "print(preprocessed_unbalanced_test_data)\n",
    "print(preprocessed_balanced_train_data)\n",
    "print(preprocessed_balanced_validation_data)\n",
    "print(preprocessed_balanced_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the processed dataset\n",
    "Take a look at a few rows of the transformed dataset to make sure the preprocessing was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $preprocessed_unbalanced_train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $preprocessed_unbalanced_validation_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $preprocessed_unbalanced_test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $preprocessed_balanced_train_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $preprocessed_balanced_validation_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $preprocessed_balanced_test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
