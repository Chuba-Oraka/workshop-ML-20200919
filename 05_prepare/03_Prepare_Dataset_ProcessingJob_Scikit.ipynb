{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q xgboost==0.90\n",
    "!pip install -q scikit-learn==0.20.3\n",
    "!pip install -q nltk==3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "#sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ./data/amazon90000.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/amazon90000.tsv', delimiter='\\t')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean commas from raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed = df\n",
    "\n",
    "df_scrubbed['marketplace'] = df_scrubbed['marketplace'].replace(',', ' ')\n",
    "df_scrubbed['review_id'] = df_scrubbed['review_id'].replace(',', ' ')\n",
    "df_scrubbed['product_id'] = df_scrubbed['product_id'].replace(',', ' ')\n",
    "df_scrubbed['product_title'] = df_scrubbed['product_title'].replace(',', ' ')\n",
    "df_scrubbed['product_category'] = df_scrubbed['product_category'].replace(',', ' ')\n",
    "df_scrubbed['review_headline'] = df_scrubbed['review_headline'].replace(',', ' ')\n",
    "df_scrubbed['review_body'] = df_scrubbed['review_body'].replace(',', ' ')\n",
    "df_scrubbed['review_date'] = df_scrubbed['review_date'].replace(',', ' ')\n",
    "\n",
    "df_scrubbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed = df.dropna()\n",
    "df_scrubbed = df_scrubbed.reset_index(drop=True)\n",
    "df_scrubbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_scrubbed['is_positive_sentiment'] = (df_scrubbed['star_rating'] >= 4).astype(int)\n",
    "df_scrubbed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the data file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/scrubbed-raw-with-header/data.csv\n",
    "\n",
    "prefix = 'feature-store/amazon-reviews/scrubbed-raw-with-header'\n",
    "\n",
    "scrubbed_raw_with_header_path = './{}/data.csv'.format(prefix)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "\n",
    "df_scrubbed.to_csv(scrubbed_raw_with_header_path, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrubbed_raw_with_header_s3_uri = sess.upload_data(path=scrubbed_raw_with_header_path, key_prefix=prefix)\n",
    "\n",
    "print(df_scrubbed_raw_with_header_s3_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='is_positive_sentiment', data=df_scrubbed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the Dataset between Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "is_negative_sentiment_df = df_scrubbed.query('is_positive_sentiment == 0')\n",
    "is_positive_sentiment_df = df_scrubbed.query('is_positive_sentiment == 1')\n",
    "\n",
    "# TODO:  check which sentiment has the least number of samples\n",
    "\n",
    "is_positive_downsampled_df = resample(is_positive_sentiment_df,\n",
    "                                      replace = False,\n",
    "                                      n_samples = len(is_negative_sentiment_df),\n",
    "                                      random_state = 27)\n",
    "\n",
    "df_balanced_raw = pd.concat([is_negative_sentiment_df, is_positive_downsampled_df])\n",
    "df_balanced_raw = df_balanced_raw.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_balanced_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='is_positive_sentiment', data=df_balanced_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_raw_only_2_columns = df_balanced_raw[['is_positive_sentiment', 'review_body']]\n",
    "#df_y_balanced_raw = df_balanced_raw['is_positive_sentiment']\n",
    "\n",
    "df_balanced_raw_only_2_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the data file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/balanced-raw-with-header/data.csv\n",
    "\n",
    "prefix = 'feature-store/amazon-reviews/balanced-raw-with-header'\n",
    "\n",
    "balanced_raw_with_header_path = './{}/data.csv'.format(prefix)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix, exist_ok=True)\n",
    "\n",
    "df_balanced_raw_only_2_columns.to_csv(balanced_raw_with_header_path, index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_raw_with_header_s3_uri = sess.upload_data(path=balanced_raw_with_header_path, key_prefix=prefix)\n",
    "\n",
    "print(df_balanced_raw_with_header_s3_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF/IDF Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the raw text into TF/IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (X)\n",
    "df_X_balanced_raw = df_balanced_raw[['review_body']]\n",
    "# Labels (y)\n",
    "df_y_balanced_raw = df_balanced_raw['is_positive_sentiment']\n",
    "\n",
    "print('X.shape:  {}'.format(df_X_balanced_raw.shape))\n",
    "print('y.shape:  {}'.format(df_y_balanced_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def feature_transform_fn(df_text):\n",
    "    text_processors = Pipeline(\n",
    "        steps=[\n",
    "            (\n",
    "                'tfidfvectorizer',\n",
    "                TfidfVectorizer(\n",
    "                    max_df=0.25,                                       \n",
    "                    min_df=.0025,\n",
    "                    analyzer='word',\n",
    "                    max_features=10000\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    column_transformer = ColumnTransformer(\n",
    "        transformers=[('text_processing', text_processors, df_text.columns.get_loc('review_body'))]\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('column_transformer',\n",
    "             column_transformer), ('svd', TruncatedSVD(n_components=300)),\n",
    "            ('standardscaler', StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_tfidf = feature_transform_fn(df_X_balanced_raw).fit_transform(df_X_balanced_raw)\n",
    "df_tfidf = pd.DataFrame(np_tfidf)\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the following:  https://aws.amazon.com/blogs/machine-learning/flagging-suspicious-healthcare-claims-with-amazon-sagemaker/\n",
    "\n",
    "_Note:  This takes a while.  Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_model = TSNE(perplexity=10, n_components=2, init='pca', n_iter=250, random_state=10)\n",
    "new_values = tsne_model.fit_transform(new_df_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# column 0-299\n",
    "labels = df_tfidf.columns.values\n",
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "plt.figure(figsize=(16, 16)) \n",
    "for i in range(len(x)):\n",
    "    plt.scatter(x[i],y[i])\n",
    "    plt.annotate(labels[i],\n",
    "                 xy=(x[i], y[i]),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#df_tfidf = vectorizer.fit_transform(text)\n",
    "\n",
    "#feature_names = vectorizer.get_feature_names()\n",
    "#print(feature_names)\n",
    "\n",
    "#df_tfidf = pd.DataFrame(vectorizer.idf_, \n",
    "#                        index=vectorizer.get_feature_names(),\n",
    "#                        columns=['idf'])\n",
    "\n",
    "#df_tfidf = pd.DataFrame(X.todense(),columns=vectorizer.get_feature_names())\n",
    "#df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform just the features (X)\n",
    "_This will run for a minute or two.  Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_tfidf = transformer.fit_transform(df_X_balanced_raw)\n",
    "df_tfidf = pd.DataFrame(np_tfidf)\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add back the label (y) into the first column\n",
    "The label needs to be in the 1st column for some of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.insert(0, 'is_positive_sentiment', df_y_balanced_raw)\n",
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly split the data into `train`, `validation`, and `test` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split all data into 90% train and 10% holdout\n",
    "df_tfidf_train, df_tfidf_holdout = train_test_split(df_tfidf, test_size=0.1, random_state=0)\n",
    "\n",
    "# Split the holdout into 50% validation and 50% test\n",
    "df_tfidf_validation, df_tfidf_test = train_test_split(df_tfidf_holdout, test_size=0.5, random_state=0)\n",
    "\n",
    "print('df_tfidf.shape={}'.format(df_tfidf.shape))\n",
    "print('df_tfidf_train.shape={}'.format(df_tfidf_train.shape))\n",
    "print('df_tfidf_validation.shape={}'.format(df_tfidf_validation.shape))\n",
    "print('df_tfidf_test.shape={}'.format(df_tfidf_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tfidf_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the datasets locally\n",
    "_Note: `header=False`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/balanced-tfidf-without-header/data.csv\n",
    "\n",
    "prefix_train = 'feature-store/amazon-reviews/balanced-tfidf-without-header/train'\n",
    "prefix_validation = 'feature-store/amazon-reviews/balanced-tfidf-without-header/validation'\n",
    "prefix_test = 'feature-store/amazon-reviews/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_train_path = './{}/data.csv'.format(prefix_train)\n",
    "balanced_tfidf_without_header_validation_path = './{}/data.csv'.format(prefix_validation)\n",
    "balanced_tfidf_without_header_test_path = './{}/data.csv'.format(prefix_test)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix_train, exist_ok=True)\n",
    "os.makedirs(prefix_validation, exist_ok=True)\n",
    "os.makedirs(prefix_test, exist_ok=True)\n",
    "\n",
    "df_tfidf_train.to_csv(balanced_tfidf_without_header_train_path, index=False, header=False)\n",
    "df_tfidf_validation.to_csv(balanced_tfidf_without_header_validation_path, index=False, header=False)\n",
    "df_tfidf_test.to_csv(balanced_tfidf_without_header_test_path, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_tfidf_without_header_train_s3_uri = sess.upload_data(path=balanced_tfidf_without_header_train_path, key_prefix=prefix_train)\n",
    "df_balanced_tfidf_without_header_validation_s3_uri = sess.upload_data(path=balanced_tfidf_without_header_train_path, key_prefix=prefix_validation)\n",
    "df_balanced_tfidf_without_header_test_s3_uri = sess.upload_data(path=balanced_tfidf_without_header_train_path, key_prefix=prefix_test)\n",
    "\n",
    "print(df_balanced_tfidf_without_header_train_s3_uri)\n",
    "print(df_balanced_tfidf_without_header_validation_s3_uri)\n",
    "print(df_balanced_tfidf_without_header_test_s3_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $df_balanced_tfidf_without_header_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
