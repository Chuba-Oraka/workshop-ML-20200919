{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the S3 Location of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r scikit_processing_job_s3_output_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Scikit Processing Job Name: sagemaker-scikit-learn-2020-03-24-01-28-42-203\n"
     ]
    }
   ],
   "source": [
    "print('Previous Scikit Processing Job Name: {}'.format(scikit_processing_job_s3_output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-24-01-28-42-203/output/bert-labeled-split-balanced-header-train', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-24-01-28-42-203/output/bert-labeled-split-balanced-header-validation', 'S3DataDistributionType': 'FullyReplicated'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/sagemaker-scikit-learn-2020-03-24-01-28-42-203/output/bert-labeled-split-balanced-header-test', 'S3DataDistributionType': 'FullyReplicated'}}}\n"
     ]
    }
   ],
   "source": [
    "prefix_train = '{}/output/bert-labeled-split-balanced-header-train'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_validation = '{}/output/bert-labeled-split-balanced-header-validation'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_test = '{}/output/bert-labeled-split-balanced-header-test'.format(scikit_processing_job_s3_output_prefix)\n",
    "\n",
    "path_train = './{}'.format(prefix_train)\n",
    "path_validation = './{}'.format(prefix_validation)\n",
    "path_test = './{}'.format(prefix_test)\n",
    "\n",
    "train_s3_uri = 's3://{}/{}'.format(bucket, prefix_train)\n",
    "validation_s3_uri = 's3://{}/{}'.format(bucket, prefix_validation)\n",
    "test_s3_uri = 's3://{}/{}'.format(bucket, prefix_test)\n",
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=train_s3_uri) #, content_type='text/csv')\n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=validation_s3_uri) #, content_type='text/csv')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=test_s3_uri) #, content_type='text/csv')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import argparse\r\n",
      "import csv\r\n",
      "import pickle as pkl\r\n",
      "import pandas as pd\r\n",
      "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\r\n",
      "import sklearn\r\n",
      "from sklearn import metrics\r\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
      "import re\r\n",
      "import glob\r\n",
      "import json\r\n",
      "import numpy as np\r\n",
      "import subprocess\r\n",
      "import sys\r\n",
      "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'simpletransformers'])\r\n",
      "import torch\r\n",
      "import torch.distributed as dist\r\n",
      "import torch.utils.data\r\n",
      "import torch.utils.data.distributed\r\n",
      "\r\n",
      "import simpletransformers\r\n",
      "from simpletransformers.classification import ClassificationModel\r\n",
      "\r\n",
      "def load_dataset(path, sep, header):\r\n",
      "    data = pd.concat([pd.read_csv(f, sep=sep, header=header) for f in glob.glob('{}/*.csv'.format(path))], ignore_index = True)\r\n",
      "\r\n",
      "    labels = data.iloc[:,0]\r\n",
      "    features = data.drop(data.columns[0], axis=1)\r\n",
      "\r\n",
      "    if header==None:\r\n",
      "        # Adjust the column names after dropped the 0th column above\r\n",
      "        # New column names are 0 (inclusive) to len(features.columns) (exclusive)\r\n",
      "        new_column_names = list(range(0, len(features.columns)))\r\n",
      "        features.columns = new_column_names\r\n",
      "\r\n",
      "    return features, labels\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument('--model-type', type=str, default='bert')\r\n",
      "    parser.add_argument('--model-name', type=str, default='bert-base-cased')\r\n",
      "    parser.add_argument('--backend', type=str, default='gloo')\r\n",
      "    parser.add_argument('--train-data', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\r\n",
      "    parser.add_argument('--validation-data', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\r\n",
      "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\r\n",
      "    parser.add_argument('--hosts', type=list, default=json.loads(os.environ['SM_HOSTS']))\r\n",
      "    parser.add_argument('--current-host', type=str, default=os.environ['SM_CURRENT_HOST'])\r\n",
      "    parser.add_argument('--num-gpus', type=int, default=os.environ['SM_NUM_GPUS'])\r\n",
      "\r\n",
      "    args, _ = parser.parse_known_args()   \r\n",
      "    model_type = args.model_type\r\n",
      "    model_name = args.model_name\r\n",
      "    backend = args.backend\r\n",
      "    train_data = args.train_data\r\n",
      "    validation_data = args.validation_data\r\n",
      "    model_dir = args.model_dir\r\n",
      "    hosts = args.hosts\r\n",
      "    current_host = args.current_host\r\n",
      "    num_gpus = args.num_gpus\r\n",
      "\r\n",
      "    # TODO:  Convert to distributed data loader\r\n",
      "    #        https://pytorch.org/tutorials/beginner/aws_distributed_training_tutorial.html\r\n",
      "    #        https://github.com/aws/sagemaker-python-sdk/issues/1110\r\n",
      "    is_distributed = len(args.hosts) > 1 and args.backend is not None\r\n",
      "    print('Distributed training - {}'.format(is_distributed))\r\n",
      "    use_cuda = args.num_gpus > 0\r\n",
      "    print('Number of gpus available - {}'.format(args.num_gpus))\r\n",
      "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\r\n",
      "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
      "\r\n",
      "    if is_distributed:\r\n",
      "        # Initialize the distributed environment.\r\n",
      "        world_size = len(args.hosts)\r\n",
      "        os.environ['WORLD_SIZE'] = str(world_size)\r\n",
      "        host_rank = args.hosts.index(args.current_host)\r\n",
      "        os.environ['RANK'] = str(host_rank)\r\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\r\n",
      "        print('Initialized the distributed environment: \\'{}\\' backend on {} nodes. '.format(\r\n",
      "            args.backend, dist.get_world_size()) + 'Current host rank is {}. Number of gpus: {}'.format(\r\n",
      "            dist.get_rank(), args.num_gpus))\r\n",
      "\r\n",
      "    # TODO:  Change this to use SM_CHANNEL_TRAIN and DistributedDataLoader, etc\r\n",
      "    # X_train, y_train = load_dataset(train_data, ',', header=0)\r\n",
      "    # X_validation, y_validation = load_dataset(validation_data, ',', header=0)\r\n",
      "\r\n",
      "    df1 = pd.read_csv('./data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', \r\n",
      "                 delimiter='\\t', \r\n",
      "                 quoting=csv.QUOTE_NONE,\r\n",
      "                 compression='gzip',\r\n",
      "                 header=0)\r\n",
      "    print(df1.shape)\r\n",
      "\r\n",
      "    df2 = pd.read_csv('./data/amazon_reviews_us_Video_Games_v1_00.tsv.gz',\r\n",
      "                 delimiter='\\t', \r\n",
      "                 quoting=csv.QUOTE_NONE,\r\n",
      "                 compression='gzip', \r\n",
      "                 header=0)\r\n",
      "    print(df2.shape)\r\n",
      "\r\n",
      "    df = pd.concat([df1, df2])\r\n",
      "\r\n",
      "    print('YES: {}'.format(df.isna().values.any()))\r\n",
      "    df = df.dropna()\r\n",
      "    df = df.reset_index(drop=True)\r\n",
      "\r\n",
      "    # Enrich the data\r\n",
      "    df['is_positive_sentiment'] = (df['star_rating'] >= 4).astype(int)\r\n",
      "\r\n",
      "    df_bert = df[['review_body', 'is_positive_sentiment']]\r\n",
      "    df_bert.columns = ['text', 'labels']\r\n",
      "    df_bert.head(5)\r\n",
      "\r\n",
      "    print(df_bert.shape)\r\n",
      "\r\n",
      "    df_bert = df_bert #[:200100]\r\n",
      "    df_bert.shape\r\n",
      "\r\n",
      "    from sklearn.model_selection import train_test_split\r\n",
      "\r\n",
      "    df_bert_train, df_bert_holdout = train_test_split(df_bert, test_size=0.10)\r\n",
      "    df_bert_validation, df_bert_test = train_test_split(df_bert_holdout, test_size=0.50)\r\n",
      "\r\n",
      "    print(df_bert_train.shape)\r\n",
      "    print(df_bert_validation.shape)\r\n",
      "    print(df_bert_test.shape)\r\n",
      "\r\n",
      "    # TODO:  change output_dir to SM_model_dir or output_path\r\n",
      "    bert_args = {\r\n",
      "       'output_dir': model_dir, \r\n",
      "       'cache_dir': 'cache/',\r\n",
      "       'fp16': False,\r\n",
      "       'max_seq_length': 128,\r\n",
      "       'train_batch_size': 8,\r\n",
      "       'eval_batch_size': 8,\r\n",
      "       'gradient_accumulation_steps': 1,\r\n",
      "       'num_train_epochs': 1,\r\n",
      "       'weight_decay': 0,\r\n",
      "       'learning_rate': 3e-5,\r\n",
      "       'adam_epsilon': 1e-8,\r\n",
      "       'warmup_ratio': 0.06,\r\n",
      "       'warmup_steps': 0,\r\n",
      "       'max_grad_norm': 1.0,\r\n",
      "       'logging_steps': 50,\r\n",
      "       'evaluate_during_training': False,\r\n",
      "       'save_steps': 2000,\r\n",
      "       'eval_all_checkpoints': True,\r\n",
      "       'use_tensorboard': True,\r\n",
      "       'tensorboard_dir': 'tensorboard',\r\n",
      "       'overwrite_output_dir': True,\r\n",
      "       'reprocess_input_data': False,\r\n",
      "    }\r\n",
      "\r\n",
      "    bert_model = ClassificationModel(model_type='distilbert', # bert, distilbert, etc, etc.\r\n",
      "                                     model_name='distilbert-base-cased',\r\n",
      "                                     args=bert_args,\r\n",
      "                                     use_cuda=use_cuda)\r\n",
      "\r\n",
      "    bert_model.train_model(train_df=df_bert_train,\r\n",
      "                           eval_df=df_bert_validation,\r\n",
      "                           show_running_loss=True)\r\n",
      "\r\n",
      "    # TODO:  use the model_dir that is passed in through args\r\n",
      "    #        (currently SM_MODEL_DIR)\r\n",
      "#    os.makedirs(model_dir, exist_ok=True)\r\n",
      "#    model_path = os.path.join(model_dir, 'bert-model')\r\n",
      "\r\n",
      "#    pkl.dump(bert_model, open(model_path, 'wb'))\r\n",
      "#    print('Wrote model to {}'.format(model_path))\r\n",
      "   \r\n",
      "#    result, model_outputs, wrong_predictions = bert_model.eval_model(eval_df=df_bert_test, acc=sklearn.metrics.accuracy_score)\r\n",
      "\r\n",
      "#    print(result)\r\n",
      "\r\n",
      "    # Show bad predictions\r\n",
      "#    print('Number of wrong predictions: {}'.format(len(wrong_predictions)))\r\n",
      "#    print('\\n')\r\n",
      "\r\n",
      "#    for prediction in wrong_predictions:\r\n",
      "#        print(prediction.text_a)\r\n",
      "#        print('\\n')\r\n",
      "\r\n",
      "#    predictions, raw_outputs = bert_model.predict([\"\"\"I really enjoyed this item.  I highly recommend it.\"\"\"])\r\n",
      "\r\n",
      "#    print('Predictions: {}'.format(predictions))\r\n",
      "#    print('Raw outputs: {}'.format(raw_outputs))\r\n",
      "\r\n",
      "#    predictions, raw_outputs = bert_model.predict([\"\"\"This item is awful and terrible.\"\"\"])\r\n",
      "\r\n",
      "#    print('Predictions: {}'.format(predictions))\r\n",
      "#    print('Raw outputs: {}'.format(raw_outputs))\r\n"
     ]
    }
   ],
   "source": [
    "!cat src_bert/bert_reviews.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "model_output_path = 's3://{}/models/tf-bert/script-mode/training-runs'.format(bucket)\n",
    "\n",
    "bert_estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                         source_dir='src_bert_tf',\n",
    "                         role=role,\n",
    "                         train_instance_count=1, # 1 is actually faster due to communication overhead with >1\n",
    "                         train_instance_type='ml.c5.9xlarge',\n",
    "                         py_version='py3',\n",
    "                         framework_version='1.15.2',\n",
    "                         output_path=model_output_path,\n",
    "                         hyperparameters={'model_type':'bert',\n",
    "                                          'model_name': 'bert-base-cased'},\n",
    "                         enable_cloudwatch_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_estimator.fit(inputs={'train': s3_input_train_data, \n",
    "                           'validation': s3_input_validation_data,}, \n",
    "                   wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_job_name:  tensorflow-training-2020-03-24-02-03-34-945\n"
     ]
    }
   ],
   "source": [
    "training_job_name = bert_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-24 02:04:30 Starting - Starting the training job...\n",
      "2020-03-24 02:04:32 Starting - Launching requested ML instances......\n",
      "2020-03-24 02:05:39 Starting - Preparing the instances for training...\n",
      "2020-03-24 02:06:25 Downloading - Downloading input data...\n",
      "2020-03-24 02:06:50 Training - Training image download completed. Training in progress..\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-03-24 02:06:53,483 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2020-03-24 02:06:53,489 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-24 02:07:43,277 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-24 02:07:43,290 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-24 02:07:43,303 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-24 02:07:43,312 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_name\": \"bert-base-cased\",\n",
      "        \"model_type\": \"bert\",\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2020-03-24-02-03-34-945\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-835319576252/tensorflow-training-2020-03-24-02-03-34-945/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tf_bert_reviews\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 36,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tf_bert_reviews.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model\",\"model_name\":\"bert-base-cased\",\"model_type\":\"bert\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=tf_bert_reviews.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=tf_bert_reviews\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=36\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-835319576252/tensorflow-training-2020-03-24-02-03-34-945/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model\",\"model_name\":\"bert-base-cased\",\"model_type\":\"bert\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2020-03-24-02-03-34-945\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-835319576252/tensorflow-training-2020-03-24-02-03-34-945/source/sourcedir.tar.gz\",\"module_name\":\"tf_bert_reviews\",\"network_interface_name\":\"eth0\",\"num_cpus\":36,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tf_bert_reviews.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model\",\"--model_name\",\"bert-base-cased\",\"--model_type\",\"bert\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=bert-base-cased\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_TYPE=bert\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 tf_bert_reviews.py --model_dir s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model --model_name bert-base-cased --model_type bert\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.6/dist-packages (1.15.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.11.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.27.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (0.15.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-03-24 02:07:58 Uploading - Uploading generated training model\n",
      "2020-03-24 02:07:58 Failed - Training job failed\n",
      "\u001b[34mCollecting tensorflow-hub==0.7.0\n",
      "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl (89 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0) (1.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0) (1.14.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0) (3.11.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0) (46.0.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorflow-hub\u001b[0m\n",
      "\u001b[34mSuccessfully installed tensorflow-hub-0.7.0\u001b[0m\n",
      "\u001b[34mCollecting bert-tensorflow==1.0.1\n",
      "  Downloading bert_tensorflow-1.0.1-py2.py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.14.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bert-tensorflow\u001b[0m\n",
      "\u001b[34mSuccessfully installed bert-tensorflow-1.0.1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m1.15.2\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:514: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/train/part-algo-1-amazon_reviews_us_Software_v1_00.csv']\u001b[0m\n",
      "\u001b[34mBeginning Training!\u001b[0m\n",
      "\u001b[34m[2020-03-24 02:07:53.243 ip-10-0-68-245.ec2.internal:98 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-03-24 02:07:53.243 ip-10-0-68-245.ec2.internal:98 INFO hook.py:170] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-03-24 02:07:53.243 ip-10-0-68-245.ec2.internal:98 INFO hook.py:215] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"tf_bert_reviews.py\", line 263, in <module>\n",
      "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/smdebug.py\", line 57, in run\n",
      "    return_value = function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n",
      "    input_fn, ModeKeys.TRAIN))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
      "    self._call_input_fn(input_fn, mode))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1116, in _call_input_fn\n",
      "    return input_fn(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/bert/run_classifier.py\", line 541, in input_fn\n",
      "    d = tf.data.TFRecordDataset(input_file)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/readers.py\", line 336, in __init__\n",
      "    filenames, compression_type, buffer_size, num_parallel_reads)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/readers.py\", line 296, in __init__\n",
      "    filenames = _create_or_validate_filenames_dataset(filenames)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/readers.py\", line 56, in _create_or_validate_filenames_dataset\n",
      "    filenames = ops.convert_to_tensor(filenames, dtype=dtypes.string)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1184, in convert_to_tensor\n",
      "    return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1242, in convert_to_tensor_v2\n",
      "    as_ref=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1297, in internal_convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 286, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\", line 265, in _constant_impl\n",
      "    allow_broadcast=allow_broadcast))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py\", line 437, in make_tensor_proto\n",
      "    raise ValueError(\"None values not supported.\")\u001b[0m\n",
      "\u001b[34mValueError: None values not supported.\u001b[0m\n",
      "\u001b[34m[2020-03-24 02:07:53.269 ip-10-0-68-245.ec2.internal:98 INFO utils.py:25] The end of training job file will not be written for jobs running under SageMaker.\u001b[0m\n",
      "\u001b[34m2020-03-24 02:07:53,525 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/bin/python3 tf_bert_reviews.py --model_dir s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model --model_name bert-base-cased --model_type bert\"\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job tensorflow-training-2020-03-24-02-03-34-945: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python3 tf_bert_reviews.py --model_dir s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model --model_name bert-base-cased --model_type bert\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7832635e8b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbert_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_job_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mattach\u001b[0;34m(cls, training_job_name, sagemaker_session, model_channel_name)\u001b[0m\n\u001b[1;32m   1835\u001b[0m         \"\"\"\n\u001b[1;32m   1836\u001b[0m         estimator = super(Framework, cls).attach(\n\u001b[0;32m-> 1837\u001b[0;31m             \u001b[0mtraining_job_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_channel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m         )\n\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mattach\u001b[0;34m(cls, training_job_name, sagemaker_session, model_channel_name)\u001b[0m\n\u001b[1;32m    588\u001b[0m         )\n\u001b[1;32m    589\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2613\u001b[0m                 ),\n\u001b[1;32m   2614\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m             )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job tensorflow-training-2020-03-24-02-03-34-945: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python3 tf_bert_reviews.py --model_dir s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-02-03-34-945/model --model_name bert-base-cased --model_type bert\""
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "bert_estimator = TensorFlow.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model artifact from AWS S3\n",
    "!aws s3 cp $model_output_path/$training_job_name/output/model.tar.gz ./models/bert-tf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "tar = tarfile.open('./models/bert-tf/model.tar.gz')\n",
    "tar.extractall(path='./models/bert-tf-model')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# args = {\n",
    "#    'fp16': False,\n",
    "#    'max_seq_length': 128\n",
    "# }\n",
    "\n",
    "# bert_model = ClassificationModel(model_type='distilbert', # bert, distilbert, etc, etc.\n",
    "#                                  model_name='./models/bert-model',\n",
    "#                                  args=args,\n",
    "#                                  use_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = bert_model.predict([\"\"\"I really enjoyed this item.  I highly recommend it.\"\"\"])\n",
    "\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = bert_model.predict([\"\"\"This item is awful and terrible.\"\"\"])\n",
    "\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
