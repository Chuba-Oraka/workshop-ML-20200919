{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the S3 Location of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r scikit_processing_job_s3_output_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Previous Scikit Processing Job Name: {}'.format(scikit_processing_job_s3_output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_train = '{}/output/bert-train'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_validation = '{}/output/bert-validation'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_test = '{}/output/bert-test'.format(scikit_processing_job_s3_output_prefix)\n",
    "\n",
    "path_train = './{}'.format(prefix_train)\n",
    "path_validation = './{}'.format(prefix_validation)\n",
    "path_test = './{}'.format(prefix_test)\n",
    "\n",
    "train_s3_uri = 's3://{}/{}'.format(bucket, prefix_train)\n",
    "validation_s3_uri = 's3://{}/{}'.format(bucket, prefix_validation)\n",
    "test_s3_uri = 's3://{}/{}'.format(bucket, prefix_test)\n",
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=train_s3_uri) #, content_type='text/csv')\n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=validation_s3_uri) #, content_type='text/csv')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=test_s3_uri) #, content_type='text/csv')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat src_bert_tf/tf_bert_reviews.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "model_output_path = 's3://{}/models/tf-bert'.format(bucket)\n",
    "\n",
    "bert_estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                         source_dir='src_bert_tf',\n",
    "                         role=role,\n",
    "                         train_instance_count=1, # 1 is actually faster due to communication overhead with >1\n",
    "                         train_instance_type='ml.c5.18xlarge',\n",
    "                         py_version='py3',\n",
    "                         framework_version='1.15.2',\n",
    "                         output_path=model_output_path,\n",
    "#                         hyperparameters={'model_type':'bert',\n",
    "#                                          'model_name': 'bert-base-cased'},\n",
    "                         enable_cloudwatch_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_estimator.fit(inputs={'train': s3_input_train_data, \n",
    "                           'validation': s3_input_validation_data,}, \n",
    "                   wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = bert_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# bert_estimator = TensorFlow.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a> After About 5 Minutes</b>'.format(region, training_job_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(region, training_job_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# This is different than the job name because we are not using ProcessingOutput's in this Spark ML case.\n",
    "training_job_s3_output_prefix = 'models/tf-bert/script-mode/training-runs/{}'.format(training_job_name)\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>'.format(bucket, training_job_s3_output_prefix, region)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model artifact from AWS S3\n",
    "!aws s3 cp $model_output_path/$training_job_name/output/model.tar.gz ./models/bert-tf/\n",
    "\n",
    "#!aws s3 cp s3://sagemaker-us-east-1-835319576252/models/tf-bert/script-mode/training-runs/tensorflow-training-2020-03-24-04-41-39-405/output/model.tar.gz ./models/bert-tf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "tar = tarfile.open('./models/bert-tf/model.tar.gz')\n",
    "tar.extractall(path='./models/bert-tf-model')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ls -al ./models/bert-tf-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -al ./models/bert-tf-model/tf-bert-model-oh-yeah/1585283912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Must upgrade wrapt before installing TF\n",
    "!pip install -q wrapt --upgrade --ignore-installed\n",
    "!pip install -q tensorflow==1.15.2\n",
    "!pip install -q tensorflow-hub==0.7.0\n",
    "!pip install -q bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saved_model = tf.saved_model.load_v2(\n",
    "    './models/bert-tf-model/tf-bert-model-oh-yeah/1585283912',\n",
    "    tags=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference = saved_model.signatures[\"serving_default\"]\n",
    "print(inference.inputs)\n",
    "print(inference.structured_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import tokenization\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                                tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "        return tokenization.FullTokenizer(vocab_file=vocab_file,\n",
    "                                               do_lower_case=do_lower_case)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_features(features, seq_length):\n",
    "  all_input_ids = []\n",
    "  all_input_mask = []\n",
    "  all_segment_ids = []\n",
    "  all_label_ids = []\n",
    "\n",
    "  for feature in features:\n",
    "    all_input_ids.append(feature.input_ids)\n",
    "    all_input_mask.append(feature.input_mask)\n",
    "    all_segment_ids.append(feature.segment_ids)\n",
    "    all_label_ids.append(feature.label_id)\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "  num_examples = len(features)\n",
    "\n",
    "  # This is for demo purposes and does NOT scale to large data sets. We do\n",
    "  # not use Dataset.from_generator() because that uses tf.py_func which is\n",
    "  # not TPU compatible. The right way to load data is with TFRecordReader.\n",
    "#   d = tf.data.Dataset.from_tensor_slices({\n",
    "#     \"input_ids\":\n",
    "#         tf.constant(\n",
    "#             all_input_ids, shape=[num_examples, seq_length],\n",
    "#             dtype=tf.int32),\n",
    "#     \"input_mask\":\n",
    "#         tf.constant(\n",
    "#             all_input_mask,\n",
    "#             shape=[num_examples, seq_length],\n",
    "#             dtype=tf.int32),\n",
    "#     \"segment_ids\":\n",
    "#         tf.constant(\n",
    "#             all_segment_ids,\n",
    "#             shape=[num_examples, seq_length],\n",
    "#             dtype=tf.int32),\n",
    "#     \"label_ids\":\n",
    "#         tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "#   })\n",
    "\n",
    "#   d = d.batch(batch_size=batch_size, drop_remainder=False)\n",
    "\n",
    "#  return d\n",
    "\n",
    "  input_ids = tf.constant(\n",
    "             all_input_ids, shape=[num_examples, seq_length],\n",
    "             dtype=tf.int32)\n",
    "\n",
    "  input_mask = tf.constant(\n",
    "             all_input_mask,\n",
    "             shape=[num_examples, seq_length],\n",
    "             dtype=tf.int32)\n",
    "\n",
    "  segment_ids = tf.constant(\n",
    "             all_segment_ids,\n",
    "             shape=[num_examples, seq_length],\n",
    "             dtype=tf.int32)\n",
    "\n",
    "  label_ids = tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "\n",
    "  return input_ids, input_mask, segment_ids, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_bert_tf import amazon_run_classifier\n",
    "\n",
    "MAX_SEQ_LENGTH = 128\n",
    "LABEL_VALUES = [1, 2, 3, 4, 5]\n",
    "\n",
    "def predict(in_sentences):\n",
    "    tokenizer = create_tokenizer_from_hub_module()\n",
    "    print('**** TOKENIZER {}****'.format(tokenizer))\n",
    "    \n",
    "    input_examples = [amazon_run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = -1) for x in in_sentences]\n",
    "    input_features = amazon_run_classifier.convert_examples_to_features(input_examples, LABEL_VALUES, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "#    predict_input_fn = amazon_run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "#    predictions = estimator.predict(predict_input_fn)\n",
    "    input_ids, input_mask, segment_ids, label_ids = get_predict_features(input_features, MAX_SEQ_LENGTH)\n",
    "    print(type(input_ids))\n",
    "\n",
    "    inference(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids)\n",
    "\n",
    "    return [(sentence, prediction['probabilities'], LABEL_VALUES[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred_sentences = [\n",
    "  \"That movie was absolutely awful\",\n",
    "  \"The acting was a bit lacking\",\n",
    "  \"The film was creative and surprising\",\n",
    "  \"Absolutely fantastic!\"\n",
    "]\n",
    "\n",
    "np_list = np.asarray(pred_sentences)\n",
    "tensor_list = tf.convert_to_tensor(np_list)\n",
    "predictions = predict(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
