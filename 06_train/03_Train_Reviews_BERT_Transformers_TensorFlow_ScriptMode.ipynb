{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q smdebug==0.7.2\n",
    "!pip install -q sagemaker-experiments==0.1.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the S3 Location of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r scikit_processing_job_s3_output_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scikit_processing_job_s3_output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scikit_processing_job_s3_output_prefix = 'sagemaker-scikit-learn-2020-04-10-04-44-09-647'\n",
    "\n",
    "print('Previous Scikit Processing Job Name: {}'.format(scikit_processing_job_s3_output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_train = '{}/output/bert-train'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_validation = '{}/output/bert-validation'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_test = '{}/output/bert-test'.format(scikit_processing_job_s3_output_prefix)\n",
    "\n",
    "train_s3_uri = 's3://{}/{}'.format(bucket, prefix_train)\n",
    "validation_s3_uri = 's3://{}/{}'.format(bucket, prefix_validation)\n",
    "test_s3_uri = 's3://{}/{}'.format(bucket, prefix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_s3_uri)\n",
    "!aws s3 ls $train_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train_data = sagemaker.s3_input(s3_data=train_s3_uri, distribution='ShardedByS3Key') \n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=validation_s3_uri, distribution='ShardedByS3Key')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=test_s3_uri, distribution='ShardedByS3Key')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat src/tf_bert_reviews.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "train_steps_per_epoch=1000\n",
    "validation_steps=1000\n",
    "test_steps=1000\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.p3.2xlarge'\n",
    "train_volume_size=1024\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "max_seq_length=128\n",
    "freeze_bert_layer=True\n",
    "enable_sagemaker_debugger=True                    # Enable SM Debugger\n",
    "#use_parameter_server=(train_instance_count >= 2) # Use Parameter Server if distributed cluster\n",
    "input_mode='Pipe'                                 # 'File' or 'Pipe' Mode\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = '{}'.format(int(time.time()))\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "experiment=Experiment.create(\n",
    "    experiment_name='Train-Reviews-BERT-Experiment-{}'.format(timestamp),\n",
    "    description='Train Reviews BERT', \n",
    "    sagemaker_boto_client=sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.tracker import Tracker\n",
    "tracker_display_name='Train-Reviews-BERT-Experiment-{}'.format(timestamp)\n",
    "print(tracker_display_name)\n",
    "\n",
    "tracker = Tracker.create(display_name=tracker_display_name, sagemaker_boto_client=sm)\n",
    "tracker.log_parameters({\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': learning_rate,\n",
    "    'epsilon': epsilon,\n",
    "    'train_batch_size': train_batch_size,\n",
    "    'validation_batch_size': validation_batch_size,\n",
    "    'test_batch_size': test_batch_size,\n",
    "    'train_steps_per_epoch': train_steps_per_epoch,\n",
    "    'validation_steps': validation_steps,\n",
    "    'test_steps': test_steps,\n",
    "    'train_instance_count': train_instance_count,\n",
    "    'train_instance_type': train_instance_type,\n",
    "    'train_volume_size': train_volume_size,\n",
    "    'use_xla': use_xla,\n",
    "    'use_amp': use_amp,\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'freeze_bert_layer': freeze_bert_layer,\n",
    "    'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "#    'use_parameter_server': use_parameter_server,\n",
    "    'input_mode': input_mode, # 'File' or 'Pipe'\n",
    "    'run_validation': run_validation,\n",
    "    'run_test': run_test,\n",
    "    'run_sample_predictions': run_sample_predictions,    \n",
    "})\n",
    "# we can log the s3 uri to the dataset we just uploaded\n",
    "tracker.log_input(name='reviews_dataset_train', media_type='s3/uri', value=train_s3_uri)\n",
    "tracker.log_input(name='reviews_dataset_validation', media_type='s3/uri', value=validation_s3_uri)\n",
    "tracker.log_input(name='reviews_dataset_test', media_type='s3/uri', value=test_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.trial import Trial\n",
    "trial_name='Train-Reviews-BERT-Trial-{}'.format(timestamp)\n",
    "trial = Trial.create(trial_name=trial_name, experiment_name=experiment.experiment_name, sagemaker_boto_client=sm)\n",
    "trial.add_trial_component(tracker.trial_component)\n",
    "trial_component_display_name='Train-Reviews-BERT-Trial-{}'.format(timestamp)\n",
    "experiment_config={'ExperimentName': experiment.experiment_name,\n",
    "                   'TrialName': trial.trial_name,\n",
    "                   'TrialComponentDisplayName': trial_component_display_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Debugger\n",
    "Rules and the Keras Callback Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule\n",
    "from sagemaker.debugger import rule_configs\n",
    "from sagemaker.debugger import CollectionConfig\n",
    "from sagemaker.debugger import DebuggerHookConfig\n",
    "\n",
    "rules=[\n",
    "        Rule.sagemaker(\n",
    "            rule_configs.loss_not_decreasing(),\n",
    "            rule_parameters={\n",
    "                'collection_names': 'losses,metrics',\n",
    "                'use_losses_collection': 'true',\n",
    "                'num_steps': '10',\n",
    "                'diff_percent': '50'\n",
    "            },\n",
    "            collections_to_save=[\n",
    "                CollectionConfig(name='losses',\n",
    "                                 parameters={\n",
    "                                     'save_interval': '10',\n",
    "                                 }),\n",
    "                CollectionConfig(name='metrics',\n",
    "                                 parameters={\n",
    "                                     'save_interval': '10',\n",
    "                                 })\n",
    "            ]\n",
    "        ),\n",
    "        Rule.sagemaker(\n",
    "            rule_configs.overtraining(),\n",
    "            rule_parameters={\n",
    "                'collection_names': 'losses,metrics',\n",
    "                'patience_train': '10',\n",
    "                'patience_validation': '10',\n",
    "                'delta': '0.5'\n",
    "            },\n",
    "            collections_to_save=[\n",
    "                CollectionConfig(name='losses',\n",
    "                                 parameters={\n",
    "                                     'save_interval': '10',\n",
    "                                 }),\n",
    "                CollectionConfig(name='metrics',\n",
    "                                 parameters={\n",
    "                                     'save_interval': '10',\n",
    "                                 })\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        'save_interval': '10', # number of steps\n",
    "        'export_tensorboard': 'true',\n",
    "        'tensorboard_dir': 'hook_tensorboard/',\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Tensorflow Script Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       train_instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_volume_size=train_volume_size,\n",
    "                       py_version='py3',\n",
    "                       framework_version='2.1.0',\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "                                        'run_validation': run_validation,\n",
    "                                        'run_test': run_test,\n",
    "                                        'run_sample_predictions': run_sample_predictions},\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions,\n",
    "                       rules=rules,\n",
    "                       debugger_hook_config=hook_config,                       \n",
    "                       train_max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs={'train': s3_input_train_data, \n",
    "                      'validation': s3_input_validation_data,\n",
    "                      'test': s3_input_test_data\n",
    "                     },\n",
    "                     experiment_config=experiment_config,                   \n",
    "                     wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "print('Training Job Name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a> After About 5 Minutes</b>'.format(region, training_job_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(region, training_job_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Training Job Has Completed</b>'.format(bucket, training_job_name, region)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "# # Might need to convert ' => \"\n",
    "# search_expression = {\n",
    "#     'Filters':[\n",
    "#         {\n",
    "#             'Name': 'DisplayName',\n",
    "#             'Operator': 'Equals',\n",
    "#             'Value': 'Training'\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sess, \n",
    "    experiment_name=experiment.experiment_name,\n",
    "#    search_expression=search_expression,\n",
    "    sort_by='metrics.validation:accuracy.max',\n",
    "    sort_order='Descending',\n",
    "    metric_names=['validation:accuracy'],\n",
    "    parameter_names=['epochs', 'train_batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_table = trial_component_analytics.dataframe()\n",
    "analytics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search_expression={\n",
    "#     'Filters':[{\n",
    "#         'Name': 'Parents.TrialName',\n",
    "#         'Operator': 'Equals',\n",
    "#         'Value': ??\n",
    "#     }]\n",
    "# },\n",
    "\n",
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=sess,\n",
    "    experiment_name=experiment.experiment_name,\n",
    "#    search_expression=search_expression,\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")\n",
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Debugger Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Rule Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estimator.latest_training_job.rule_job_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before getting to analysis, here are some notes on concepts being used in Debugger that help with analysis.\n",
    "* **Trial** - object that is a center piece of Debugger API when it comes to getting access to tensors. It is a top level abstract that represents a single run of a training job. All tensors emitted by training job are associated with its trial.\n",
    "* **Step** - object that represents next level of abstraction. In Debugger - step is a representation of a single batch of a training job. Each trial has multiple steps. Each tensor is associated with multiple steps - having a particular value at each of the steps.\n",
    "* **Tensor** - object that represent actual tensor saved during training job. Note, a tensor can be a 1-D scaler, as well (ie. loss is stored as a scalar).\n",
    "\n",
    "For more details on these concepts as well as on Debugger API in general (including examples) please refer to Debugger Analysis API documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "# this is where we create a Trial object that allows access to saved tensors\n",
    "trial = create_trial(estimator.latest_job_debugger_artifacts_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trial.tensor_names():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data(trial, tensor_name, batch_index, steps_range, mode):\n",
    "    tensor = trial.tensor(tensor_name)\n",
    "    vals = []\n",
    "    for step_num in steps_range:\n",
    "        val = tensor.value(step_num=step_num, mode=mode)[batch_index]\n",
    "        vals.append(val)\n",
    "    return pd.DataFrame(columns=['steps', tensor_name], data=list(zip(steps_range, vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.tensorflow import modes\n",
    "\n",
    "# Below we select the very first tensor from every batch.\n",
    "# Feel free to modify this and select another tensor from the batch.\n",
    "batch_index = 0\n",
    "\n",
    "# This is a name of a tensor to analyze.\n",
    "tensor_name = 'accuracy'\n",
    "\n",
    "steps = 0\n",
    "while steps == 0:\n",
    "    # trial.steps return all steps that have been downloaded by Debugger to date.\n",
    "    # It doesn't represent all steps that are to be available once training job is complete -\n",
    "    # it is a snapshot of a current state of the training job. If you call it after training job is done\n",
    "    # you will get all tensors available at once.\n",
    "    steps = trial.steps()\n",
    "    print('Waiting for tensors to become available...')\n",
    "    time.sleep(3)\n",
    "print('\\nDone')\n",
    "\n",
    "print('Getting tensors...')\n",
    "rendered_steps = []\n",
    "\n",
    "# trial.loaded_all_steps is a way to keep monitoring for a state of a training job as seen by Debugger.\n",
    "# When SageMaker completes training job Debugger, and trial, becomes aware of it.\n",
    "\n",
    "loaded_all_steps = False\n",
    "while not loaded_all_steps:\n",
    "    loaded_all_steps = trial.loaded_all_steps\n",
    "    steps = trial.steps()\n",
    "    # show diff between lists\n",
    "    steps_to_render = list(set(steps).symmetric_difference(set(rendered_steps)))\n",
    "    \n",
    "    data = get_data(trial=trial, \n",
    "                    tensor_name=tensor_name, \n",
    "                    batch_index=0, \n",
    "                    steps_range=steps_to_render, \n",
    "                    mode=modes.GLOBAL)\n",
    "    print(data)\n",
    "    data.plot(x='steps', y=tensor_name)\n",
    "    \n",
    "    rendered_steps.extend(steps_to_render)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.tensorflow import modes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Let's visualize weights of the first convolutional layer as they progressively change through training.\n",
    "tensor_name = 'loss'\n",
    "\n",
    "num_batches = trial.tensor(tensor_name).value(step_num=steps[0]).shape[0]\n",
    "for batch_index in range(0, num_batches):\n",
    "    steps_range = trial.tensor(tensor_name).steps()\n",
    "    print(steps_range)\n",
    "    data = get_data(trial=trial, \n",
    "                    tensor_name=tensor_name, \n",
    "                    batch_index=batch_index, \n",
    "                    steps_range=steps_range, \n",
    "                    mode=modes.GLOBAL)\n",
    "    print(data)\n",
    "    data.plot(x='steps', y=tensor_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.tensorflow import modes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tensor_name = 'accuracy'\n",
    "\n",
    "num_batches = trial.tensor(tensor_name).value(step_num=steps[0]).shape[0]\n",
    "for batch_index in range(0, num_batches):\n",
    "    steps_range = trial.tensor(tensor_name).steps()\n",
    "    print(steps_range)\n",
    "    data = get_data(trial=trial, \n",
    "                    tensor_name=tensor_name, \n",
    "                    batch_index=batch_index, \n",
    "                    steps_range=steps_range, \n",
    "                    mode=modes.GLOBAL)\n",
    "    print(data)\n",
    "    data.plot(x='steps', y=tensor_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Lambda Function to Stop the TrainingJob Early\n",
    "In your AWS console, go to Lambda Management Console,\n",
    "Create a new function by hitting Create Function,\n",
    "Choose the language as Python 3.7 and put in the following sample code for stopping the training job if one of the Rule statuses is \"IssuesFound\".\n",
    "\n",
    "### CloudWatch Events for Rules\n",
    "Rule status changes in a training job trigger CloudWatch Events. These events can be acted upon by configuring a CloudWatch Rule (different from Amazon SageMaker Debugger Rule) to trigger each time a Debugger Rule changes status. In this notebook we'll go through how you can create a CloudWatch Rule to direct Training Job State change events to a lambda function that stops the training job in case a rule triggers and has status \"IssuesFound\".\n",
    "\n",
    "Create a new execution role for the Lambda, and\n",
    "In your IAM console, search for the role and attach \"AmazonSageMakerFullAccess\" policy to the role. This is needed for the code in your Lambda function to stop the training job.\n",
    "\n",
    "\n",
    "### Create a CloudWatch Rule to Trigger a Lamba\n",
    "In your AWS Console, go to CloudWatch and select Rule from the left column,\n",
    "Hit Create Rule. The console will redirect you to the Rule creation page,\n",
    "For the Service Name, select \"SageMaker\".\n",
    "For the Event Type, select \"SageMaker Training Job State Change\".\n",
    "In the Targets select the Lambda function you created above, and\n",
    "For this example notebook, we'll leave everything as is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    training_job_name = event.get(\"detail\").get(\"TrainingJobName\")\n",
    "    eval_statuses = event.get(\"detail\").get(\"DebugRuleEvaluationStatuses\", None)\n",
    "\n",
    "    if eval_statuses is None or len(eval_statuses) == 0:\n",
    "        logging.info(\"Couldn't find any debug rule statuses, skipping...\")\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps('Nothing to do')\n",
    "        }\n",
    "\n",
    "    client = boto3.client('sagemaker')\n",
    "\n",
    "    for status in eval_statuses:\n",
    "        if status.get(\"RuleEvaluationStatus\") == \"IssuesFound\":\n",
    "            logging.info(\n",
    "                'Evaluation of rule configuration {} resulted in \"IssuesFound\". '\n",
    "                'Attempting to stop training job {}'.format(\n",
    "                    status.get(\"RuleConfigurationName\"), training_job_name\n",
    "                )\n",
    "            )\n",
    "            try:\n",
    "                client.stop_training_job(\n",
    "                    TrainingJobName=training_job_name\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logging.error(\n",
    "                    \"Encountered error while trying to \"\n",
    "                    \"stop training job {}: {}\".format(\n",
    "                        training_job_name, str(e)\n",
    "                    )\n",
    "                )\n",
    "                raise e\n",
    "    return None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a new execution role for the Lambda, and\n",
    "* In your IAM console, search for the role and attach \"AmazonSageMakerFullAccess\" policy to the role. This is needed for the code in your Lambda function to stop the training job.\n",
    "\n",
    "#### Create a CloudWatch Rule\n",
    "\n",
    "* In your AWS Console, go to CloudWatch and select Rule from the left column,\n",
    "* Hit Create Rule. The console will redirect you to the Rule creation page,\n",
    " * For the Service Name, select \"SageMaker\".\n",
    " * For the Event Type, select \"SageMaker Training Job State Change\".\n",
    "* In the Targets select the Lambda function you created above, and\n",
    "* For this example notebook, we'll leave everything as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker kicked off rule evaluation jobs, one for each of the SageMaker rules - `Overtraining` and `LossNotDecreasing` as specified in the estimator. If we setup a CloudWatch Rule to stop the training job, we would see the `TrainingJobStatus` change to `Stopped` once the `RuleEvaluationStatus` for changes to `IssuesFound`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This utility gives the link to monitor the CW event\n",
    "# def _get_rule_job_name(training_job_name, rule_configuration_name, rule_job_arn):\n",
    "#         \"\"\"Helper function to get the rule job name\"\"\"\n",
    "#         return \"{}-{}-{}\".format(\n",
    "#             training_job_name[:26], rule_configuration_name[:26], rule_job_arn[-8:]\n",
    "#         )\n",
    "    \n",
    "# def _get_cw_url_for_rule_job(rule_job_name, region):\n",
    "#     return \"https://{}.console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\".format(region, region, rule_job_name)\n",
    "\n",
    "\n",
    "# def get_rule_jobs_cw_urls(estimator):\n",
    "#     region = boto3.Session().region_name\n",
    "#     training_job = estimator.latest_training_job\n",
    "#     training_job_name = training_job.describe()[\"TrainingJobName\"]\n",
    "#     rule_eval_statuses = training_job.describe()[\"DebugRuleEvaluationStatuses\"]\n",
    "    \n",
    "#     result={}\n",
    "#     for status in rule_eval_statuses:\n",
    "#         if status.get(\"RuleEvaluationJobArn\", None) is not None:\n",
    "#             rule_job_name = _get_rule_job_name(training_job_name, status[\"RuleConfigurationName\"], status[\"RuleEvaluationJobArn\"])\n",
    "#             result[status[\"RuleConfigurationName\"]] = _get_cw_url_for_rule_job(rule_job_name, region)\n",
    "#     return result\n",
    "\n",
    "# get_rule_jobs_cw_urls(estimator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
