{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/train', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/validation', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "prefix_train = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/train'\n",
    "prefix_validation = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/validation'\n",
    "prefix_test = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_train_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_train)\n",
    "#balanced_tfidf_without_header_train_s3_uri = 's3://{}/{}'.format(bucket, prefix_train)\n",
    "balanced_tfidf_without_header_validation_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_validation)\n",
    "#balanced_tfidf_without_header_validation_s3_uri = 's3://{}/{}'.format(bucket, prefix_validation)\n",
    "balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_test)\n",
    "#balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}'.format(bucket, prefix_test)\n",
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_train_s3_uri, content_type='text/csv')\n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_validation_s3_uri, content_type='text/csv')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_test_s3_uri, content_type='text/csv')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3\n",
      "s3://sagemaker-us-east-1-835319576252/models/built-in/training-runs\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri \n",
    "\n",
    "# get the URI for new container\n",
    "builtin_container_uri = get_image_uri(region_name=region,                                \n",
    "                                      repo_name='xgboost', \n",
    "                                      repo_version='0.90-2')\n",
    "print(builtin_container_uri)\n",
    "\n",
    "model_output_path = 's3://{}/models/built-in/training-runs'.format(bucket)\n",
    "print(model_output_path)\n",
    "\n",
    "xgb_estimator = sagemaker.estimator.Estimator(image_name=builtin_container_uri, \n",
    "                                              role=role, \n",
    "                                              train_instance_count=1, \n",
    "                                              train_instance_type='ml.m4.xlarge', \n",
    "                                              output_path=model_output_path, \n",
    "                                              sagemaker_session=sess,\n",
    "                                              #enable_cloudwatch_metrics=True\n",
    "                                             )\n",
    "\n",
    "xgb_estimator.set_hyperparameters(objective='binary:logistic',\n",
    "                                  num_round=1,\n",
    "                                  max_depth=5,\n",
    "                                  eval_metric='auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-06 07:41:32 Starting - Starting the training job...\n",
      "2020-03-06 07:41:35 Starting - Launching requested ML instances......\n",
      "2020-03-06 07:42:44 Starting - Preparing the instances for training......\n",
      "2020-03-06 07:43:37 Downloading - Downloading input data...\n",
      "2020-03-06 07:44:16 Training - Downloading the training image..\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:44:40] 64108x300 matrix with 19232400 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:44:40] 1781x300 matrix with 534300 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 64108 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 1781 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.828989#011validation-auc:0.658473\u001b[0m\n",
      "\n",
      "2020-03-06 07:44:54 Uploading - Uploading generated training model\n",
      "2020-03-06 07:44:54 Completed - Training job completed\n",
      "Training seconds: 77\n",
      "Billable seconds: 77\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.fit({'train': s3_input_train_data,\n",
    "                   'validation': s3_input_validation_data\n",
    "                  }\n",
    "                  #, wait=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_job_name:  sagemaker-xgboost-2020-03-06-07-41-32-557\n"
     ]
    }
   ],
   "source": [
    "training_job_name = xgb_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  This is broken\n",
    "#from sagemaker.xgboost import XGBoost\n",
    "\n",
    "#xgb_estimator = XGBoost.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Calculate Test Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2.7 KiB/2.7 KiB (40.4 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-1-835319576252/models/built-in/training-runs/sagemaker-xgboost-2020-03-06-07-41-32-557/output/model.tar.gz to models/built-in/model.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "# download the model artifact from AWS S3\n",
    "!aws s3 cp $model_output_path/$training_job_name/output/model.tar.gz ./models/built-in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "# TODO:  extract to ./model/built-in/\n",
    "\n",
    "#opens the downloaded model artifcat and loads it as 'model' variable\n",
    "tar = tarfile.open('./models/built-in/model.tar.gz')\n",
    "tar.extractall(path='./models/built-in/')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Mar  6 07:45 .\r\n",
      "drwxrwxr-x 4 ec2-user ec2-user 4096 Mar  5 06:37 ..\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 2763 Mar  6 07:44 model.tar.gz\r\n",
      "-rw-r--r-- 1 ec2-user ec2-user 6345 Mar  6 07:44 xgboost-model\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./models/built-in/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restored = pkl.load(open('./models/built-in/xgboost-model', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/csv/balanced-tfidf-without-header/data.csv\n",
    "\n",
    "prefix_test = 'feature-store/amazon-reviews/csv/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_test_path = './{}/data.csv'.format(prefix_test)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix_test, exist_ok=True)\n",
    "\n",
    "balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $balanced_tfidf_without_header_test_s3_uri $balanced_tfidf_without_header_test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, sep, header):\n",
    "    data = pd.read_csv(path, sep=sep, header=header)\n",
    "\n",
    "    labels = data.iloc[:,0]\n",
    "    features = data.drop(data.columns[0], axis=1)\n",
    "    \n",
    "    if header==None:\n",
    "        # Adjust the column names after dropped the 0th column above\n",
    "        # New column names are 0 (inclusive) to len(features.columns) (exclusive)\n",
    "        new_column_names = list(range(0, len(features.columns)))\n",
    "        features.columns = new_column_names\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_dataset(path=balanced_tfidf_without_header_test_path, sep=',', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.634733</td>\n",
       "      <td>-0.247392</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>-0.523243</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>-0.448801</td>\n",
       "      <td>-0.204092</td>\n",
       "      <td>-0.238300</td>\n",
       "      <td>-0.261760</td>\n",
       "      <td>-0.219047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>-0.557045</td>\n",
       "      <td>-0.381416</td>\n",
       "      <td>-0.103129</td>\n",
       "      <td>-0.209871</td>\n",
       "      <td>-0.556612</td>\n",
       "      <td>1.304991</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>1.384731</td>\n",
       "      <td>-0.083465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.258064</td>\n",
       "      <td>-1.061612</td>\n",
       "      <td>-0.027788</td>\n",
       "      <td>-0.435960</td>\n",
       "      <td>0.519479</td>\n",
       "      <td>-0.291335</td>\n",
       "      <td>0.263390</td>\n",
       "      <td>-0.780300</td>\n",
       "      <td>-0.411519</td>\n",
       "      <td>-0.517505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080147</td>\n",
       "      <td>0.484613</td>\n",
       "      <td>0.113549</td>\n",
       "      <td>-0.315451</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>-2.017522</td>\n",
       "      <td>0.042569</td>\n",
       "      <td>-0.315694</td>\n",
       "      <td>-1.637476</td>\n",
       "      <td>1.099162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.123441</td>\n",
       "      <td>-0.381155</td>\n",
       "      <td>0.220870</td>\n",
       "      <td>-0.306529</td>\n",
       "      <td>0.295466</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>0.808974</td>\n",
       "      <td>-0.886816</td>\n",
       "      <td>-0.537187</td>\n",
       "      <td>-1.609552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907523</td>\n",
       "      <td>-1.370449</td>\n",
       "      <td>-0.497941</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.229369</td>\n",
       "      <td>-0.549921</td>\n",
       "      <td>-0.901384</td>\n",
       "      <td>0.611026</td>\n",
       "      <td>0.231871</td>\n",
       "      <td>-1.763118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.085429</td>\n",
       "      <td>-0.558576</td>\n",
       "      <td>-0.111424</td>\n",
       "      <td>-0.648954</td>\n",
       "      <td>-0.045818</td>\n",
       "      <td>-0.389012</td>\n",
       "      <td>-0.304378</td>\n",
       "      <td>-0.226467</td>\n",
       "      <td>0.129833</td>\n",
       "      <td>-0.374666</td>\n",
       "      <td>...</td>\n",
       "      <td>1.990565</td>\n",
       "      <td>0.674278</td>\n",
       "      <td>1.541115</td>\n",
       "      <td>-1.362709</td>\n",
       "      <td>-0.785404</td>\n",
       "      <td>2.047984</td>\n",
       "      <td>0.874032</td>\n",
       "      <td>-0.547825</td>\n",
       "      <td>-0.133409</td>\n",
       "      <td>0.407323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943603</td>\n",
       "      <td>-0.748338</td>\n",
       "      <td>-0.302065</td>\n",
       "      <td>-0.454148</td>\n",
       "      <td>-0.777959</td>\n",
       "      <td>-1.025572</td>\n",
       "      <td>-0.138429</td>\n",
       "      <td>0.392192</td>\n",
       "      <td>-0.901120</td>\n",
       "      <td>0.385676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.930250</td>\n",
       "      <td>1.317045</td>\n",
       "      <td>-1.353617</td>\n",
       "      <td>0.330193</td>\n",
       "      <td>-0.600254</td>\n",
       "      <td>0.714468</td>\n",
       "      <td>-1.320635</td>\n",
       "      <td>-2.121154</td>\n",
       "      <td>-0.086226</td>\n",
       "      <td>-0.318210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.634733 -0.247392  0.069444 -0.523243 -0.004713 -0.448801 -0.204092   \n",
       "1  1.258064 -1.061612 -0.027788 -0.435960  0.519479 -0.291335  0.263390   \n",
       "2 -0.123441 -0.381155  0.220870 -0.306529  0.295466  0.015603  0.808974   \n",
       "3 -0.085429 -0.558576 -0.111424 -0.648954 -0.045818 -0.389012 -0.304378   \n",
       "4  0.943603 -0.748338 -0.302065 -0.454148 -0.777959 -1.025572 -0.138429   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.238300 -0.261760 -0.219047  ...  0.164698 -0.557045 -0.381416 -0.103129   \n",
       "1 -0.780300 -0.411519 -0.517505  ... -0.080147  0.484613  0.113549 -0.315451   \n",
       "2 -0.886816 -0.537187 -1.609552  ...  0.907523 -1.370449 -0.497941 -0.000245   \n",
       "3 -0.226467  0.129833 -0.374666  ...  1.990565  0.674278  1.541115 -1.362709   \n",
       "4  0.392192 -0.901120  0.385676  ... -0.930250  1.317045 -1.353617  0.330193   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.209871 -0.556612  1.304991  0.499820  1.384731 -0.083465  \n",
       "1  0.965301 -2.017522  0.042569 -0.315694 -1.637476  1.099162  \n",
       "2 -0.229369 -0.549921 -0.901384  0.611026  0.231871 -1.763118  \n",
       "3 -0.785404  2.047984  0.874032 -0.547825 -0.133409  0.407323  \n",
       "4 -0.600254  0.714468 -1.320635 -2.121154 -0.086226 -0.318210  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import xgboost\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgboost.plot_importance(model_restored, \n",
    "                        importance_type='gain', \n",
    "                        max_num_features=30, \n",
    "                        height=0.8, \n",
    "                        ax=ax, \n",
    "                        show_values = True)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must convert pandas dataframe to XGBoost DMatrix before predicting\n",
    "preds_test = model_restored.predict(xgboost.DMatrix(X_test.values))\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert regression values into classification (0 or 1) using threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds_test_0_or_1 = np.where(preds_test > 0.5, 1, 0)\n",
    "preds_test_0_or_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "print('Test Accuracy: ', accuracy_score(y_test, preds_test_0_or_1))\n",
    "print('Test Precision: ', precision_score(y_test, preds_test_0_or_1, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds_test_0_or_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_test = confusion_matrix(y_test, preds_test_0_or_1)\n",
    "df_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "def plot_conf_mat(cm, classes, title, cmap = plt.cm.Greens):\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plot_conf_mat(df_cm_test, classes=['Not Positive Sentiment', 'Positive Sentiment'], \n",
    "                          title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "auc = round(metrics.roc_auc_score(y_test, preds_test_0_or_1), 4)\n",
    "print('AUC is ' + repr(auc))\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds_test_0_or_1)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the Hyperparameter Tuner\n",
    "from sagemaker.tuner import IntegerParameter\n",
    "from sagemaker.tuner import ContinuousParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "# Define exploration boundaries (default suggested values from Amazon SageMaker Documentation)\n",
    "hyperparameter_ranges = {\n",
    "    'alpha': ContinuousParameter(0, 1000, scaling_type=\"Auto\"),\n",
    "    'colsample_bylevel': ContinuousParameter(0.1, 1,scaling_type=\"Logarithmic\"),\n",
    "    'colsample_bytree': ContinuousParameter(0.5, 1, scaling_type='Logarithmic'),\n",
    "    'eta': ContinuousParameter(0.1, 0.5, scaling_type='Logarithmic'),\n",
    "    'gamma':ContinuousParameter(0, 5, scaling_type='Auto'),\n",
    "    'lambda': ContinuousParameter(0,100,scaling_type='Auto'),\n",
    "    'max_delta_step': IntegerParameter(0,10,scaling_type='Auto'),\n",
    "    'max_depth': IntegerParameter(0,10,scaling_type='Auto'),\n",
    "    'min_child_weight': ContinuousParameter(0,10,scaling_type='Auto'),\n",
    "    'num_round': IntegerParameter(1,4000,scaling_type='Auto'),\n",
    "    'subsample': ContinuousParameter(0.5,1,scaling_type='Logarithmic')}\n",
    "\n",
    "objective_metric_name = 'validation:auc'\n",
    "\n",
    "tuner_log = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=60,\n",
    "    max_parallel_jobs=10,\n",
    "    strategy='Bayesian'\n",
    ")\n",
    "\n",
    "## Starts the hyperparameter tuning job\n",
    "tuner_log.fit({'train': balanced_tfidf_without_header_train_s3_uri, \n",
    "               'validation': balanced_tfidf_without_header_validation_s3_uri}, \n",
    "               include_cls_metadata=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prints the status of the latest hyperparameter tuning job\n",
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner_log.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From an external application, you can use the following code to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "xgb_endpoint_name = 'xgboost-built-in-{}'.format(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime()))\n",
    "xgb_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deploy trained XGBoost model endpoint to perform predictions\n",
    "xgb_predictor = xgb_estimator.deploy(initial_instance_count = 1, \n",
    "                                     instance_type = 'ml.m4.xlarge',\n",
    "                                     endpoint_name=xgb_endpoint_name)\n",
    "\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "payload_500_samples = X_test[:500].to_csv(index=False, header=False).rstrip()\n",
    "\n",
    "response_500_samples = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=xgb_endpoint_name,\n",
    "    Body=payload.encode('utf-8'),\n",
    "    ContentType='text/csv')['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_500_samples = np.fromstring(response_500_samples, sep=',')\n",
    "predictions_500_samples_0_or_1 = np.where(predictions_500_samples > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Accuracy: ', accuracy_score(y_test[:500], predictions_500_samples_0_or_1))\n",
    "print('Test Precision: ', precision_score(y_test[:500], predictions_500_samples_0_or_1, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm_test = confusion_matrix(y_test[:500], predictions_500_samples_0_or_1)\n",
    "df_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "def plot_conf_mat(cm, classes, title, cmap = plt.cm.Greens):\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "plot_conf_mat(df_cm_test, classes=['Not Positive Sentiment', 'Positive Sentiment'], \n",
    "                          title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "auc = round(metrics.roc_auc_score(y_test, preds_test), 4)\n",
    "print('AUC is ' + repr(auc))\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, preds_test)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr, tpr, 'b',\n",
    "label='AUC = %0.2f'% auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  XGBoostPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  1) update this to do TF/IDF\n",
    "#        2) use this in other versions of the model\n",
    "# Derived from the following:\n",
    "#   https://aim357.readthedocs.io/en/latest/GluePySparkMLFeatureEngineering/GluePySparkMLFeatureEngineering.html#deepar-deep-dive\n",
    "\n",
    "class XGBoostPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "\n",
    "    def predict(self, ts, cat=None, dynamic_feat=None,\n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + 1\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "\n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "\n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "\n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "\n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)\n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "\n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]\n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_endpoint_name = prefix + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "xgb_predictor = xgb_estimator.deploy(\n",
    "                     initial_instance_count=1, \n",
    "                     instance_type='ml.m4.xlarge',\n",
    "                     predictor_cls=XGBoostPredictor,\n",
    "                     endpoint_name=xgb_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict([\"\"\"Very funny. A typical mid 50's comedy.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = bert_model.predict([\"\"\"That movie was absolutely awful.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
