{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "#!pip install -q scikit-learn==0.20.3\n",
    "#!pip install -q nltk==3.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy the datasets from S3 to this notebook instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $S3_BUCKET/feature-store/amazon-reviews/balanced-tfidf-without-header/data.csv\n",
    "\n",
    "prefix_train = 'feature-store/amazon-reviews/balanced-tfidf-without-header/train'\n",
    "prefix_validation = 'feature-store/amazon-reviews/balanced-tfidf-without-header/validation'\n",
    "prefix_test = 'feature-store/amazon-reviews/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_train_path = './{}/data.csv'.format(prefix_train)\n",
    "balanced_tfidf_without_header_validation_path = './{}/data.csv'.format(prefix_validation)\n",
    "balanced_tfidf_without_header_test_path = './{}/data.csv'.format(prefix_test)\n",
    "\n",
    "import os\n",
    "os.makedirs(prefix_train, exist_ok=True)\n",
    "os.makedirs(prefix_validation, exist_ok=True)\n",
    "os.makedirs(prefix_test, exist_ok=True)\n",
    "\n",
    "balanced_tfidf_without_header_train_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_train)\n",
    "balanced_tfidf_without_header_validation_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_validation)\n",
    "balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $balanced_tfidf_without_header_train_s3_uri $balanced_tfidf_without_header_train_path\n",
    "!aws s3 cp $balanced_tfidf_without_header_validation_s3_uri $balanced_tfidf_without_header_validation_path\n",
    "!aws s3 cp $balanced_tfidf_without_header_test_s3_uri $balanced_tfidf_without_header_test_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, sep):\n",
    "    data = pd.read_csv(path, sep=sep)\n",
    "\n",
    "    labels = data['is_positive_sentiment']\n",
    "    features = data.drop(['is_positive_sentiment'], axis=1)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "This may take a few minutes.  Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective  = 'binary:logistic'\n",
    "max_depth  = 5\n",
    "num_round  = 1\n",
    "\n",
    "# Load transformed features (is_positive_sentiment, f0, f1, ...)\n",
    "X_train, y_train = load_dataset(balanced_tfidf_without_header_train_path, ',')\n",
    "X_validation, y_validation = load_dataset(balanced_tfidf_without_header_validation_path, ',')\n",
    "X_test, y_test = load_dataset(balanced_tfidf_without_header_test_path, ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q xgboost==0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "_This will take a few minutes.  Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(objective=objective,\n",
    "                           num_round=num_round,\n",
    "                           max_depth=max_depth)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "# See https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
    "# Need to save with joblib or pickle.  `xgb.save_model()` does not save feature_names\n",
    "# TODO:  use pickle\n",
    "model_dir  = './model/notebook/'\n",
    "model_path = os.path.join(model_dir, 'xgboost-model')\n",
    "\n",
    "pkl.dump(model, open(model_path, 'wb'))\n",
    "\n",
    "print('Wrote model to {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the feature importance for this model\n",
    "TODO:  Display the values of the features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgboost.plot_importance(model, importance_type='gain', max_num_features=30, height=0.8, ax=ax, show_values = True)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  Explain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Model \n",
    "This simulates restoring a model within an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model_path = os.path.join(model_dir, 'xgboost-model')\n",
    "    model = pkl.load(open(model_path, 'rb'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restored = model_fn(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  Perform hyperparamter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "auc = model_restored.score(X_validation, y_validation)\n",
    "print('Validation AUC: ', auc)\n",
    "\n",
    "preds_validation = model_restored.predict(X_validation)\n",
    "print('Validation Accuracy: ', accuracy_score(y_validation, preds_validation))\n",
    "print('Validation Precision: ', precision_score(y_validation, preds_validation, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_validation, preds_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm_validation = confusion_matrix(y_validation, preds_validation)\n",
    "\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm_validation, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "# TODO:  Add labels to each quadrant (False, True / False, True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "auc = model_restored.score(X_test, y_test)\n",
    "print('Test AUC ', auc)\n",
    "\n",
    "preds_test = model_restored.predict(X_test)\n",
    "print('Test Accuracy: ', accuracy_score(y_test, preds_test))\n",
    "print('Test Precision: ', precision_score(y_test, preds_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm_test = confusion_matrix(y_test, preds_test)\n",
    "\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4) # for label size\n",
    "sn.heatmap(df_cm_test, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "# TODO:  Add labels to each quadrant (False, True / False, True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  Deploy the model\n",
    "1. Create a SageMaker endpoint using this model.\n",
    "\n",
    "2. Define the predict function to transform raw text into TF/IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
