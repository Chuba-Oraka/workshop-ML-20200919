{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these posts: \n",
    "* https://medium.com/@chrisfotache/text-classification-in-python-pipelines-nlp-nltk-tf-idf-xgboost-and-more-b83451a327e0\n",
    "* https://github.com/keisukeirie/Amazon_review_helpfulness_prediction\n",
    "* https://stackabuse.com/text-classification-with-bert-tokenizer-and-tf-2-0-in-python/\n",
    "* https://towardsdatascience.com/simple-bert-using-tensorflow-2-0-132cb19e9b22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/balanced-tfidf-without-header/train/data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/balanced-tfidf-without-header/validation/data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/feature-store/amazon-reviews/balanced-tfidf-without-header/test/data.csv', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "prefix_train = 'feature-store/amazon-reviews/balanced-tfidf-without-header/train'\n",
    "prefix_validation = 'feature-store/amazon-reviews/balanced-tfidf-without-header/validation'\n",
    "prefix_test = 'feature-store/amazon-reviews/balanced-tfidf-without-header/test'\n",
    "\n",
    "balanced_tfidf_without_header_train_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_train)\n",
    "balanced_tfidf_without_header_validation_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_validation)\n",
    "balanced_tfidf_without_header_test_s3_uri = 's3://{}/{}/data.csv'.format(bucket, prefix_test)\n",
    "\n",
    "s3_input_train_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_train_s3_uri, content_type='text/csv')\n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_validation_s3_uri, content_type='text/csv')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=balanced_tfidf_without_header_test_s3_uri, content_type='text/csv')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os, argparse, pickle\r\n",
      "import pandas as pd\r\n",
      "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\r\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
      "import nltk\r\n",
      "import re\r\n",
      "import xgboost as xgb\r\n",
      "from xgboost import XGBClassifier\r\n",
      "\r\n",
      "\r\n",
      "def load_dataset(path, sep):\r\n",
      "    data = pd.read_csv(path, sep=sep)\r\n",
      "\r\n",
      "    labels = data['is_positive_sentiment']\r\n",
      "    features = data.drop(['is_positive_sentiment'], axis=1)\r\n",
      "\r\n",
      "    return features, labels\r\n",
      "\r\n",
      "\r\n",
      "def model_fn(model_dir):\r\n",
      "    model = xgb.Booster()\r\n",
      "    model.load_model(os.path.join(model_dir, 'xgboost_reviews.model'))\r\n",
      "\r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument('--objective', type=str, default='binary:logistic')\r\n",
      "    parser.add_argument('--max-depth', type=int, default=5)\r\n",
      "    parser.add_argument('--num-round', type=int, default=1)   \r\n",
      "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\r\n",
      "    parser.add_argument('--train-data', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\r\n",
      "    parser.add_argument('--validation-data', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\r\n",
      "   \r\n",
      "    args, _ = parser.parse_known_args()   \r\n",
      "    objective  = args.objective    \r\n",
      "    max_depth  = args.max_depth\r\n",
      "    num_round  = args.num_round\r\n",
      "    model_dir  = args.model_dir\r\n",
      "    train_data   = args.train_data\r\n",
      "    validation_data = args.validation_data\r\n",
      "    \r\n",
      "    # Load transformed features (is_positive_sentiment, f0, f1, ...)    \r\n",
      "    X_train, y_train = load_dataset(train_data, ',')\r\n",
      "    X_validation, y_validation = load_dataset(validation_data, ',')\r\n",
      "                \r\n",
      "    classifier = XGBClassifier(objective=objective, \r\n",
      "                               num_round=num_round,\r\n",
      "                               max_depth=max_depth)\r\n",
      "    \r\n",
      "    classifier.fit(X_train, y_train)\r\n",
      "\r\n",
      "    # See https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\r\n",
      "    classifier.save_model(os.path.join(model_dir, 'xgboost_reviews.model'))\r\n",
      "    \r\n",
      "    auc = classifier.score(X_validation, y_validation)\r\n",
      "    print(\"AUC \", auc)\r\n",
      "   \r\n",
      "    preds = classifier.predict(X_validation)\r\n",
      "    print('Accuracy: ', accuracy_score(y_validation, preds))\r\n",
      "    print('Precision: ', precision_score(y_validation, preds, average=None))\r\n",
      "\r\n",
      "    model_restored = model_fn('.')\r\n",
      "    preds_restored = model_restored.predict(X_validation)\r\n",
      "\r\n",
      "    print('Accuracy: ', accuracy_score(y_validation, preds_restored))\r\n",
      "    print('Precision: ', precision_score(y_validation, preds_restored, average=None))\r\n"
     ]
    }
   ],
   "source": [
    "!cat src/xgboost_reviews.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "model_output_path = 's3://{}/sagemaker/xgboost/training-runs'.format(bucket)\n",
    "\n",
    "xgb_estimator = XGBoost(entry_point='xgboost_reviews.py', \n",
    "                        source_dir='src/',\n",
    "                        role=role,\n",
    "                        train_instance_count=1, \n",
    "#                        train_instance_type='local',\n",
    "                        train_instance_type='ml.m4.xlarge',\n",
    "                        framework_version='0.90-2',\n",
    "                        py_version='py3',\n",
    "                        output_path=model_output_path,\n",
    "                        hyperparameters={'objective':'binary:logistic',\n",
    "                                         'num_round': 1,\n",
    "                                         'max_depth': 5}                                         \n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator.fit(inputs={'train': s3_input_train_data, \n",
    "                          'validation': s3_input_validation_data}, wait=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name = xgb_estimator.latest_training_job.name\n",
    "print('training_job_name:  {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "xgb_estimator = XGBoost.attach(training_job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  FIx prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_endpoint_name = prefix + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "xgb_predictor = xgb_estimator.deploy(\n",
    "                     initial_instance_count=1, \n",
    "                     instance_type='ml.m4.xlarge',\n",
    "                     endpoint_name=xgb_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# TODO:  Fix this...\n",
    "sm_rt = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Predict a sample from the validation set\n",
    "payload = df_validation[:1].drop(['is_positive_sentiment'], axis=1) \n",
    "payload = payload.to_csv(header=False, index=False).rstrip()\n",
    "\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_rt.invoke_endpoint(\n",
    "    EndpointName=xgb_endpoint_name,\n",
    "    Body=payload.encode('utf8'),\n",
    "    ContentType='text/csv')\n",
    "\n",
    "print(response['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to delete the endpoint!\n",
    "# sagemaker_session.delete_endpoint(endpoint_name=xgb_endpoint_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = xgb_predictor.predict([\"\"\"Very funny. A typical mid 50's comedy.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = xgb_predictor.predict([\"\"\"That movie was absolutely awful.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
