{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TensorFlow-Trained BERT Model to a PyTorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install TensorFlow and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: awscli 1.18.39 has requirement botocore==1.15.39, but you'll have botocore 1.17.14 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mERROR: awscli 1.18.39 has requirement rsa<=3.5.0,>=3.1.2, but you'll have rsa 4.6 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow==2.1.0 --upgrade --ignore-installed\n",
    "!pip install -q torch==1.5.0 --upgrade --ignore-installed\n",
    "!pip install -q transformers==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchserve\n",
      "  Downloading torchserve-0.1.1-py2.py3-none-any.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 18.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch-model-archiver\n",
      "  Downloading torch_model_archiver-0.1.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchserve) (0.18.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchserve) (5.4.5)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torchserve) (5.1.0)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Installing collected packages: torchserve, enum-compat, torch-model-archiver\n",
      "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.1.1 torchserve-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchserve torch-model-archiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the Training Job Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous training_job_name: tensorflow-training-2020-06-30-21-24-43-479\n"
     ]
    }
   ],
   "source": [
    "print('Previous training_job_name: {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the TensorFlow-Trained Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal error: Parameter validation failed:\r\n",
      "Invalid bucket name \"\": Bucket name must match the regex \"^[a-zA-Z0-9.\\-_]{1,255}$\" or be an ARN matching the regex \"^arn:(aws).*:s3:[a-z\\-0-9]+:[0-9]{12}:accesspoint[/:][a-zA-Z0-9\\-]{1,63}$\"\r\n"
     ]
    }
   ],
   "source": [
    "# Download the model and output artifacts from AWS S3\n",
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz $models_dir/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "#!ls -al ./models\n",
    "\n",
    "tar = tarfile.open('{}/model.tar.gz'.format(models_dir))\n",
    "tar.extractall(path=models_dir)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 487060\r\n",
      "drwxrwxr-x 6 ec2-user ec2-user      4096 Jul  4 18:56 .\r\n",
      "drwxrwxr-x 9 ec2-user ec2-user      4096 Jul  4 18:58 ..\r\n",
      "drwxr-xr-x 2 ec2-user ec2-user      4096 Jun 30 21:34 metrics\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 498719004 Jun 30 21:35 model.tar.gz\r\n",
      "drwxr-xr-x 2 ec2-user ec2-user      4096 Jun 30 21:29 tensorboard\r\n",
      "drwxr-xr-x 3 ec2-user ec2-user      4096 Jun 30 21:29 tensorflow\r\n",
      "drwxr-xr-x 3 ec2-user ec2-user      4096 Jun 30 21:29 transformers\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al $models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261692\r\n",
      "drwxr-xr-x 2 ec2-user ec2-user      4096 Jun 30 21:33 .\r\n",
      "drwxr-xr-x 3 ec2-user ec2-user      4096 Jun 30 21:29 ..\r\n",
      "-rw-r--r-- 1 ec2-user ec2-user      1358 Jun 30 21:33 config.json\r\n",
      "-rw-r--r-- 1 ec2-user ec2-user 267959068 Jun 30 21:33 tf_model.h5\r\n"
     ]
    }
   ],
   "source": [
    "transformer_model_dir = '{}/transformers/fine-tuned/'.format(models_dir)\n",
    "\n",
    "!ls -al $transformer_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"_num_labels\": 5,\r\n",
      "  \"activation\": \"gelu\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"DistilBertForMaskedLM\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.1,\r\n",
      "  \"bad_words_ids\": null,\r\n",
      "  \"bos_token_id\": null,\r\n",
      "  \"decoder_start_token_id\": null,\r\n",
      "  \"dim\": 768,\r\n",
      "  \"do_sample\": false,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": false,\r\n",
      "  \"eos_token_id\": null,\r\n",
      "  \"finetuning_task\": null,\r\n",
      "  \"hidden_dim\": 3072,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\",\r\n",
      "    \"3\": \"LABEL_3\",\r\n",
      "    \"4\": \"LABEL_4\"\r\n",
      "  },\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"is_decoder\": false,\r\n",
      "  \"is_encoder_decoder\": false,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2,\r\n",
      "    \"LABEL_3\": 3,\r\n",
      "    \"LABEL_4\": 4\r\n",
      "  },\r\n",
      "  \"length_penalty\": 1.0,\r\n",
      "  \"max_length\": 20,\r\n",
      "  \"max_position_embeddings\": 512,\r\n",
      "  \"min_length\": 0,\r\n",
      "  \"model_type\": \"distilbert\",\r\n",
      "  \"n_heads\": 12,\r\n",
      "  \"n_layers\": 6,\r\n",
      "  \"no_repeat_ngram_size\": 0,\r\n",
      "  \"num_beams\": 1,\r\n",
      "  \"num_return_sequences\": 1,\r\n",
      "  \"output_attentions\": false,\r\n",
      "  \"output_hidden_states\": false,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"prefix\": null,\r\n",
      "  \"pruned_heads\": {},\r\n",
      "  \"qa_dropout\": 0.1,\r\n",
      "  \"repetition_penalty\": 1.0,\r\n",
      "  \"seq_classif_dropout\": 0.2,\r\n",
      "  \"sinusoidal_pos_embds\": false,\r\n",
      "  \"task_specific_params\": null,\r\n",
      "  \"temperature\": 1.0,\r\n",
      "  \"tie_weights_\": true,\r\n",
      "  \"top_k\": 50,\r\n",
      "  \"top_p\": 1.0,\r\n",
      "  \"torchscript\": false,\r\n",
      "  \"use_bfloat16\": false,\r\n",
      "  \"vocab_size\": 30522\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "cat $transformer_model_dir/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TensorFlow Model to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification # PyTorch version\n",
    "\n",
    "loaded_pytorch_model = DistilBertForSequenceClassification.from_pretrained(transformer_model_dir,\n",
    "                                                                     id2label={\n",
    "                                                                       0: 1,\n",
    "                                                                       1: 2,\n",
    "                                                                       2: 3,\n",
    "                                                                       3: 4,\n",
    "                                                                       4: 5\n",
    "                                                                     },\n",
    "                                                                     label2id={\n",
    "                                                                       1: 0,\n",
    "                                                                       2: 1,\n",
    "                                                                       3: 2,\n",
    "                                                                       4: 3,\n",
    "                                                                       5: 4\n",
    "                                                                     },\n",
    "                                                                  from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_distilbert.DistilBertForSequenceClassification'>\n",
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(type(loaded_pytorch_model))\n",
    "print(loaded_pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_device -1\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "inference_device = -1 # CPU: -1, GPU: 0\n",
    "print('inference_device {}'.format(inference_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "inference_pipeline = TextClassificationPipeline(model=loaded_pytorch_model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                                framework='pt',\n",
    "                                                device=inference_device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved it!  I will recommend this to everyone. [{'label': 5, 'score': 0.2354256}]\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"I loved it!  I will recommend this to everyone.\"\"\"\n",
    "print(review, inference_pipeline(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Really bad.  I hope they don't make this anymore. [{'label': 5, 'score': 0.23714961}]\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"Really bad.  I hope they don't make this anymore.\"\"\"\n",
    "print(review, inference_pipeline(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Transformer/PyTorch Model with `.save_pretrained()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_models_dir = './models/transformers/pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pytorch_model.save_pretrained(pytorch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261588\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user      4096 Jul  4 19:00 .\r\n",
      "drwxr-xr-x 4 ec2-user ec2-user      4096 Jul  4 19:00 ..\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      1302 Jul  4 19:00 config.json\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 267852933 Jul  4 19:00 pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = DistilBertForSequenceClassification.from_pretrained(pytorch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "inference_pipeline = TextClassificationPipeline(model=pytorch_model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                                framework='pt',\n",
    "                                                device=inference_device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved it!  I will recommend this to everyone. [{'label': 5, 'score': 0.2354256}]\n"
     ]
    }
   ],
   "source": [
    "review = \"\"\"I loved it!  I will recommend this to everyone.\"\"\"\n",
    "print(review, inference_pipeline(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Transformer/PyTorch Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_pytorch_model_name = 'pytorch_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/models/transformer-pytorch/\n"
     ]
    }
   ],
   "source": [
    "s3_transformer_pytorch_model_path = 's3://{}/models/transformer-pytorch/'.format(bucket)\n",
    "print(s3_transformer_pytorch_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: models/transformers/pytorch/config.json to s3://sagemaker-us-east-1-835319576252/models/transformer-pytorch/config.json\n",
      "upload: models/transformers/pytorch/pytorch_model.bin to s3://sagemaker-us-east-1-835319576252/models/transformer-pytorch/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $pytorch_models_dir $s3_transformer_pytorch_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-04 19:01:20       1302 config.json\r\n",
      "2020-07-04 19:01:20  267852933 pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_transformer_pytorch_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_transformer_pytorch_model_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store s3_transformer_pytorch_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save PyTorch Model with `torch.save()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model_name = 'pytorch_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./models/pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model_path = './models/pytorch/{}'.format(pytorch_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(loaded_pytorch_model.state_dict(), pytorch_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 267852933 Jul  4 19:02 ./models/pytorch/pytorch_model.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al $pytorch_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload PyTorch Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/models/pytorch/pytorch_model.pt\n"
     ]
    }
   ],
   "source": [
    "s3_pytorch_model_path = 's3://{}/models/pytorch/{}'.format(bucket, pytorch_model_name)\n",
    "print(s3_pytorch_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: models/pytorch/pytorch_model.pt to s3://sagemaker-us-east-1-835319576252/models/pytorch/pytorch_model.pt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $pytorch_model_path $s3_pytorch_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-04 19:02:54  267852933 pytorch_model.pt\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_pytorch_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_pytorch_model_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store s3_pytorch_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
