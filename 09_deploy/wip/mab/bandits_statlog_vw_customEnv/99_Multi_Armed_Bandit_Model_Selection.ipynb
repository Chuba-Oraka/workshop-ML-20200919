{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandits with Amazon SageMaker RL\n",
    "\n",
    "We demonstrate how you can manage your own contextual multi-armed bandit workflow on SageMaker using the built-in [Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) container to train and deploy contextual bandit models. We show how to train these models that interact with a live environment (using a simulated client application) and continuously update the model with efficient exploration.\n",
    "\n",
    "### Why Contextual Bandits?\n",
    "\n",
    "Wherever we look to personalize content for a user (content layout, ads, search, product recommendations, etc.), contextual bandits come in handy. Traditional personalization methods collect a training dataset, build a model and deploy it for generating recommendations. However, the training algorithm does not inform us on how to collect this dataset, especially in a production system where generating poor recommendations lead to loss of revenue. Contextual bandit algorithms help us collect this data in a strategic manner by trading off between exploiting known information and exploring recommendations which may yield higher benefits. The collected data is used to update the personalization model in an online manner. Therefore, contextual bandits help us train a personalization model while minimizing the impact of poor recommendations.\n",
    "\n",
    "### What does this notebook contain?\n",
    "\n",
    "To implement the exploration-exploitation strategy, we need an iterative training and deployment system that: (1) recommends an action using the contextual bandit model based on user context, (2) captures the implicit feedback over time and (3) continuously trains the model with incremental interaction data. In this notebook, we show how to setup the infrastructure needed for such an iterative learning system. While the example demonstrates a bandits application, these continual learning systems are useful more generally in dynamic scenarios where models need to be continually updated to capture the recent trends in the data (e.g. tracking fraud behaviors based on detection mechanisms or tracking user interests over time). \n",
    "\n",
    "In a typical supervised learning setup, the model is trained with a SageMaker training job and it is hosted behind a SageMaker hosting endpoint. The client application calls the endpoint for inference and receives a response. In bandits, the client application also sends the reward (a score assigned to each recommendation generated by the model) back for subsequent model training. These rewards will be part of the dataset for the subsequent model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on this blog post:\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/power-contextual-bandits-using-continual-learning-with-amazon-sagemaker-rl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/multi_armed_bandit_maximize_reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/multi_armed_bandit_traffic_shift.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contextual bandit training workflow is controlled by an experiment manager provided with this example. The client application (say a recommender system application) pings the SageMaker hosting endpoint that is serving the bandits model. The application sends the state (user features) as input and receives an action (recommendation) as a response. The client application sends the recommended action to the user and stores the received reward in S3. The SageMaker hosted endpoint also stores inference data (state and action) in S3. The experiment manager joins the inference data with rewards as they become available. The joined data is used to update the model with a SageMaker training job. The updated model is evaluated offline and deployed to SageMaker hosting endpoint if the model evaluation score improves upon prior models. \n",
    "\n",
    "Below is an overview of the subsequent cells in the notebook: \n",
    "* Configuration: this includes details related to SageMaker and other AWS resources needed for the bandits application. \n",
    "* IAM role setup: this creates appropriate execution role and shows how to add more permissions to the role, needed for specific AWS resources.\n",
    "* Client application (Environment): this shows the simulated client application.\n",
    "* Step-by-step bandits model development: \n",
    " 1. Model Initialization (random or warm-start) \n",
    " 2. Deploy the First Model \n",
    " 3. Initialize the Client Application \n",
    " 4. Reward Ingestion \n",
    " 5. Model Re-training and Re-deployment \n",
    "* Bandits model deployment with the end-to-end loop. \n",
    "* Visualization \n",
    "* Cleanup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Mode\n",
    "\n",
    "To facilitate experimentation, we provide a `local_mode` that runs the contextual bandit example using the SageMaker Notebook instance itself instead of SageMaker training and hosting instances. The workflow remains the same in `local_mode`, but runs much faster for small datasets. Hence, it is a useful tool for experimentation and debugging. However, it will not scale to production use cases with high throughput and large datasets. \n",
    "\n",
    "In `local_mode`, the training, evaluation and hosting is done with the SageMaker VW docker container. The join is not handled by SageMaker, and is done inside the client application. The rest of the textual explanation assumes that the notebook is run in SageMaker mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import sagemaker\n",
    "\n",
    "sys.path.append('common')\n",
    "sys.path.append('common/sagemaker_rl')\n",
    "\n",
    "from markdown_helper import *\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "The configuration for the bandits application can be specified in a `config.yaml` file as can be seen below. It configures the AWS resources needed. The DynamoDB tables are used to store metadata related to experiments, models and data joins. The `private_resource` specifices the SageMaker instance types and counts used for training, evaluation and hosting. The SageMaker container image is used for the bandits application. This config file also contains algorithm and SageMaker-specific setups.  Note that all the data generated and used for the bandits application will be stored in `s3://sagemaker-{REGION}-{AWS_ACCOUNT_ID}/{experiment_id}/`.\n",
    "\n",
    "Please make sure that the `num_arms` parameter in the config is equal to the number of actions in the client application (which is defined in the cell below).\n",
    "\n",
    "The Docker image is defined here:  https://github.com/aws/sagemaker-rl-container/blob/master/vw/docker/8.7.0/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mresource\u001b[39;49;00m:\r\n",
      "  \u001b[94mshared_resource\u001b[39;49;00m:\r\n",
      "    \u001b[37m# cloud formation stack\u001b[39;49;00m\r\n",
      "    \u001b[94mresources_cf_stack_name\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsSharedResourceStack\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# Dynamo table for status of an experiment\u001b[39;49;00m\r\n",
      "    \u001b[94mexperiment_db\u001b[39;49;00m:\r\n",
      "      \u001b[94mtable_name\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsExperimentTable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# Dynamo table for status of all models trained\u001b[39;49;00m\r\n",
      "    \u001b[94mmodel_db\u001b[39;49;00m:\r\n",
      "      \u001b[94mtable_name\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsModelTable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# Dynamo table for status of all joining job for reward ingestion\u001b[39;49;00m\r\n",
      "    \u001b[94mjoin_db\u001b[39;49;00m:\r\n",
      "      \u001b[94mtable_name\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsJoinTable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    \u001b[94miam_role\u001b[39;49;00m:\r\n",
      "      \u001b[94mrole_name\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsIAMRole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "  \u001b[94mprivate_resource\u001b[39;49;00m:\r\n",
      "    \u001b[94mhosting_fleet\u001b[39;49;00m:\r\n",
      "      \u001b[94minstance_type\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mml.t2.medium\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "      \u001b[94minstance_count\u001b[39;49;00m: 1\r\n",
      "    \u001b[94mtraining_fleet\u001b[39;49;00m:\r\n",
      "      \u001b[94minstance_type\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    \u001b[94mevaluation_fleet\u001b[39;49;00m:\r\n",
      "      \u001b[94minstance_type\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\u001b[37m# Vowpal Wabbit container\u001b[39;49;00m\r\n",
      "\u001b[94mimage\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33m462105765813.dkr.ecr.{AWS_REGION}.amazonaws.com/sagemaker-rl-vw-container:vw-8.7.0-cpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "\u001b[37m# Vowpal Wabbit algorithm parameters\u001b[39;49;00m\r\n",
      "\u001b[94malgor\u001b[39;49;00m:\r\n",
      "  \u001b[94malgorithms_parameters\u001b[39;49;00m:\r\n",
      "    \u001b[94mexploration_policy\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33megreedy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m# supports \"egreedy\", \"bag\", \"cover\"\u001b[39;49;00m\r\n",
      "    \u001b[94mepsilon\u001b[39;49;00m: 0.001 \u001b[37m# used if egreedy is the exploration policy\u001b[39;49;00m\r\n",
      "    \u001b[94mnum_policies\u001b[39;49;00m: 3 \u001b[37m# used if bag or cover is the exploration policy\u001b[39;49;00m\r\n",
      "    \u001b[94mnum_arms\u001b[39;49;00m: 5\r\n",
      "    \u001b[94mcfa_type\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33mdr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[37m# supports \"dr\", \"ips\"\u001b[39;49;00m\r\n",
      "\u001b[37m# use local mode?\u001b[39;49;00m\r\n",
      "\u001b[94mlocal_mode\u001b[39;49;00m: true\r\n",
      "\u001b[37m# if true, use the same endpoint with updated model\u001b[39;49;00m\r\n",
      "\u001b[94msoft_deployment\u001b[39;49;00m: true\r\n",
      " \r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config.yaml'\n",
    "with open(config_file, 'r') as yaml_file:\n",
    "    config = yaml.load(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional permissions for the IAM role\n",
    "IAM role requires additional permissions for [AWS CloudFormation](https://aws.amazon.com/cloudformation/), [Amazon DynamoDB](https://aws.amazon.com/dynamodb/), [Amazon Kinesis Data Firehose](https://aws.amazon.com/kinesis/data-firehose/) and [Amazon Athena](https://aws.amazon.com/athena/). Make sure the SageMaker role you are using has the permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(generate_help_for_experiment_manager_permissions(sagemaker_role)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client application (Environment)\n",
    "The client application simulates a live environment that uses the SageMaker bandits model to serve recommendations to users. The logic of reward generation resides in the client application. We simulate the online learning loop with feedback using the [Statlog (Shuttle) Data Set](https://archive.ics.uci.edu/ml/datasets/Statlog+(Shuttle)). The data consists of 7 classes, and if the agent selects the right class, then reward is 1. Otherwise, the agent obtains a reward 0.\n",
    "\n",
    "The workflow of the client application is as follows:\n",
    "- The client application picks a context at random, which is sent to the SageMaker endpoint for retrieving an action.\n",
    "- SageMaker endpoint returns an action, associated probability and `event_id`.\n",
    "- Since this simulator was generated from the Statlog dataset, we know the true class for that context. \n",
    "- The application reports the reward to the experiment manager using S3, along with the corresponding `event_id`.\n",
    "\n",
    "`event_id` is a unique identifier for each interaction. It is used to join inference data `<state, action, action probability>` with the rewards. \n",
    "\n",
    "In a later cell of this notebook, where there exists a hosted endpoint, we illustrate how the client application interacts with the endpoint and gets the recommended action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step bandits model development\n",
    "\n",
    "`ExperimentManager` is the top level class for all the Bandits/RL and continual learning workflows. Similar to the estimators in the [Sagemaker Python SDK](https://github.com/aws/sagemaker-python-sdk), `ExperimentManager` contains methods for training, deployment and evaluation. It keeps track of the job status and reflects current progress in the workflow.\n",
    "\n",
    "Start the application using the `ExperimentManager` class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "experiment_name = 'bandits-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ExperimentManager` will create a AWS CloudFormation Stack of additional resources needed for the Bandit experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator.resource_manager:Using Resources in CloudFormation stack named: BanditsSharedResourceStack for Shared Resources.\n"
     ]
    }
   ],
   "source": [
    "from orchestrator.workflow.manager.experiment_manager import ExperimentManager\n",
    "\n",
    "bandits_experiment = ExperimentManager(config, experiment_id=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Deleting hosting endpoint 'bandits-1597300705'...\n",
      "WARNING:orchestrator.clients.ddb.experiment_db_client:Deleting experiment record...\n",
      "INFO:orchestrator.resource_manager:Using Resources in CloudFormation stack named: BanditsSharedResourceStack for Shared Resources.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bandits_experiment.clean_resource(experiment_id=bandits_experiment.experiment_id)\n",
    "\n",
    "    bandits_experiment.clean_table_records(experiment_id=bandits_experiment.experiment_id)\n",
    "except:\n",
    "    print('Ignore any errors.  This is OK.')\n",
    "\n",
    "bandits_experiment = ExperimentManager(config, experiment_id=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a new experiment, we need to initialize the first model. In the case where historical data is available and is in the format of `<state, action, action probability, reward>`, we can warm start by learning the policy offline. Otherwise, we can initiate a random policy.\n",
    "\n",
    "**Warm start the policy**\n",
    "\n",
    "We showcase the warm start by generating a batch of randomly selected samples with size `batch_size`. Then we split it into a training set and an evaluation set using the parameter `ratio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: astroid 2.3.3 has requirement wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wrapt --upgrade --ignore-installed\n",
    "!pip install -q transformers==2.8.0\n",
    "!pip install -q tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "import datetime\n",
    "import json\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "def remove_underrepresented_classes(features, labels, thresh=0.0005):\n",
    "    \"\"\"Removes classes when number of datapoints fraction is below a threshold.\"\"\"\n",
    "    total_count = labels.shape[0]\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    ratios = counts.astype('float') / total_count\n",
    "    vals_and_ratios = dict(zip(unique, ratios))\n",
    "    print('Unique classes and their ratio of total: %s' % vals_and_ratios)\n",
    "    keep = [vals_and_ratios[v] >= thresh for v in labels]\n",
    "    return features[keep], labels[np.array(keep)]\n",
    "\n",
    "def safe_std(values):\n",
    "    \"\"\"Remove zero std values for ones.\"\"\"\n",
    "    return np.array([val if val != 0.0 else 1.0 for val in values])\n",
    "\n",
    "def classification_to_bandit_problem(contexts, labels, num_actions=None):\n",
    "    \"\"\"Normalize contexts and encode deterministic rewards.\"\"\"\n",
    "    if num_actions is None:\n",
    "        num_actions = np.max(labels) + 1\n",
    "    num_contexts = contexts.shape[0]\n",
    "\n",
    "    # Due to random subsampling in small problems, some features may be constant\n",
    "    sstd = safe_std(np.std(contexts, axis=0, keepdims=True)[0, :])\n",
    "\n",
    "    # Normalize features\n",
    "    contexts = ((contexts - np.mean(contexts, axis=0, keepdims=True)) / sstd)\n",
    "\n",
    "    # One hot encode labels as rewards\n",
    "    rewards = np.zeros((num_contexts, num_actions))\n",
    "    rewards[np.arange(num_contexts), labels] = 1.0\n",
    "\n",
    "    return contexts, rewards, (np.ones(num_contexts), labels)\n",
    "\n",
    "\n",
    "class StatlogSimApp():\n",
    "    \"\"\"\n",
    "    A client application simulator using Statlog data.\n",
    "    \"\"\"\n",
    "    def __init__(self, predictor, data):\n",
    "# #        file_name = 'sim_app/shuttle.trn'\n",
    "#         self.num_actions = 5\n",
    "# #        self.data_size = 43483\n",
    "        \n",
    "#         with open(file_name, 'r') as f:\n",
    "#             data = np.loadtxt(f)\n",
    "\n",
    "#         # Shuffle data\n",
    "#         np.random.shuffle(data)\n",
    "\n",
    "#         # Last column is label, rest are features\n",
    "#         contexts = data[:, :-1]\n",
    "#         labels = data[:, -1].astype(int) - 1  # convert to 0 based index\n",
    "\n",
    "        self.num_actions = 5\n",
    "\n",
    "        ############\n",
    "        # TODO:  Factor this code out\n",
    "        data = pd.read_csv(data).to_numpy()\n",
    "\n",
    "    #    df = pd.read_csv(data, \n",
    "    #                     delimiter='\\t', \n",
    "    #                     quoting=csv.QUOTE_NONE,\n",
    "    #                     compression='gzip')\n",
    "    #    df_scrubbed = df[['review_body', 'star_rating']].sample(n=100)\n",
    "    #    df_scrubbed = df_scrubbed.reset_index()\n",
    "    #    df_scrubbed.shape\n",
    "    #    data = df_scrubbed.to_numpy()\n",
    "\n",
    "        # Last column is label, the rest are the features    \n",
    "        data_without_index = data[:,1:]\n",
    "        contexts = data_without_index[:, :-1]\n",
    "        labels = data_without_index[:, -1].astype(int) - 1  # convert to 0 based index\n",
    "        ############\n",
    "    \n",
    "        context, labels = remove_underrepresented_classes(contexts, labels)\n",
    "        self.context, self.labels, _ = classification_to_bandit_problem(\n",
    "                                        context, labels, self.num_actions)\n",
    "        self.opt_rewards = [1]\n",
    "        \n",
    "        self.rewards_buffer = []\n",
    "        self.joined_data_buffer = []\n",
    "\n",
    "    def choose_random_user(self):\n",
    "        context_index = np.random.choice(self.context.shape[0])\n",
    "        context = self.context[context_index]\n",
    "        return context_index, context\n",
    "    \n",
    "    def get_reward(self, \n",
    "                   context_index, \n",
    "                   action, \n",
    "                   event_id, \n",
    "                   model_id, \n",
    "                   action_prob, \n",
    "                   sample_prob, \n",
    "                   local_mode):\n",
    "\n",
    "        reward = 1 if self.labels[context_index][action-1] == 1 else 0\n",
    "\n",
    "        if local_mode:\n",
    "            json_blob = {\"reward\": reward,\n",
    "                         \"event_id\": event_id,\n",
    "                         \"action\": action,\n",
    "                         \"action_prob\": action_prob,\n",
    "                         \"model_id\": model_id,\n",
    "                         \"observation\": self.context[context_index].tolist(),\n",
    "                         \"sample_prob\": sample_prob}\n",
    "            self.joined_data_buffer.append(json_blob)\n",
    "        else:\n",
    "            json_blob = {\"reward\": reward, \"event_id\": event_id}\n",
    "            self.rewards_buffer.append(json_blob)\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def clear_buffer(self):\n",
    "        self.rewards_buffer.clear()\n",
    "        self.joined_data_buffer.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from src.io_utils import parse_s3_uri\n",
    "import csv\n",
    "\n",
    "def prepare_warm_start_data(data, batch_size=100):\n",
    "    \"\"\"\n",
    "    Generate a batch of experiences for warm starting the policy.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_actions = 5\n",
    "    \n",
    "    ############\n",
    "    # TODO:  Factor this code out\n",
    "    data = pd.read_csv(data).to_numpy()\n",
    "        \n",
    "#    df = pd.read_csv(data, \n",
    "#                     delimiter='\\t', \n",
    "#                     quoting=csv.QUOTE_NONE,\n",
    "#                     compression='gzip')\n",
    "#    df_scrubbed = df[['review_body', 'star_rating']].sample(n=100)\n",
    "#    df_scrubbed = df_scrubbed.reset_index()\n",
    "#    df_scrubbed.shape\n",
    "#    data = df_scrubbed.to_numpy()\n",
    "    \n",
    "    # Last column is label, the rest are the features    \n",
    "    data_without_index = data[:,1:]\n",
    "    contexts = data_without_index[:, :-1]\n",
    "    labels = data_without_index[:, -1].astype(int) - 1  # convert to 0 based index\n",
    "\n",
    "    # TODO:  Convert raw text into tokens\n",
    "    \n",
    "    # print(contexts)\n",
    "    # print(labels)\n",
    "\n",
    "    context, labels = remove_underrepresented_classes(contexts, labels)\n",
    "    \n",
    "    print(type(labels[0]))\n",
    "    print(type(context[0]))\n",
    "    \n",
    "    statlog_context, statlog_labels, _ = classification_to_bandit_problem(\n",
    "                                    context, labels, num_actions)\n",
    "\n",
    "    joined_data_buffer = []\n",
    "    for i in range(0, batch_size):\n",
    "        context_index_i = np.random.choice(statlog_context.shape[0])\n",
    "        context_i = statlog_context[context_index_i]\n",
    "        action = np.random.choice(num_actions) + 1 #random action\n",
    "        action_prob = 1 / num_actions # probability of picking a random action\n",
    "        reward = 1 if statlog_labels[context_index_i][action-1] == 1 else 0\n",
    "\n",
    "        json_blob = {\"reward\": reward,\n",
    "                    \"event_id\": 'not-apply-to-warm-start',\n",
    "                    \"action\": action,\n",
    "                    \"action_prob\": action_prob,\n",
    "                    \"model_id\": 'not-apply-to-warm-start',\n",
    "                    \"observation\": context_i.tolist(),\n",
    "                    \"sample_prob\": np.random.uniform(0.0, 1.0)}\n",
    "\n",
    "        joined_data_buffer.append(json_blob)\n",
    "\n",
    "    return joined_data_buffer\n",
    "\n",
    "# def download_historical_data_from_s3(data_s3_prefix):\n",
    "#     \"\"\"Download the warm start data from S3.\"\"\"\n",
    "#     s3_client = boto3.client('s3')\n",
    "#     bucket, prefix, _ = parse_s3_uri(data_s3_prefix)\n",
    "\n",
    "#     results = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "#     contents = results.get('Contents')\n",
    "#     key = contents[0].get('Key')\n",
    "    \n",
    "#     data_file_name = 'statlog_warm_start.data'\n",
    "#     s3_client.download_file(bucket, key, data_file_name)\n",
    "\n",
    "# def evaluate_historical_data(data_file):\n",
    "#     \"\"\"Calculate policy value of the logged policy.\"\"\"\n",
    "#     # Assume logged data comes from same policy \n",
    "#     # so no need for counterfactual analysis\n",
    "#     offline_data = pd.read_csv(data_file, sep=\",\")\n",
    "#     offline_data_mean = offline_data['reward'].mean()\n",
    "#     offline_data_cost = 1 - offline_data_mean\n",
    "#     offline_data_cost\n",
    "#     return offline_data_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes and their ratio of total: {0: 0.1111111111111111, 1: 0.2222222222222222, 2: 0.2222222222222222, 3: 0.2222222222222222, 4: 0.2222222222222222}\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Successfully create S3 bucket 'sagemaker-us-east-1-835319576252' for athena queries\n",
      "INFO:orchestrator:Started dummy local joining job...\n",
      "INFO:orchestrator:Splitting data into train/evaluation set with ratio of 0.8\n",
      "INFO:orchestrator:Joined data will be stored under s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300713\n",
      "INFO:orchestrator:_upload_data_buffer_as_joined_data_format put s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300713/train/local-joined-data-1597300713.csv\n",
      "INFO:orchestrator:_upload_data_buffer_as_joined_data_format put s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300713/eval/local-joined-data-1597300713.csv\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "#warm_start_data_buffer = prepare_warm_start_data('./data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz',\n",
    "warm_start_data_buffer = prepare_warm_start_data(data='./data/model_rewards.csv',\n",
    "                                                 batch_size=batch_size)\n",
    "\n",
    "# upload to s3\n",
    "bandits_experiment.ingest_joined_data(warm_start_data_buffer,\n",
    "                                      ratio=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_id': 'bandits-1597300705',\n",
       " 'training_workflow_metadata': {'next_model_to_train_id': None,\n",
       "  'last_trained_model_id': None,\n",
       "  'training_state': None},\n",
       " 'hosting_workflow_metadata': {'last_hosted_model_id': None,\n",
       "  'hosting_endpoint': None,\n",
       "  'hosting_state': None,\n",
       "  'next_model_to_host_id': None},\n",
       " 'joining_workflow_metadata': {'joining_state': 'SUCCEEDED',\n",
       "  'last_joined_job_id': 'bandits-1597300705-join-job-id-1597300713',\n",
       "  'next_join_job_id': None},\n",
       " 'evaluation_workflow_metadata': {'evaluation_state': None,\n",
       "  'last_evaluation_job_id': None,\n",
       "  'next_evaluation_job_id': None}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits_experiment._jsonify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Next Model name would be bandits-1597300705-model-id-1597300721\n",
      "INFO:orchestrator:Start training job for model 'bandits-1597300705-model-id-1597300721''\n",
      "INFO:orchestrator:Training job will be executed in 'local' mode\n",
      "WARNING:sagemaker.estimator:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpbdure2z3_algo-1-6m82s_1 ... \n",
      "\u001b[1BAttaching to tmpbdure2z3_algo-1-6m82s_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 2020-08-13 06:38:44,715 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 2020-08-13 06:38:44,741 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 2020-08-13 06:38:44,752 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 2020-08-13 06:38:44,762 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"sagemaker_estimator\": \"RLEstimator\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"current_host\": \"algo-1-6m82s\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"algo-1-6m82s\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"exploration_policy\": \"egreedy\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"epsilon\": 0.001,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"num_policies\": 3,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"num_arms\": 5,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"cfa_type\": \"dr\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"job_name\": \"bandits-1597300705-model-id-1597300721\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"master_hostname\": \"algo-1-6m82s\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300721/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"module_name\": \"train-vw\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"current_host\": \"algo-1-6m82s\",\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m             \"algo-1-6m82s\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m     \"user_entry_point\": \"train-vw.py\"\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HOSTS=[\"algo-1-6m82s\"]\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HPS={\"cfa_type\":\"dr\",\"epsilon\":0.001,\"exploration_policy\":\"egreedy\",\"num_arms\":5,\"num_policies\":3}\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_USER_ENTRY_POINT=train-vw.py\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-6m82s\",\"hosts\":[\"algo-1-6m82s\"]}\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_CURRENT_HOST=algo-1-6m82s\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_MODULE_NAME=train-vw\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300721/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-6m82s\",\"framework_module\":null,\"hosts\":[\"algo-1-6m82s\"],\"hyperparameters\":{\"cfa_type\":\"dr\",\"epsilon\":0.001,\"exploration_policy\":\"egreedy\",\"num_arms\":5,\"num_policies\":3},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bandits-1597300705-model-id-1597300721\",\"log_level\":20,\"master_hostname\":\"algo-1-6m82s\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300721/source/sourcedir.tar.gz\",\"module_name\":\"train-vw\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-6m82s\",\"hosts\":[\"algo-1-6m82s\"]},\"user_entry_point\":\"train-vw.py\"}\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_USER_ARGS=[\"--cfa_type\",\"dr\",\"--epsilon\",\"0.001\",\"--exploration_policy\",\"egreedy\",\"--num_arms\",\"5\",\"--num_policies\",\"3\"]\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HP_EXPLORATION_POLICY=egreedy\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HP_EPSILON=0.001\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HP_NUM_POLICIES=3\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HP_NUM_ARMS=5\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m SM_HP_CFA_TYPE=dr\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/vowpal_wabbit/python:/vowpal_wabbit/build/python:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m /usr/bin/python train-vw.py --cfa_type dr --epsilon 0.001 --exploration_policy egreedy --num_arms 5 --num_policies 3\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:root:channels ['training']\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:root:hps: {'cfa_type': 'dr', 'epsilon': 0.001, 'exploration_policy': 'egreedy', 'num_arms': 5, 'num_policies': 3}\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:root:No pre-trained model has been specified in channel pretrained_model.Training will start from scratch.\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:VW CLI:creating an instance of VWModel\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:VW CLI:successfully created VWModel\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:VW CLI:command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-f', '/opt/ml/model/vw.model', '--save_resume', '-p', '/dev/stdout']\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:VW CLI:Started VW process!\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:root:Processing training data: [PosixPath('/opt/ml/input/data/training/local-joined-data-1597300713.csv')]\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m final_regressor = /opt/ml/model/vw.model\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m predictions = /dev/stdout\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m Num weight bits = 18\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m learning rate = 0.5\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m initial_t = 0\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m power_t = 0.5\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m using no cache\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m Reading datafile = \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m num sources = 1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m average  since         example        example  current  current  current\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m loss     last          counter         weight    label  predict features\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 0.001000 0.001000            1            1.0        3 1:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 2.498500 4.996000            2            2.0        1 1:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 1.249500 0.000500            4            4.0        1 2:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 1.249375 1.249250            8            8.0        3 4:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 0.937250 0.625125           16           16.0        1 3:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 0.625219 0.313187           32           32.0        4 1:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 0.703172 0.781125           64           64.0        2 3:0.999200        1\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m finished run\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m number of examples = 86\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m weighted example sum = 86.000000\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m weighted label sum = 0.000000\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m average loss = 0.523465\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m total feature number = 86\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m \n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m INFO:root:Model learned using 86 training experiences.\n",
      "\u001b[36malgo-1-6m82s_1  |\u001b[0m 2020-08-13 06:38:45,179 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpbdure2z3/algo-1-6m82s Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmpbdure2z3_algo-1-6m82s_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "bandits_experiment.initialize_first_model(input_data_s3_prefix=bandits_experiment.last_joined_job_train_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate current model against historical model\n",
    "\n",
    "After every training cycle, we evaluate if the newly trained model is better than the one currently deployed. Using the evaluation dataset, we evaluate how the new model would perform compared to the model that is currently deployed. SageMaker RL supports offline evaluation by performing counterfactual analysis (CFA). By default, we apply [doubly robust (DR) estimation](https://arxiv.org/pdf/1103.4601.pdf) method. The bandit policy tries to minimize the cost (1-reward) value in this case, so a smaller evaluation score indicates better policy performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Evaluating model 'bandits-1597300705-model-id-1597300721' with evaluation job id 'bandits-1597300705-model-id-1597300721-eval-1597300735'\n",
      "INFO:orchestrator:Evaluation job will be executed in 'local' mode\n",
      "WARNING:sagemaker.estimator:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpcxz_yucr/algo-1-1nab8 Please remove it manually.\n",
      "WARNING:orchestrator:No model has been hosted. Please deploy a model and check later.\n",
      "INFO:orchestrator:Getting eval scores for model 'bandits-1597300705-model-id-1597300721' on eval data set 's3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300713/eval'\n",
      "INFO:orchestrator:Evaluation score for model 'bandits-1597300705-model-id-1597300721'with data 's3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300713/eval' is 1.001176.\n"
     ]
    }
   ],
   "source": [
    "# evaluate the current model\n",
    "bandits_experiment.evaluate_model(\n",
    "    input_data_s3_prefix=bandits_experiment.last_joined_job_eval_data,\n",
    "    evaluate_model_id=bandits_experiment.last_trained_model_id)\n",
    "\n",
    "eval_score_last_trained_model = bandits_experiment.get_eval_score(\n",
    "    evaluate_model_id=bandits_experiment.last_trained_model_id,\n",
    "    eval_data_path=bandits_experiment.last_joined_job_eval_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get baseline performance from the historical (warm start) data\n",
    "# download_historical_data_from_s3(data_s3_prefix=bandits_experiment.last_joined_job_eval_data)\n",
    "# baseline_score = evaluate_historical_data(data_file='statlog_warm_start.data')\n",
    "# baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bandits-1597300705-model-id-1597300721'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the model_id of the last model trained.\n",
    "bandits_experiment.last_trained_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training and evaluation is done, we can deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Model 'bandits-1597300705-model-id-1597300721' is ready to deploy.\n",
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5c7ddf8630>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5c7ddf8898>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5c7ddf8a58>: Failed to establish a new connection: [Errno 111] Connection refused',)': /ping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp89xlh7wl_algo-1-psdo0_1\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:C 13 Aug 2020 06:39:10.890 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:C 13 Aug 2020 06:39:10.890 # Redis version=5.0.6, bits=64, commit=00000000, modified=0, pid=18, just started\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:C 13 Aug 2020 06:39:10.890 # Configuration loaded\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # Server initialized\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m 18:M 13 Aug 2020 06:39:10.891 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:13 INFO 139656814556928] Redis server started successfully!\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Starting gunicorn...\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Started server process with PID: 24\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Started gunicorn.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 WARNING 139656814556928] Loggers have already been setup.\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928 integration.py:348] worker started\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] loading entry points\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Number of server workers: 8\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [24] [INFO] Starting gunicorn 19.9.0\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [24] [INFO] Listening at: http://0.0.0.0:8080 (24)\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [24] [INFO] Using worker: sync\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [25] [INFO] Booting worker with pid: 25\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] creating an instance of VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] successfully created VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/model/vw.model']\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300721\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Started VW process!\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [28] [INFO] Booting worker with pid: 28\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] creating an instance of VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] successfully created VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/model/vw.model']\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300721\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Started VW process!\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [31] [INFO] Booting worker with pid: 31\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] creating an instance of VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] successfully created VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/model/vw.model']\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300721\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Started VW process!\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:14 +0000] [34] [INFO] Booting worker with pid: 34\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] creating an instance of VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] successfully created VWModel\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/model/vw.model']\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300721\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:14 INFO 139656814556928] Started VW process!\n",
      "!"
     ]
    }
   ],
   "source": [
    "bandits_experiment.deploy_model(model_id=bandits_experiment.last_trained_model_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the experiment state at any point by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_id': 'bandits-1597300705',\n",
       " 'training_workflow_metadata': {'next_model_to_train_id': None,\n",
       "  'last_trained_model_id': 'bandits-1597300705-model-id-1597300721',\n",
       "  'training_state': 'TRAINED'},\n",
       " 'hosting_workflow_metadata': {'hosting_endpoint': 'local:arn-does-not-matter',\n",
       "  'hosting_state': <HostingState.DEPLOYED: 'DEPLOYED'>,\n",
       "  'last_hosted_model_id': 'bandits-1597300705-model-id-1597300721',\n",
       "  'next_model_to_host_id': None},\n",
       " 'joining_workflow_metadata': {'joining_state': 'SUCCEEDED',\n",
       "  'last_joined_job_id': 'bandits-1597300705-join-job-id-1597300713',\n",
       "  'next_join_job_id': None},\n",
       " 'evaluation_workflow_metadata': {'evaluation_state': 'EVALUATED',\n",
       "  'last_evaluation_job_id': 'bandits-1597300705-model-id-1597300721-eval-1597300735',\n",
       "  'next_evaluation_job_id': None}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits_experiment._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model just trained appears in both `last_trained_model_id` and `last_hosted_model_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Client Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the last trained model is hosted, client application can send out the state, hit the endpoint, and receive the recommended action. There are 7 classes in the statlog data, corresponding to 7 actions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes and their ratio of total: {0: 0.1111111111111111, 1: 0.2222222222222222, 2: 0.2222222222222222, 3: 0.2222222222222222, 4: 0.2222222222222222}\n"
     ]
    }
   ],
   "source": [
    "predictor = bandits_experiment.predictor\n",
    "\n",
    "sim_app = StatlogSimApp(data='./data/model_rewards.csv',\n",
    "                        predictor=predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that `num_arms` specified in `config.yaml` is equal to the total unique actions in the simulation application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sim_app.num_actions == bandits_experiment.config[\"algor\"][\"algorithms_parameters\"][\"num_arms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected action: 3, event ID: 243479965267372479126869264948909965314, model ID: bandits-1597300705-model-id-1597300721, probability: 0.9992000000000001\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "user_id, user_context = sim_app.choose_random_user()\n",
    "\n",
    "action, event_id, model_id, action_prob, sample_prob = predictor.get_action(obs=user_context)\n",
    "\n",
    "# Check prediction response by uncommenting the lines below\n",
    "print('Selected action: {}, event ID: {}, model ID: {}, probability: {}'.format(action, event_id, model_id, action_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client application generates a reward after receiving the recommended action and stores the tuple `<eventID, reward>` in S3. In this case, reward is 1 if predicted action is the true class, and 0 otherwise. SageMaker hosting endpoint saves all the inferences `<eventID, state, action, action probability>` to S3 using [Kinesis Firehose](https://aws.amazon.com/kinesis/data-firehose/). The experiment manager joins the reward with state, action and action probability using [Amazon Athena](https://aws.amazon.com/athena/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting batch of experience data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Successfully create S3 bucket 'sagemaker-us-east-1-835319576252' for athena queries\n",
      "INFO:orchestrator:Started dummy local joining job...\n",
      "INFO:orchestrator:Splitting data into train/evaluation set with ratio of 0.8\n",
      "INFO:orchestrator:Joined data will be stored under s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300760\n",
      "INFO:orchestrator:_upload_data_buffer_as_joined_data_format put s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300760/train/local-joined-data-1597300760.csv\n",
      "INFO:orchestrator:_upload_data_buffer_as_joined_data_format put s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300760/eval/local-joined-data-1597300760.csv\n"
     ]
    }
   ],
   "source": [
    "local_mode = bandits_experiment.local_mode\n",
    "batch_size = 500 # collect 500 data instances\n",
    "print(\"Collecting batch of experience data...\")\n",
    "\n",
    "# Generate experiences and log them\n",
    "for i in range(batch_size):\n",
    "    user_id, user_context = sim_app.choose_random_user()\n",
    "    action, event_id, model_id, action_prob, sample_prob = predictor.get_action(obs=user_context.tolist())\n",
    "    reward = sim_app.get_reward(user_id, action, event_id, model_id, action_prob, sample_prob, local_mode)\n",
    "    \n",
    "# Join (observation, action) with rewards (can be delayed) and upload the data to S3\n",
    "if local_mode:\n",
    "    bandits_experiment.ingest_joined_data(sim_app.joined_data_buffer)\n",
    "else:\n",
    "    print(\"Waiting for firehose to flush data to s3...\")\n",
    "    time.sleep(60) # Wait for firehose to flush data to S3\n",
    "    rewards_s3_prefix = bandits_experiment.ingest_rewards(sim_app.rewards_buffer)\n",
    "    bandits_experiment.join(rewards_s3_prefix)\n",
    "    \n",
    "sim_app.clear_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300760/train'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits_experiment.last_joined_job_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_id': 'bandits-1597300705',\n",
       " 'training_workflow_metadata': {'next_model_to_train_id': None,\n",
       "  'last_trained_model_id': 'bandits-1597300705-model-id-1597300721',\n",
       "  'training_state': 'TRAINED'},\n",
       " 'hosting_workflow_metadata': {'hosting_endpoint': 'local:arn-does-not-matter',\n",
       "  'hosting_state': 'DEPLOYED',\n",
       "  'last_hosted_model_id': 'bandits-1597300705-model-id-1597300721',\n",
       "  'next_model_to_host_id': None},\n",
       " 'joining_workflow_metadata': {'joining_state': 'SUCCEEDED',\n",
       "  'last_joined_job_id': 'bandits-1597300705-join-job-id-1597300760',\n",
       "  'next_join_job_id': None},\n",
       " 'evaluation_workflow_metadata': {'evaluation_state': 'EVALUATED',\n",
       "  'last_evaluation_job_id': 'bandits-1597300705-model-id-1597300721-eval-1597300735',\n",
       "  'next_evaluation_job_id': None}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the workflow to see if join job has completed successfully\n",
    "bandits_experiment._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-train and Re-deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a new model with newly collected experiences, and host the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Use last trained model bandits-1597300705-model-id-1597300721 as pre-trained model for training\n",
      "INFO:orchestrator:Starting training job for ModelId 'bandits-1597300705-model-id-1597300768''\n",
      "INFO:orchestrator:Training job will be executed in 'local' mode\n",
      "WARNING:sagemaker.estimator:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpjboqt5rk_algo-1-whyov_1 ... \n",
      "\u001b[1BAttaching to tmpjboqt5rk_algo-1-whyov_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 2020-08-13 06:39:31,340 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 2020-08-13 06:39:31,352 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 2020-08-13 06:39:31,363 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 2020-08-13 06:39:31,372 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"sagemaker_estimator\": \"RLEstimator\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"pretrained_model\": \"/opt/ml/input/data/pretrained_model\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"current_host\": \"algo-1-whyov\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"algo-1-whyov\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"exploration_policy\": \"egreedy\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"epsilon\": 0.001,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"num_policies\": 3,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"num_arms\": 5,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"cfa_type\": \"dr\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"pretrained_model\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m             \"ContentType\": \"application/x-sagemaker-model\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"job_name\": \"bandits-1597300705-model-id-1597300768\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"master_hostname\": \"algo-1-whyov\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300768/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"module_name\": \"train-vw\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"current_host\": \"algo-1-whyov\",\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m             \"algo-1-whyov\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m     \"user_entry_point\": \"train-vw.py\"\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HOSTS=[\"algo-1-whyov\"]\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HPS={\"cfa_type\":\"dr\",\"epsilon\":0.001,\"exploration_policy\":\"egreedy\",\"num_arms\":5,\"num_policies\":3}\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_USER_ENTRY_POINT=train-vw.py\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-whyov\",\"hosts\":[\"algo-1-whyov\"]}\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"pretrained_model\":{\"ContentType\":\"application/x-sagemaker-model\",\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_CHANNELS=[\"pretrained_model\",\"training\"]\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_CURRENT_HOST=algo-1-whyov\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_MODULE_NAME=train-vw\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300768/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{\"pretrained_model\":\"/opt/ml/input/data/pretrained_model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-whyov\",\"framework_module\":null,\"hosts\":[\"algo-1-whyov\"],\"hyperparameters\":{\"cfa_type\":\"dr\",\"epsilon\":0.001,\"exploration_policy\":\"egreedy\",\"num_arms\":5,\"num_policies\":3},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"pretrained_model\":{\"ContentType\":\"application/x-sagemaker-model\",\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bandits-1597300705-model-id-1597300768\",\"log_level\":20,\"master_hostname\":\"algo-1-whyov\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300768/source/sourcedir.tar.gz\",\"module_name\":\"train-vw\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-whyov\",\"hosts\":[\"algo-1-whyov\"]},\"user_entry_point\":\"train-vw.py\"}\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_USER_ARGS=[\"--cfa_type\",\"dr\",\"--epsilon\",\"0.001\",\"--exploration_policy\",\"egreedy\",\"--num_arms\",\"5\",\"--num_policies\",\"3\"]\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_CHANNEL_PRETRAINED_MODEL=/opt/ml/input/data/pretrained_model\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HP_EXPLORATION_POLICY=egreedy\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HP_EPSILON=0.001\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HP_NUM_POLICIES=3\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HP_NUM_ARMS=5\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m SM_HP_CFA_TYPE=dr\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/vowpal_wabbit/python:/vowpal_wabbit/build/python:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m /usr/bin/python train-vw.py --cfa_type dr --epsilon 0.001 --exploration_policy egreedy --num_arms 5 --num_policies 3\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:root:channels ['pretrained_model', 'training']\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:root:hps: {'cfa_type': 'dr', 'epsilon': 0.001, 'exploration_policy': 'egreedy', 'num_arms': 5, 'num_policies': 3}\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:root:Loading model from /opt/ml/input/data/pretrained_model/vw.model\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:VW CLI:creating an instance of VWModel\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:VW CLI:successfully created VWModel\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:VW CLI:command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-i', '/opt/ml/input/data/pretrained_model/vw.model', '-f', '/opt/ml/model/vw.model', '--save_resume', '-p', '/dev/stdout']\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:VW CLI:Started VW process!\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:root:Processing training data: [PosixPath('/opt/ml/input/data/training/local-joined-data-1597300760.csv')]\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m final_regressor = /opt/ml/model/vw.model\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m predictions = /dev/stdout\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m Num weight bits = 18\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m learning rate = 0.5\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m initial_t = 0\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m power_t = 0.5\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m using no cache\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m Reading datafile = \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m num sources = 1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m average  since         example        example  current  current  current\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m loss     last          counter         weight    label  predict features\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 1.000000 1.000000            1            1.0        3 3:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 1.000000 1.000000            2            2.0        3 3:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 1.000000 1.000000            4            4.0        3 3:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 1.000000 1.000000            8            8.0        3 3:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 0.625063 0.250125           16           16.0        3 4:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 0.312613 0.000163           32           32.0        3 4:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 0.156369 0.000125           64           64.0        3 4:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 0.078256 0.000144          128          128.0        3 4:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 0.039206 0.000155          256          256.0        3 4:0.999200        1\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m finished run\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m number of examples = 400\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m weighted example sum = 400.000000\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m weighted label sum = 0.000000\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m average loss = 0.025149\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m total feature number = 400\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m \n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m INFO:root:Model learned using 400 training experiences.\n",
      "\u001b[36malgo-1-whyov_1  |\u001b[0m 2020-08-13 06:39:31,851 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmpjboqt5rk_algo-1-whyov_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpjboqt5rk/algo-1-whyov Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "bandits_experiment.train_next_model(input_data_s3_prefix=bandits_experiment.last_joined_job_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bandits-1597300705-model-id-1597300768'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits_experiment.last_trained_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Model 'bandits-1597300705-model-id-1597300768' is ready to deploy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Found new model! Trying to replace Model ID: bandits-1597300705-model-id-1597300721 with Model ID: bandits-1597300705-model-id-1597300768\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [24] [INFO] Handling signal: hup\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [24] [INFO] Hang up: Master\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [39] [INFO] Booting worker with pid: 39\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [40] [INFO] Booting worker with pid: 40\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] creating an instance of VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] successfully created VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/downloads/6jbeFT0P/vw.model']\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300768\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [41] [INFO] Booting worker with pid: 41\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [28] [INFO] Worker exiting (pid: 28)\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [25] [INFO] Worker exiting (pid: 25)\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] creating an instance of VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] successfully created VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/downloads/6jbeFT0P/vw.model']\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300768\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [42] [INFO] Booting worker with pid: 42\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] creating an instance of VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] successfully created VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/downloads/6jbeFT0P/vw.model']\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300768\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Started VW process!\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] creating an instance of VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] successfully created VWModel\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-p', '/dev/stdout', '--quiet', '--testonly', '-i', '/opt/ml/downloads/6jbeFT0P/vw.model']\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Loaded weights successfully for Model ID:bandits-1597300705-model-id-1597300768\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [31] [INFO] Worker exiting (pid: 31)\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [2020-08-13 06:39:42 +0000] [34] [INFO] Worker exiting (pid: 34)\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Started VW process!\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Started VW process!\r\n",
      "\u001b[36malgo-1-psdo0_1  |\u001b[0m [08/13/2020 06:39:42 INFO 139656814556928] Started VW process!\r\n"
     ]
    }
   ],
   "source": [
    "bandits_experiment.deploy_model(model_id=bandits_experiment.last_trained_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bandits-1597300705-model-id-1597300768'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandits_experiment.last_hosted_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuously Deploy New Bandit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cells explained the individual steps in the training workflow. To train a model to convergence, we will continually train the model based on data collected with client application interactions. We demonstrate the continual training loop in a single cell below.\n",
    "\n",
    "We include the evaluation step at each step before deployment to compare the model just trained (`last_trained_model_id`) against the model that is currently hosted (`last_hosted_model_id`). If you want the loops to finish faster, you can set `do_evaluation=False` in the cell below.\n",
    "\n",
    "Details of each joining and training job can be tracked in `join_db` and `model_db` respectively. `model_db` also stores the evaluation scores. When you have multiple experiments, you can check their status in `experiment_db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You can monitor your Training/Hosting evaluation metrics on this [CloudWatch Dashboard](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#dashboards:name=bandits-1597300705;start=PT1H)\n",
       "\n",
       "(Note: This would need Trained/Hosted Models to be evaluated in order to publish Evaluation Scores)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_evaluation = True\n",
    "\n",
    "# You can also monitor your loop progress on CloudWatch Dashboard \n",
    "display(Markdown(bandits_experiment.get_cloudwatch_dashboard_details()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    #### Loop 1\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator:Successfully create S3 bucket 'sagemaker-us-east-1-835319576252' for athena queries\n",
      "INFO:orchestrator:Started dummy local joining job...\n",
      "INFO:orchestrator:Splitting data into train/evaluation set with ratio of 0.85\n",
      "INFO:orchestrator:Joined data will be stored under s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300788\n",
      "INFO:orchestrator:_upload_data_buffer_as_joined_data_format put s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300788/train/local-joined-data-1597300789.csv\n",
      "INFO:orchestrator:_upload_data_buffer_as_joined_data_format put s3://sagemaker-us-east-1-835319576252/bandits-1597300705/joined_data/bandits-1597300705-join-job-id-1597300788/eval/local-joined-data-1597300789.csv\n",
      "INFO:orchestrator:Use last trained model bandits-1597300705-model-id-1597300768 as pre-trained model for training\n",
      "INFO:orchestrator:Starting training job for ModelId 'bandits-1597300705-model-id-1597300797''\n",
      "INFO:orchestrator:Training job will be executed in 'local' mode\n",
      "WARNING:sagemaker.estimator:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpce5k3r3h_algo-1-g73hb_1 ... \n",
      "\u001b[1BAttaching to tmpce5k3r3h_algo-1-g73hb_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 2020-08-13 06:39:59,754 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 2020-08-13 06:39:59,767 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 2020-08-13 06:39:59,778 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 2020-08-13 06:39:59,787 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"sagemaker_estimator\": \"RLEstimator\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"pretrained_model\": \"/opt/ml/input/data/pretrained_model\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"current_host\": \"algo-1-g73hb\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"framework_module\": null,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"algo-1-g73hb\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"exploration_policy\": \"egreedy\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"epsilon\": 0.001,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"num_policies\": 3,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"num_arms\": 5,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"cfa_type\": \"dr\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"pretrained_model\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m             \"ContentType\": \"application/x-sagemaker-model\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"job_name\": \"bandits-1597300705-model-id-1597300797\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"master_hostname\": \"algo-1-g73hb\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300797/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"module_name\": \"train-vw\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"num_cpus\": 8,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"current_host\": \"algo-1-g73hb\",\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m             \"algo-1-g73hb\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m     \"user_entry_point\": \"train-vw.py\"\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HOSTS=[\"algo-1-g73hb\"]\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HPS={\"cfa_type\":\"dr\",\"epsilon\":0.001,\"exploration_policy\":\"egreedy\",\"num_arms\":5,\"num_policies\":3}\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_USER_ENTRY_POINT=train-vw.py\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_estimator\":\"RLEstimator\"}\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-g73hb\",\"hosts\":[\"algo-1-g73hb\"]}\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"pretrained_model\":{\"ContentType\":\"application/x-sagemaker-model\",\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_CHANNELS=[\"pretrained_model\",\"training\"]\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_CURRENT_HOST=algo-1-g73hb\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_MODULE_NAME=train-vw\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_FRAMEWORK_MODULE=\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_NUM_CPUS=8\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300797/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator\":\"RLEstimator\"},\"channel_input_dirs\":{\"pretrained_model\":\"/opt/ml/input/data/pretrained_model\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-g73hb\",\"framework_module\":null,\"hosts\":[\"algo-1-g73hb\"],\"hyperparameters\":{\"cfa_type\":\"dr\",\"epsilon\":0.001,\"exploration_policy\":\"egreedy\",\"num_arms\":5,\"num_policies\":3},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"pretrained_model\":{\"ContentType\":\"application/x-sagemaker-model\",\"TrainingInputMode\":\"File\"},\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bandits-1597300705-model-id-1597300797\",\"log_level\":20,\"master_hostname\":\"algo-1-g73hb\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-835319576252/bandits-1597300705/training_jobs/bandits-1597300705-model-id-1597300797/source/sourcedir.tar.gz\",\"module_name\":\"train-vw\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-g73hb\",\"hosts\":[\"algo-1-g73hb\"]},\"user_entry_point\":\"train-vw.py\"}\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_USER_ARGS=[\"--cfa_type\",\"dr\",\"--epsilon\",\"0.001\",\"--exploration_policy\",\"egreedy\",\"--num_arms\",\"5\",\"--num_policies\",\"3\"]\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_CHANNEL_PRETRAINED_MODEL=/opt/ml/input/data/pretrained_model\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HP_EXPLORATION_POLICY=egreedy\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HP_EPSILON=0.001\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HP_NUM_POLICIES=3\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HP_NUM_ARMS=5\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m SM_HP_CFA_TYPE=dr\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/vowpal_wabbit/python:/vowpal_wabbit/build/python:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m /usr/bin/python train-vw.py --cfa_type dr --epsilon 0.001 --exploration_policy egreedy --num_arms 5 --num_policies 3\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:root:channels ['pretrained_model', 'training']\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:root:hps: {'cfa_type': 'dr', 'epsilon': 0.001, 'exploration_policy': 'egreedy', 'num_arms': 5, 'num_policies': 3}\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:root:Loading model from /opt/ml/input/data/pretrained_model/vw.model\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:VW CLI:creating an instance of VWModel\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:VW CLI:successfully created VWModel\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:VW CLI:command: ['vw', '--cb_explore', '5', '--epsilon', '0.001', '-i', '/opt/ml/input/data/pretrained_model/vw.model', '-f', '/opt/ml/model/vw.model', '--save_resume', '-p', '/dev/stdout']\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:VW CLI:Started VW process!\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:root:Processing training data: [PosixPath('/opt/ml/input/data/training/local-joined-data-1597300789.csv')]\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m final_regressor = /opt/ml/model/vw.model\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m predictions = /dev/stdout\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m Num weight bits = 18\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m learning rate = 0.5\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m initial_t = 0\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m power_t = 0.5\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m using no cache\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m Reading datafile = \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m num sources = 1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m average  since         example        example  current  current  current\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m loss     last          counter         weight    label  predict features\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 1.000000 1.000000            1            1.0        4 4:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 1.000000 1.000000            2            2.0        4 4:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 1.000000 1.000000            4            4.0        4 4:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 0.875000 0.750000            8            8.0        4 4:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 0.562563 0.250125           16           16.0        4 2:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 0.281363 0.000163           32           32.0        4 2:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 0.140769 0.000175           64           64.0        4 2:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 0.070456 0.000144          128          128.0        4 2:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 0.035308 0.000160          256          256.0        4 2:0.999200        1\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m finished run\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m number of examples = 423\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m weighted example sum = 423.000000\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m weighted label sum = 0.000000\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m average loss = 0.021430\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m total feature number = 423\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m \n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m INFO:root:Model learned using 423 training experiences.\n",
      "\u001b[36malgo-1-g73hb_1  |\u001b[0m 2020-08-13 06:40:00,271 sagemaker-containers INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Failed to delete: /tmp/tmpce5k3r3h/algo-1-g73hb Please remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mtmpce5k3r3h_algo-1-g73hb_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "total_loops = 2 # Increase for higher accuracy\n",
    "batch_size = 500 # Model will be trained after every 500 data instances\n",
    "rewards_list = []\n",
    "\n",
    "local_mode = bandits_experiment.local_mode\n",
    "for loop_no in range(total_loops):\n",
    "    print(f\"\"\"\n",
    "    #### Loop {loop_no+1}\n",
    "    \"\"\")\n",
    "    \n",
    "    # Generate experiences and log them\n",
    "    for i in range(batch_size):\n",
    "        user_id, user_context = sim_app.choose_random_user()\n",
    "        action, event_id, model_id, action_prob, sample_prob = predictor.get_action(obs=user_context.tolist())\n",
    "        reward = sim_app.get_reward(user_id, action, event_id, model_id, action_prob, sample_prob, local_mode)\n",
    "        rewards_list.append(reward)\n",
    "    \n",
    "    \n",
    "    # publish rewards sum for this batch to CloudWatch for monitoring \n",
    "    bandits_experiment.cw_logger.publish_rewards_for_simulation(\n",
    "        bandits_experiment.experiment_id,\n",
    "        sum(rewards_list[-batch_size:])/batch_size\n",
    "    )\n",
    "    \n",
    "    # Local/Athena join\n",
    "    if local_mode:\n",
    "        bandits_experiment.ingest_joined_data(sim_app.joined_data_buffer,ratio=0.85)\n",
    "    else:\n",
    "        print(\"Waiting for firehose to flush data to s3...\")\n",
    "        time.sleep(60) \n",
    "        rewards_s3_prefix = bandits_experiment.ingest_rewards(sim_app.rewards_buffer)\n",
    "        bandits_experiment.join(rewards_s3_prefix, ratio=0.85)\n",
    "    \n",
    "    # Train \n",
    "    bandits_experiment.train_next_model(\n",
    "        input_data_s3_prefix=bandits_experiment.last_joined_job_train_data)\n",
    "    \n",
    "    if do_evaluation:\n",
    "    # Evaluate\n",
    "        bandits_experiment.evaluate_model(\n",
    "            input_data_s3_prefix=bandits_experiment.last_joined_job_eval_data,\n",
    "            evaluate_model_id=bandits_experiment.last_trained_model_id)\n",
    "        eval_score_last_trained_model = bandits_experiment.get_eval_score(\n",
    "            evaluate_model_id=bandits_experiment.last_trained_model_id,\n",
    "            eval_data_path=bandits_experiment.last_joined_job_eval_data)\n",
    "\n",
    "        bandits_experiment.evaluate_model(\n",
    "            input_data_s3_prefix=bandits_experiment.last_joined_job_eval_data,\n",
    "            evaluate_model_id=bandits_experiment.last_hosted_model_id)\n",
    "\n",
    "        eval_score_last_hosted_model = bandits_experiment.get_eval_score(\n",
    "            evaluate_model_id=bandits_experiment.last_hosted_model_id, \n",
    "            eval_data_path=bandits_experiment.last_joined_job_eval_data)\n",
    "    \n",
    "        # Deploy\n",
    "        if eval_score_last_trained_model <= eval_score_last_hosted_model:\n",
    "            bandits_experiment.deploy_model(model_id=bandits_experiment.last_trained_model_id)\n",
    "        else:\n",
    "            print('Not deploying model in loop {}'.format(loop_no))\n",
    "    else:\n",
    "        bandits_experiment.deploy_model(model_id=bandits_experiment.last_trained_model_id)\n",
    "    \n",
    "    sim_app.clear_buffer()\n",
    "\n",
    "print(f\"Total time taken to complete {total_loops} loops: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Bandit Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the model performance along the training loop by plotting the rolling mean reward across client interactions. Here rolling mean reward is calculated on the last `rolling_window` number of data instances, where each data instance corresponds to a single client interaction. \n",
    "\n",
    "> Note: The plot below cannot be generated if the notebook has been restarted after the execution of the cell above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "def get_mean_reward(reward_lst, batch_size=batch_size):\n",
    "    mean_rew=list()\n",
    "    for r in range(len(reward_lst)):\n",
    "        mean_rew.append(sum(reward_lst[:r+1]) * 1.0 / ((r+1)*batch_size))\n",
    "    return mean_rew\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "lwd = 5\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors=plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "\n",
    "rolling_window = 100\n",
    "rewards_df = pd.DataFrame(rewards_list, columns=['bandit']).rolling(rolling_window).mean()\n",
    "rewards_df['oracle'] = sum(sim_app.opt_rewards) / len(sim_app.opt_rewards)\n",
    "\n",
    "rewards_df.plot(y=['bandit','oracle'],linewidth=lwd)\n",
    "plt.legend(loc=4, prop={'size': 20})\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlabel('Data instances (models were updated every %s data instances)' % batch_size, size=20)\n",
    "plt.ylabel('Rolling Mean Reward', size=30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df.bandit.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three DynamoDB tables (experiment, join, model) from the bandits application above (e.g. `experiment_id='bandits-...'`). To better maintain them, we should remove the related records if the experiment has finished. Besides, having an endpoint running will incur costs. Therefore, we delete these components as part of the clean up process.\n",
    "\n",
    "> Only execute the clean up cells below when you've finished the current experiment and want to deprecate everything associated with it. After the cleanup, the Cloudwatch metrics will not be populated anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     bandits_experiment.clean_resource(experiment_id=bandits_experiment.experiment_id)\n",
    "\n",
    "#     bandits_experiment.clean_table_records(experiment_id=bandits_experiment.experiment_id)\n",
    "# except:\n",
    "#     print('Ignore any errors.  This is OK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "550.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
