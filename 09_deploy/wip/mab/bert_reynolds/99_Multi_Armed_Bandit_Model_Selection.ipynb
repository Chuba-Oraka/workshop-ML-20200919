{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandits with Amazon SageMaker RL\n",
    "\n",
    "We demonstrate how you can manage your own contextual multi-armed bandit workflow on SageMaker using the built-in [Vowpal Wabbit (VW)](https://github.com/VowpalWabbit/vowpal_wabbit) container to train and deploy contextual bandit models. We show how to train these models that interact with a live environment (using a simulated client application) and continuously update the model with efficient exploration.\n",
    "\n",
    "### Why Contextual Bandits?\n",
    "\n",
    "Wherever we look to personalize content for a user (content layout, ads, search, product recommendations, etc.), contextual bandits come in handy. Traditional personalization methods collect a training dataset, build a model and deploy it for generating recommendations. However, the training algorithm does not inform us on how to collect this dataset, especially in a production system where generating poor recommendations lead to loss of revenue. Contextual bandit algorithms help us collect this data in a strategic manner by trading off between exploiting known information and exploring recommendations which may yield higher benefits. The collected data is used to update the personalization model in an online manner. Therefore, contextual bandits help us train a personalization model while minimizing the impact of poor recommendations.\n",
    "\n",
    "### What does this notebook contain?\n",
    "\n",
    "To implement the exploration-exploitation strategy, we need an iterative training and deployment system that: (1) recommends an action using the contextual bandit model based on user context, (2) captures the implicit feedback over time and (3) continuously trains the model with incremental interaction data. In this notebook, we show how to setup the infrastructure needed for such an iterative learning system. While the example demonstrates a bandits application, these continual learning systems are useful more generally in dynamic scenarios where models need to be continually updated to capture the recent trends in the data (e.g. tracking fraud behaviors based on detection mechanisms or tracking user interests over time). \n",
    "\n",
    "In a typical supervised learning setup, the model is trained with a SageMaker training job and it is hosted behind a SageMaker hosting endpoint. The client application calls the endpoint for inference and receives a response. In bandits, the client application also sends the reward (a score assigned to each recommendation generated by the model) back for subsequent model training. These rewards will be part of the dataset for the subsequent model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Resources\n",
    "\n",
    "* https://aws.amazon.com/blogs/machine-learning/power-contextual-bandits-using-continual-learning-with-amazon-sagemaker-rl/\n",
    "* https://getstream.io/blog/introduction-contextual-bandits/\n",
    "* https://github.com/VowpalWabbit/\n",
    "* https://github.com/aws/sagemaker-rl-container\n",
    "* [Bandit Experiment Manager](./common/sagemaker_rl/orchestrator/workflow/manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/multi_armed_bandit_maximize_reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/multi_armed_bandit_traffic_shift.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contextual bandit training workflow is controlled by an experiment manager provided with this example. The client application (say a recommender system application) pings the SageMaker hosting endpoint that is serving the bandits model. The application sends the state (user features) as input and receives an action (recommendation) as a response. The client application sends the recommended action to the user and stores the received reward in S3. The SageMaker hosted endpoint also stores inference data (state and action) in S3. The experiment manager joins the inference data with rewards as they become available. The joined data is used to update the model with a SageMaker training job. The updated model is evaluated offline and deployed to SageMaker hosting endpoint if the model evaluation score improves upon prior models. \n",
    "\n",
    "Below is an overview of the subsequent cells in the notebook: \n",
    "* Configuration: this includes details related to SageMaker and other AWS resources needed for the bandits application. \n",
    "* IAM role setup: this creates appropriate execution role and shows how to add more permissions to the role, needed for specific AWS resources.\n",
    "* Client application (Environment): this shows the simulated client application.\n",
    "* Step-by-step bandits model development: \n",
    " 1. Model Initialization (random or warm-start) \n",
    " 2. Deploy the First Model \n",
    " 3. Initialize the Client Application \n",
    " 4. Reward Ingestion \n",
    " 5. Model Re-training and Re-deployment \n",
    "* Bandits model deployment with the end-to-end loop. \n",
    "* Visualization \n",
    "* Cleanup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Mode\n",
    "\n",
    "To facilitate experimentation, we provide a `local_mode` that runs the contextual bandit example using the SageMaker Notebook instance itself instead of SageMaker training and hosting instances. The workflow remains the same in `local_mode`, but runs much faster for small datasets. Hence, it is a useful tool for experimentation and debugging. However, it will not scale to production use cases with high throughput and large datasets. \n",
    "\n",
    "In `local_mode`, the training, evaluation and hosting is done with the SageMaker VW docker container. The join is not handled by SageMaker, and is done inside the client application. The rest of the textual explanation assumes that the notebook is run in SageMaker mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import sagemaker\n",
    "\n",
    "sys.path.append('common')\n",
    "sys.path.append('common/sagemaker_rl')\n",
    "\n",
    "from markdown_helper import *\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "The configuration for the bandits application can be specified in a `config.yaml` file as can be seen below. It configures the AWS resources needed. The DynamoDB tables are used to store metadata related to experiments, models and data joins. The `private_resource` specifices the SageMaker instance types and counts used for training, evaluation and hosting. The SageMaker container image is used for the bandits application. This config file also contains algorithm and SageMaker-specific setups.  Note that all the data generated and used for the bandits application will be stored in `s3://sagemaker-{REGION}-{AWS_ACCOUNT_ID}/{experiment_id}/`.\n",
    "\n",
    "Please make sure that the `num_arms` parameter in the config is equal to the number of actions in the client application (which is defined in the cell below).\n",
    "\n",
    "The Docker image is defined here:  https://github.com/aws/sagemaker-rl-container/blob/master/vw/docker/8.7.0/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config.yaml'\n",
    "with open(config_file, 'r') as yaml_file:\n",
    "    config = yaml.load(yaml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional permissions for the IAM role\n",
    "IAM role requires additional permissions for [AWS CloudFormation](https://aws.amazon.com/cloudformation/), [Amazon DynamoDB](https://aws.amazon.com/dynamodb/), [Amazon Kinesis Data Firehose](https://aws.amazon.com/kinesis/data-firehose/) and [Amazon Athena](https://aws.amazon.com/athena/). Make sure the SageMaker role you are using has the permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(generate_help_for_experiment_manager_permissions(sagemaker_role)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client application (Environment)\n",
    "The client application simulates a live environment that uses the SageMaker bandits model to serve recommendations to users. The logic of reward generation resides in the client application. We simulate the online learning loop with feedback.  The data consists of 5 classes, and if the agent selects the right class, then reward is 1.  Otherwise, the agent obtains a reward 0.\n",
    "\n",
    "The workflow of the client application is as follows:\n",
    "- The client application picks a context at random, which is sent to the SageMaker endpoint for retrieving an action.\n",
    "- SageMaker endpoint returns an action, associated probability and `event_id`.\n",
    "- Since this simulator was generated from the dataset, we know the true class for that context. \n",
    "- The application reports the reward to the experiment manager using S3, along with the corresponding `event_id`.\n",
    "\n",
    "`event_id` is a unique identifier for each interaction. It is used to join inference data `<state, action, action probability>` with the rewards. \n",
    "\n",
    "In a later cell of this notebook, where there exists a hosted endpoint, we illustrate how the client application interacts with the endpoint and gets the recommended action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step bandits model development\n",
    "\n",
    "[**Bandit Experiment Manager**](./common/sagemaker_rl/orchestrator/workflow/manager/) is the top level class for all the Bandits/RL and continual learning workflows. Similar to the estimators in the [Sagemaker Python SDK](https://github.com/aws/sagemaker-python-sdk), `ExperimentManager` contains methods for training, deployment and evaluation. It keeps track of the job status and reflects current progress in the workflow.\n",
    "\n",
    "Start the application using the `ExperimentManager` class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "experiment_name = 'bandits-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ExperimentManager` will create a AWS CloudFormation Stack of additional resources needed for the Bandit experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orchestrator.workflow.manager.experiment_manager import ExperimentManager\n",
    "\n",
    "bandit_experiment_manager = ExperimentManager(config, experiment_id=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bandit_experiment_manager.clean_resource(experiment_id=bandit_experiment_manager.experiment_id)\n",
    "    bandit_experiment_manager.clean_table_records(experiment_id=bandit_experiment_manager.experiment_id)\n",
    "except:\n",
    "    print('Ignore any errors.  Errors are OK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_experiment_manager = ExperimentManager(config, experiment_id=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Bandit Model\n",
    "To start a new experiment, we need to initialize the first bandit model or \"policy\" in reinforcement learning terminology.  \n",
    "\n",
    "If we have historical data in the format `(state, action, action probability, reward)`, we can perform a \"warm start\" and learn the bandit model offline.  \n",
    "\n",
    "However, let's assume we are starting with no historical data and initialize a random bandit model using `initialize_first_model()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bandit_experiment_manager.initialize_first_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ^^ Ignore `Failed to delete: /tmp/...` message above.  This is OK. ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Experiment State:  TRAINED\n",
    "`training_state`: `TRAINED`\n",
    "\n",
    "Remember the `last_trained_model_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_experiment_manager._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Bandit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training and evaluation is done, we can deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the model_id of the last model trained.\n",
    "print('Deploying newly-trained bandit model: {}'.format(bandit_experiment_manager.last_trained_model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Deploying bandit model_id {}'.format(bandit_experiment_manager.last_trained_model_id))\n",
    "\n",
    "bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Experiment State\n",
    "`hosting_state`: `DEPLOYED`\n",
    "\n",
    "The `last_trained_model_id` and `last_hosted_model_id` are now the same as we just deployed the bandit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bandit_experiment_manager._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Client Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the last trained model is hosted, client application can send out the state, hit the endpoint, and receive the recommended action. There are 2 models that we want to test:  model1 and model2.  This translates to 2 actions that the bandit model will predict.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r step_functions_pipeline_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_endpoint_name = step_functions_pipeline_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_1_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "waiter = client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=model_1_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "model1 = Predictor(endpoint_name=model_1_endpoint_name,\n",
    "                   sagemaker_session=sess,\n",
    "                   content_type='application/json',\n",
    "                   model_name='saved_model',\n",
    "                   model_version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"This is not good.\"]\n",
    "\n",
    "model1_predicted_classes = model1.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(model1_predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">Model 1 SageMaker REST Endpoint</a></b>'.format(region, model_1_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r step_functions_pipeline_endpoint_name_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_endpoint_name = step_functions_pipeline_endpoint_name_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_2_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=model_2_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "model2 = Predictor(endpoint_name=model_2_endpoint_name,\n",
    "                   sagemaker_session=sess,\n",
    "                   content_type='application/json',\n",
    "                   model_name='saved_model',\n",
    "                   model_version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"This is not good.\"]\n",
    "\n",
    "model2_predicted_classes = model2.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(model2_predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">Model 2 SageMaker REST Endpoint</a></b>'.format(region, model_2_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "class Simulation():\n",
    "    def __init__(self, data, num_events, bandit_model, bert_model_map):\n",
    "        self.bandit_model = bandit_model\n",
    "        self.bert_model_map = bert_model_map\n",
    "        \n",
    "        self.num_actions = 2\n",
    "\n",
    "        df_reviews = pd.read_csv(data, \n",
    "                                 delimiter='\\t', \n",
    "                                 quoting=csv.QUOTE_NONE,\n",
    "                                 compression='gzip')\n",
    "        df_scrubbed = df_reviews[['review_id', 'star_rating']].sample(n=num_events) #.query('star_rating == 1')\n",
    "        df_scrubbed = df_scrubbed.reset_index()\n",
    "        df_scrubbed.shape\n",
    "        np_reviews = df_scrubbed.to_numpy()\n",
    "\n",
    "        np_reviews = np.delete(np_reviews, 0, 1)\n",
    "        \n",
    "        # Last column is label, the rest are the features (contexts)\n",
    "        labels = np_reviews[:, -1] #.astype(int)\n",
    "        contexts = np_reviews[:, :-1]\n",
    "\n",
    "        self.contexts = contexts\n",
    "        self.labels = labels\n",
    "\n",
    "        print(self.contexts)\n",
    "        print(self.labels)\n",
    "        \n",
    "        self.optimal_rewards = [1]\n",
    "        self.rewards_buffer = []\n",
    "        self.joined_data_buffer = []\n",
    "\n",
    "    def choose_random_context(self):\n",
    "        context_index = np.random.choice(self.contexts.shape[0])\n",
    "        context = self.contexts[context_index]\n",
    "        return context_index, context    \n",
    "\n",
    "    def clear_buffer(self):\n",
    "        self.rewards_buffer.clear()\n",
    "        self.joined_data_buffer.clear()    \n",
    "\n",
    "    def get_reward(self, \n",
    "                   context_index, \n",
    "                   action, \n",
    "                   event_id, \n",
    "                   bandit_model_id, \n",
    "                   action_prob, \n",
    "                   sample_prob, \n",
    "                   local_mode):\n",
    "#        print('context_index {}'.format(context_index))       \n",
    "    \n",
    "        context = [context_index]\n",
    "    \n",
    "#        print('context {}'.format(context))\n",
    "        label = self.labels[context_index]\n",
    "#        print('label {}'.format(label))\n",
    "#        print('action {}'.format(action))\n",
    "#        print('event_id {}'.format(event_id))\n",
    "#        print('bandit_model_id {}'.format(bandit_model_id))\n",
    "#        print('action_prob {}'.format(action_prob))\n",
    "\n",
    "        bert_model = self.bert_model_map[action]\n",
    "        bert_predicted_class = bert_model.predict([context])[0]\n",
    "#        print('bert_predicted_class {}'.format(bert_predicted_class))\n",
    "        \n",
    "        if bert_predicted_class == label:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "#        print('reward {}'.format(reward))\n",
    "\n",
    "        if local_mode:\n",
    "            json_blob = {\"reward\": reward,\n",
    "                         \"event_id\": event_id,\n",
    "                         \"action\": action,\n",
    "                         \"action_prob\": action_prob,\n",
    "                         \"model_id\": bandit_model_id,\n",
    "                         \"observation\": context,\n",
    "                         \"sample_prob\": sample_prob}\n",
    "            \n",
    "            self.joined_data_buffer.append(json_blob)\n",
    "        else:\n",
    "            json_blob = {\"reward\": reward, \"event_id\": event_id}\n",
    "            self.rewards_buffer.append(json_blob)\n",
    "        \n",
    "        return reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_model = bandit_experiment_manager.predictor\n",
    "\n",
    "sim_app = Simulation(data='./data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz',\n",
    "                     num_events=100,\n",
    "                     bandit_model=bandit_model,\n",
    "                     bert_model_map={\n",
    "                                     1: model1,\n",
    "                                     2: model2\n",
    "                                    }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that `num_arms` specified in `config.yaml` is equal to the total unique actions in the simulation application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing {} BERT models'.format(sim_app.num_actions))\n",
    "\n",
    "assert sim_app.num_actions == bandit_experiment_manager.config[\"algor\"][\"algorithms_parameters\"][\"num_arms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "context_index, context = sim_app.choose_random_context()\n",
    "action, event_id, bandit_model_id, action_prob, sample_prob = bandit_model.get_action(obs=context) # obs=context)\n",
    "\n",
    "print('event ID: {}\\nbert_model_id: {}\\naction_probability: {}'.format(event_id, action, action_prob, bandit_model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client application generates a reward after receiving the recommended action and stores the tuple `<eventID, reward>` in S3. In this case, reward is 1 if predicted action is the true class, and 0 otherwise. SageMaker hosting endpoint saves all the inferences `<eventID, state, action, action probability>` to S3 using [**Kinesis Firehose**](https://aws.amazon.com/kinesis/data-firehose/). The `ExperimentManager` joins the reward with state, action and action probability using [**Amazon Athena**](https://aws.amazon.com/athena/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "local_mode = bandit_experiment_manager.local_mode\n",
    "num_events = 100 # collect events\n",
    "print('Collecting {} events...'.format(num_events))\n",
    "\n",
    "# Generate experiences and log them\n",
    "for i in range(num_events):\n",
    "    context_index, context = sim_app.choose_random_context()\n",
    "    action, event_id, bandit_model_id, action_prob, sample_prob = bandit_model.get_action(obs=context)\n",
    "\n",
    "    # print('Context Index {}'.format(context_index))\n",
    "    # print('Context {}'.format(context))    \n",
    "    # print('Action (bert model to invoke) {}'.format(action))\n",
    "    # print('Event ID {}'.format(event_id))\n",
    "    # print('Bandit Model ID {}'.format(bandit_model_id))\n",
    "    # print('Action Probability {}'.format(action_prob))\n",
    "    # print('Sample Probability {}'.format(sample_prob))\n",
    "    \n",
    "    reward = sim_app.get_reward(context_index=context_index, \n",
    "                                action=action, \n",
    "                                event_id=event_id, \n",
    "                                bandit_model_id=bandit_model_id, \n",
    "                                action_prob=action_prob, \n",
    "                                sample_prob=sample_prob, \n",
    "                                local_mode=local_mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Bandit Model Training Data\n",
    "\n",
    "Join `Event` and `Reward` data to and upload to S3 in the following format:\n",
    "\n",
    "```\n",
    "{\n",
    " 'reward': -1, # -1 if the model is wrong, +1 if the model is correct\n",
    " 'event_id': 131181492351609994318271340276526219266, # unique event id\n",
    " 'action': 1, # suggested action (bert_model_id 1 or 2)\n",
    " 'action_prob': 0.9995, # probability that the suggested action is correct\n",
    " 'model_id': 'bandits-1597631299-model-id-1597631304', # unique bandit_model_id\n",
    " 'observation': [54], # feature (review_id)\n",
    " 'sample_prob': 0.43410828171830174 \n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if local_mode:\n",
    "    print('Using local mode with memory buffers.')\n",
    "    print(sim_app.joined_data_buffer)\n",
    "    bandit_experiment_manager.ingest_joined_data(sim_app.joined_data_buffer)\n",
    "else:\n",
    "    print(\"Using production mode with Kinesis Firehose.  Waiting to flush to S3...\")\n",
    "    time.sleep(60) # Wait for firehose to flush data to S3\n",
    "    rewards_s3_prefix = bandit_experiment_manager.ingest_rewards(sim_app.rewards_buffer)\n",
    "    bandit_experiment_manager.join(rewards_s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Experiment Status:  Joined\n",
    "`joining_state`:  `SUCCEEDED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_experiment_manager._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Bandit Model Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bandit model training data {}'.format(bandit_experiment_manager.last_joined_job_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "bandit_model_train_data_s3_uri = S3Downloader.list(bandit_experiment_manager.last_joined_job_train_data)[0]\n",
    "print(bandit_model_train_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "bandit_model_train_data = S3Downloader.read_file(bandit_model_train_data_s3_uri)\n",
    "print(bandit_model_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Bandit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a new model with newly collected experiences, and host the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trained bandit model id {}'.format(bandit_experiment_manager.last_trained_model_id))\n",
    "\n",
    "bandit_experiment_manager.train_next_model(input_data_s3_prefix=bandit_experiment_manager.last_joined_job_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore ^^ `Failed to delete` Error Above ^^ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Bandit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Deploying bandit model id {}'.format(bandit_experiment_manager.last_hosted_model_id))\n",
    "\n",
    "bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuously Deploy New Bandit Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cells explained the individual steps in the training workflow. To train a model to convergence, we will continually train the model based on data collected with client application interactions. We demonstrate the continual training loop in a single cell below.\n",
    "\n",
    "We include the evaluation step at each step before deployment to compare the model just trained (`last_trained_model_id`) against the model that is currently hosted (`last_hosted_model_id`). \n",
    "Details of each joining and training job can be tracked in `join_db` and `model_db` respectively. `model_db` also stores the evaluation scores. When you have multiple experiments, you can check their status in `experiment_db`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Current Model Against Historical Model\n",
    "\n",
    "After every training cycle, we evaluate if the newly trained model is better than the one currently deployed. Using the evaluation dataset, we evaluate how the new model would perform compared to the model that is currently deployed. SageMaker RL supports offline evaluation by performing counterfactual analysis (CFA). By default, we apply [**doubly robust (DR) estimation**](https://arxiv.org/pdf/1103.4601.pdf) method. The bandit policy tries to minimize the cost (1-reward) value in this case, so a smaller evaluation score indicates better policy performance.\n",
    "\n",
    "_If you want the loops to finish faster, you can skip the evaluation by setting `do_evaluation=False` in the cell below._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_evaluation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(bandit_experiment_manager.get_cloudwatch_dashboard_details()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "total_loops = 5 # Increase for higher accuracy\n",
    "retrain_batch_size = 100 # Model will be trained after every `batch_size` number of data instances\n",
    "rewards_list = []\n",
    "\n",
    "event_list = []\n",
    "\n",
    "local_mode = bandit_experiment_manager.local_mode\n",
    "for loop_no in range(total_loops):\n",
    "    print(f\"\"\"\n",
    "    #############\n",
    "    #### Loop {loop_no+1}\n",
    "    #############\n",
    "    \"\"\")\n",
    "    \n",
    "    # Generate experiences and log them\n",
    "    for i in range(retrain_batch_size):\n",
    "        context_index, context = sim_app.choose_random_context()\n",
    "        action, event_id, bandit_model_id, action_prob, sample_prob = bandit_model.get_action(obs=context)\n",
    "\n",
    "        print('Context Index {}'.format(context_index))\n",
    "        print('Context {}'.format(context))    \n",
    "        print('Action (bert model to invoke) {}'.format(action))\n",
    "        print('Event ID {}'.format(event_id))\n",
    "        print('Bandit Model ID {}'.format(bandit_model_id))\n",
    "        print('Action Probability {}'.format(action_prob))\n",
    "        print('Sample Probability {}'.format(sample_prob))\n",
    "\n",
    "        # reward = sim_app.get_reward(user_id, action, event_id, bandit_model_id, action_prob, sample_prob, local_mode)\n",
    "        reward = sim_app.get_reward(context_index=context_index, \n",
    "                                    action=action, \n",
    "                                    event_id=event_id, \n",
    "                                    bandit_model_id=bandit_model_id, \n",
    "                                    action_prob=action_prob, \n",
    "                                    sample_prob=sample_prob, \n",
    "                                    local_mode=local_mode)\n",
    "\n",
    "        rewards_list.append(reward)  \n",
    "        \n",
    "    # Publish rewards sum for this batch to CloudWatch for monitoring \n",
    "    bandit_experiment_manager.cw_logger.publish_rewards_for_simulation(\n",
    "        bandit_experiment_manager.experiment_id,\n",
    "        sum(rewards_list[-retrain_batch_size:])/retrain_batch_size\n",
    "    )\n",
    "    \n",
    "    # Join the events and rewards data to use for the next bandit-model training job\n",
    "    if local_mode:\n",
    "        bandit_experiment_manager.ingest_joined_data(sim_app.joined_data_buffer,\n",
    "                                                     ratio=0.90)\n",
    "    else:\n",
    "        # Kinesis Firehose => S3 => Athena\n",
    "        print(\"Waiting for firehose to flush data to s3...\")\n",
    "        time.sleep(60) \n",
    "        rewards_s3_prefix = bandit_experiment_manager.ingest_rewards(sim_app.rewards_buffer)\n",
    "        bandit_experiment_manager.join(rewards_s3_prefix, ratio=0.90)\n",
    "    \n",
    "    # Train \n",
    "    bandit_experiment_manager.train_next_model(\n",
    "        input_data_s3_prefix=bandit_experiment_manager.last_joined_job_train_data)\n",
    "\n",
    "    # Evaluate and/or deploy the new bandit model\n",
    "    if do_evaluation:\n",
    "        bandit_experiment_manager.evaluate_model(\n",
    "            input_data_s3_prefix=bandit_experiment_manager.last_joined_job_eval_data,\n",
    "            evaluate_model_id=bandit_experiment_manager.last_trained_model_id)\n",
    "\n",
    "        eval_score_last_trained_model = bandit_experiment_manager.get_eval_score(\n",
    "            evaluate_model_id=bandit_experiment_manager.last_trained_model_id,\n",
    "            eval_data_path=bandit_experiment_manager.last_joined_job_eval_data)\n",
    "\n",
    "        bandit_experiment_manager.evaluate_model(\n",
    "            input_data_s3_prefix=bandit_experiment_manager.last_joined_job_eval_data,\n",
    "            evaluate_model_id=bandit_experiment_manager.last_hosted_model_id)\n",
    "\n",
    "        eval_score_last_hosted_model = bandit_experiment_manager.get_eval_score(\n",
    "            evaluate_model_id=bandit_experiment_manager.last_hosted_model_id, \n",
    "            eval_data_path=bandit_experiment_manager.last_joined_job_eval_data)\n",
    "    \n",
    "        if eval_score_last_trained_model <= eval_score_last_hosted_model:\n",
    "            bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id)\n",
    "        else:\n",
    "            print('Not deploying model in loop {}'.format(loop_no))\n",
    "    else:\n",
    "        # Just deploy the new bandit model without evaluating against previous model\n",
    "        bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id)\n",
    "    \n",
    "    sim_app.clear_buffer()\n",
    "    \n",
    "print(f\"Total time taken to complete {total_loops} loops: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Bandit Model Joined Event and Reward Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bandit model event and reward data {}'.format(bandit_experiment_manager.last_joined_job_eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "bandit_model_joined_event_and_reward_data_s3_uri = S3Downloader.list(bandit_experiment_manager.last_joined_job_eval_data)[0]\n",
    "print(bandit_model_joined_event_and_reward_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "bandit_model_joined_event_and_reward_data = S3Downloader.read_file(bandit_model_joined_event_and_reward_data_s3_uri)\n",
    "print(bandit_model_joined_event_and_reward_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Joined Event and Reward Data from S3 to Local Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_model_joined_event_and_reward_data_file_path = './'\n",
    "bandit_model_joined_event_and_reward_data = S3Downloader.download(bandit_model_joined_event_and_reward_data_s3_uri, bandit_model_joined_event_and_reward_data_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandit_model_joined_event_and_reward_data_local_file_path = bandit_model_joined_event_and_reward_data_s3_uri.split('/')[-1]\n",
    "\n",
    "df_joined_events_and_rewards = pd.read_csv(bandit_model_joined_event_and_reward_data_local_file_path, \n",
    "                                    delimiter=',', \n",
    "                                    quoting=csv.QUOTE_ALL)\n",
    "df_joined_events_and_rewards.query('action==1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Experiment State\n",
    "\n",
    "`evaluation_state`: `EVALUATED`\n",
    "\n",
    "The same bandit_model_id will appear in both `last_trained_model_id` and `last_evaluation_job_id` fields below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bandit_experiment_manager._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Bandit Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the bandit-model training performance by plotting the rolling mean reward across client interactions.\n",
    "\n",
    "Here rolling mean reward is calculated on the last `rolling_window` number of data instances, where each data instance corresponds to a single client interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_reward(reward_lst, batch_size=retrain_batch_size):\n",
    "    mean_rew=list()\n",
    "    for r in range(len(reward_lst)):\n",
    "        mean_rew.append(sum(reward_lst[:r+1]) * 1.0 / ((r+1)*retrain_batch_size))\n",
    "    return mean_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 100\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "lwd = 5\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors=plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "\n",
    "rewards_df = pd.DataFrame(rewards_list, columns=['bandit']).rolling(rolling_window).mean()\n",
    "#rewards_df['oracle'] = sum(sim_app.optimal_rewards) / len(sim_app.optimal_rewards)\n",
    "\n",
    "rewards_df.plot(y=['bandit'], # 'oracle'], \n",
    "                linewidth=lwd)\n",
    "plt.legend(loc=4, prop={'size': 20})\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlabel('Data instances (models were updated every %s data instances)' % retrain_batch_size, size=20)\n",
    "plt.ylabel('Rolling {} Mean Reward'.format(rolling_window), size=30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Invocation Metrics for the BERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "    \n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#metricsV2:namespace=AWS/SageMaker;dimensions=EndpointName,VariantName;search={}\">Model 1 SageMaker REST Endpoint</a></b>'.format(region, model_1_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#metricsV2:namespace=AWS/SageMaker;dimensions=EndpointName,VariantName;search={}\">Model 2 SageMaker REST Endpoint</a></b>'.format(region, model_2_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the Reward Data Across All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df.bandit.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three DynamoDB tables (experiment, join, model) from the bandits application above (e.g. `experiment_id='bandits-...'`). To better maintain them, we should remove the related records if the experiment has finished. Besides, having an endpoint running will incur costs. Therefore, we delete these components as part of the clean up process.\n",
    "\n",
    "Only execute the clean up cells below when you've finished the current experiment and want to deprecate everything associated with it. \n",
    "\n",
    "_The CloudWatch metrics will be removed during this cleanup step._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Cleaning up experiment_id {}'.format(bandit_experiment_manager.experiment_id))\n",
    "# try:\n",
    "#     bandit_experiment_manager.clean_resource(experiment_id=bandit_experiment_manager.experiment_id)\n",
    "#     bandit_experiment_manager.clean_table_records(experiment_id=bandit_experiment_manager.experiment_id)\n",
    "#     sim_app.clear_buffer()\n",
    "# except:\n",
    "#     print('Ignore any errors.  Errors are OK.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "550.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
