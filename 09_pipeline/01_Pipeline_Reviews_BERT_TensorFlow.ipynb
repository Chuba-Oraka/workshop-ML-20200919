{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Required Modules\n",
    "\n",
    "Now import the required modules from the Step Functions SDK and AWS SageMaker, configure an S3 bucket, and get the AWS SageMaker execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stepfunctions==1.0.0.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.0.7)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from stepfunctions==1.0.0.7) (5.3.1)\n",
      "Requirement already satisfied: boto3>=1.9.213 in /home/ec2-user/.local/lib/python3.6/site-packages (from stepfunctions==1.0.0.7) (1.12.41)\n",
      "Requirement already satisfied: sagemaker>=1.42.8 in /home/ec2-user/.local/lib/python3.6/site-packages (from stepfunctions==1.0.0.7) (1.55.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from boto3>=1.9.213->stepfunctions==1.0.0.7) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from boto3>=1.9.213->stepfunctions==1.0.0.7) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.41 in /home/ec2-user/.local/lib/python3.6/site-packages (from boto3>=1.9.213->stepfunctions==1.0.0.7) (1.15.41)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (20.3)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (1.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (1.6.0)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==0.1.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (1.18.2)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from sagemaker>=1.42.8->stepfunctions==1.0.0.7) (3.11.3)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/.local/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.41->boto3>=1.9.213->stepfunctions==1.0.0.7) (1.25.9)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/.local/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.41->boto3>=1.9.213->stepfunctions==1.0.0.7) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/.local/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.41->boto3>=1.9.213->stepfunctions==1.0.0.7) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/.local/lib/python3.6/site-packages (from packaging>=20.0->sagemaker>=1.42.8->stepfunctions==1.0.0.7) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/.local/lib/python3.6/site-packages (from packaging>=20.0->sagemaker>=1.42.8->stepfunctions==1.0.0.7) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/.local/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker>=1.42.8->stepfunctions==1.0.0.7) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/.local/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker>=1.42.8->stepfunctions==1.0.0.7) (46.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install stepfunctions==1.0.0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stepfunctions\n",
    "import logging\n",
    "\n",
    "from stepfunctions.template.pipeline import TrainingPipeline\n",
    "stepfunctions.set_stream_logger(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the AWS SageMaker Execution Role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a Policy to Your SageMaker Role in IAM\n",
    "\n",
    "**If you are running this notebook on an Amazon SageMaker notebook instance**, the IAM role assumed by your notebook instance needs permission to create and run workflows in AWS Step Functions. To provide this permission to the role, do the following.\n",
    "\n",
    "1. Open the Amazon [SageMaker console](https://console.aws.amazon.com/sagemaker/). \n",
    "2. Select **Notebook instances** and choose the name of your notebook instance\n",
    "3. Under **Permissions and encryption** select the role ARN to view the role on the IAM console\n",
    "4. Choose **Attach policies** and search for `AWSStepFunctionsFullAccess`.\n",
    "5. Select the check box next to `AWSStepFunctionsFullAccess` and choose **Attach policy**\n",
    "\n",
    "If you are running this notebook in a local environment, the SDK will use your configured AWS CLI configuration. For more information, see [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n",
    "\n",
    "Next, create an execution role in IAM for Step Functions. \n",
    "\n",
    "## Create an Execution Role for Step Functions\n",
    "\n",
    "You need an execution role so that you can create and execute workflows in Step Functions.\n",
    "\n",
    "1. Go to the [IAM console](https://console.aws.amazon.com/iam/)\n",
    "2. Select **Roles** and then **Create role**.\n",
    "3. Under **Choose the service that will use this role** select **Step Functions**\n",
    "4. Choose **Next** until you can enter a **Role name**\n",
    "5. Enter a name such as `StepFunctionsWorkflowExecutionRole` and then select **Create role**\n",
    "\n",
    "\n",
    "Attach a policy to the role you created. The following steps attach a policy that provides full access to Step Functions, however as a good practice you should only provide access to the resources you need.  \n",
    "\n",
    "1. Under the **Permissions** tab, click **Add inline policy**\n",
    "2. Enter the following in the **JSON** tab\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:CreateTransformJob\",\n",
    "                \"sagemaker:DescribeTransformJob\",\n",
    "                \"sagemaker:StopTransformJob\",\n",
    "                \"sagemaker:CreateTrainingJob\",\n",
    "                \"sagemaker:DescribeTrainingJob\",\n",
    "                \"sagemaker:StopTrainingJob\",\n",
    "                \"sagemaker:CreateHyperParameterTuningJob\",\n",
    "                \"sagemaker:DescribeHyperParameterTuningJob\",\n",
    "                \"sagemaker:StopHyperParameterTuningJob\",\n",
    "                \"sagemaker:CreateModel\",\n",
    "                \"sagemaker:CreateEndpointConfig\",\n",
    "                \"sagemaker:CreateEndpoint\",\n",
    "                \"sagemaker:DeleteEndpointConfig\",\n",
    "                \"sagemaker:DeleteEndpoint\",\n",
    "                \"sagemaker:UpdateEndpoint\",\n",
    "                \"sagemaker:ListTags\",\n",
    "                \"lambda:InvokeFunction\",\n",
    "                \"sqs:SendMessage\",\n",
    "                \"sns:Publish\",\n",
    "                \"ecs:RunTask\",\n",
    "                \"ecs:StopTask\",\n",
    "                \"ecs:DescribeTasks\",\n",
    "                \"dynamodb:GetItem\",\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:UpdateItem\",\n",
    "                \"dynamodb:DeleteItem\",\n",
    "                \"batch:SubmitJob\",\n",
    "                \"batch:DescribeJobs\",\n",
    "                \"batch:TerminateJob\",\n",
    "                \"glue:StartJobRun\",\n",
    "                \"glue:GetJobRun\",\n",
    "                \"glue:GetJobRuns\",\n",
    "                \"glue:BatchStopJobRun\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"events:PutTargets\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:DescribeRule\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTrainingJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTransformJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTuningJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForECSTaskRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForBatchJobsRule\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "3. Choose **Review policy** and give the policy a name such as `StepFunctionsWorkflowExecutionPolicy`\n",
    "4. Choose **Create policy**. You will be redirected to the details page for the role.\n",
    "5. Copy the **Role ARN** at the top of the **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable scikit_processing_job_s3_output_prefix\n"
     ]
    }
   ],
   "source": [
    "%store -r scikit_processing_job_s3_output_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TT0310826689\n"
     ]
    }
   ],
   "source": [
    "print(scikit_processing_job_s3_output_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Scikit Processing Job Name: TT0310826689\n"
     ]
    }
   ],
   "source": [
    "#scikit_processing_job_s3_output_prefix = 'sagemaker-scikit-learn-2020-04-10-04-44-09-647'\n",
    "\n",
    "scikit_processing_job_s3_output_prefix = 'TT0310826689'\n",
    "\n",
    "#s3://sagemaker-us-east-1-828802286385//output/bert-train/part-algo-1-amazon_reviews_us_Apparel_v1_00.tfrecord\n",
    "\n",
    "print('Previous Scikit Processing Job Name: {}'.format(scikit_processing_job_s3_output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_train = '{}/output/bert-train'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_validation = '{}/output/bert-validation'.format(scikit_processing_job_s3_output_prefix)\n",
    "prefix_test = '{}/output/bert-test'.format(scikit_processing_job_s3_output_prefix)\n",
    "\n",
    "train_s3_uri = 's3://{}/{}'.format(bucket, prefix_train)\n",
    "validation_s3_uri = 's3://{}/{}'.format(bucket, prefix_validation)\n",
    "test_s3_uri = 's3://{}/{}'.format(bucket, prefix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-828802286385/TT0310826689/output/bert-train\n",
      "2020-04-21 15:17:52 2842017956 part-algo-1-amazon_reviews_us_Apparel_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 3256644636 part-algo-1-amazon_reviews_us_Books_v1_01.tfrecord\n",
      "2020-04-21 15:17:52  817388348 part-algo-1-amazon_reviews_us_Digital_Music_Purchase_v1_00.tfrecord\n",
      "2020-04-21 15:17:52  392412003 part-algo-1-amazon_reviews_us_Furniture_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 1293434433 part-algo-1-amazon_reviews_us_Home_Improvement_v1_00.tfrecord\n",
      "2020-04-21 15:17:52  171699748 part-algo-1-amazon_reviews_us_Luggage_v1_00.tfrecord\n",
      "2020-04-21 15:17:52  450276402 part-algo-1-amazon_reviews_us_Musical_Instruments_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 1313804795 part-algo-1-amazon_reviews_us_Pet_Products_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 2379851198 part-algo-1-amazon_reviews_us_Toys_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 4395944875 part-algo-1-amazon_reviews_us_Wireless_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 1702370740 part-algo-2-amazon_reviews_us_Automotive_v1_00.tfrecord\n",
      "2020-04-21 15:17:52 1681960843 part-algo-2-amazon_reviews_us_Books_v1_02.tfrecord\n",
      "2020-04-21 15:17:52   50969090 part-algo-2-amazon_reviews_us_Digital_Software_v1_00.tfrecord\n",
      "2020-04-21 15:17:52   70316784 part-algo-2-amazon_reviews_us_Gift_Card_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 3030381387 part-algo-2-amazon_reviews_us_Home_v1_00.tfrecord\n",
      "2020-04-21 15:21:28   48926304 part-algo-2-amazon_reviews_us_Major_Appliances_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 1297907882 part-algo-2-amazon_reviews_us_Office_Products_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 2125453822 part-algo-2-amazon_reviews_us_Shoes_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 2569817433 part-algo-2-amazon_reviews_us_Video_DVD_v1_00.tfrecord\n",
      "2020-04-21 15:21:28  879004721 part-algo-3-amazon_reviews_us_Baby_v1_00.tfrecord\n",
      "2020-04-21 15:21:28  904382714 part-algo-3-amazon_reviews_us_Camera_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 1935776473 part-algo-3-amazon_reviews_us_Digital_Video_Download_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 1178550706 part-algo-3-amazon_reviews_us_Grocery_v1_00.tfrecord\n",
      "2020-04-21 15:21:28  850161526 part-algo-3-amazon_reviews_us_Jewelry_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 2402943768 part-algo-3-amazon_reviews_us_Mobile_Apps_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 1139168876 part-algo-3-amazon_reviews_us_Outdoors_v1_00.tfrecord\n",
      "2020-04-21 15:21:28  175529858 part-algo-3-amazon_reviews_us_Software_v1_00.tfrecord\n",
      "2020-04-21 15:21:28  900310265 part-algo-3-amazon_reviews_us_Video_Games_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 2510200513 part-algo-4-amazon_reviews_us_Beauty_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 6210395292 part-algo-4-amazon_reviews_us_Digital_Ebook_Purchase_v1_00.tfrecord\n",
      "2020-04-21 15:21:28   71730527 part-algo-4-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord\n",
      "2020-04-21 15:21:27 2620777353 part-algo-4-amazon_reviews_us_Health_Personal_Care_v1_00.tfrecord\n",
      "2020-04-21 15:21:28 2413444587 part-algo-4-amazon_reviews_us_Kitchen_v1_00.tfrecord\n",
      "2020-04-21 15:21:28   52423605 part-algo-4-amazon_reviews_us_Mobile_Electronics_v1_00.tfrecord\n",
      "2020-04-21 15:25:20 3430205662 part-algo-4-amazon_reviews_us_PC_v1_00.tfrecord\n",
      "2020-04-21 15:25:20 2372618152 part-algo-4-amazon_reviews_us_Sports_v1_00.tfrecord\n",
      "2020-04-21 15:25:20  202050384 part-algo-4-amazon_reviews_us_Video_v1_00.tfrecord\n",
      "2020-04-21 15:25:20 5157162534 part-algo-5-amazon_reviews_us_Books_v1_00.tfrecord\n",
      "2020-04-21 15:25:20 2594939522 part-algo-5-amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tfrecord\n",
      "2020-04-21 15:25:20 1544626099 part-algo-5-amazon_reviews_us_Electronics_v1_00.tfrecord\n",
      "2020-04-21 15:25:20  360162781 part-algo-5-amazon_reviews_us_Home_Entertainment_v1_00.tfrecord\n",
      "2020-04-21 15:25:21 1256250570 part-algo-5-amazon_reviews_us_Lawn_and_Garden_v1_00.tfrecord\n",
      "2020-04-21 15:25:20 2464401663 part-algo-5-amazon_reviews_us_Music_v1_00.tfrecord\n",
      "2020-04-21 15:25:20   43089602 part-algo-5-amazon_reviews_us_Personal_Care_Appliances_v1_00.tfrecord\n",
      "2020-04-21 15:25:20  857024888 part-algo-5-amazon_reviews_us_Tools_v1_00.tfrecord\n",
      "2020-04-21 15:25:21  470796922 part-algo-5-amazon_reviews_us_Watches_v1_00.tfrecord\n"
     ]
    }
   ],
   "source": [
    "print(train_s3_uri)\n",
    "!aws s3 ls $train_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-828802286385/TT0310826689/output/bert-train', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-828802286385/TT0310826689/output/bert-validation', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-828802286385/TT0310826689/output/bert-test', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n"
     ]
    }
   ],
   "source": [
    "s3_input_train_data = sagemaker.s3_input(s3_data=train_s3_uri, distribution='ShardedByS3Key') \n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=validation_s3_uri, distribution='ShardedByS3Key')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=test_s3_uri, distribution='ShardedByS3Key')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: src/tf_bert_reviews.py: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat src/tf_bert_reviews.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "train_steps_per_epoch=100\n",
    "validation_steps=100\n",
    "test_steps=100\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.p3.2xlarge'\n",
    "train_volume_size=1024\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "max_seq_length=128\n",
    "freeze_bert_layer=True\n",
    "enable_sagemaker_debugger=True                    # Enable SM Debugger\n",
    "#use_parameter_server=(train_instance_count >= 2) # Use Parameter Server if distributed cluster\n",
    "input_mode='Pipe'                                 # 'File' or 'Pipe' Mode\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       train_instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_volume_size=train_volume_size,\n",
    "                       py_version='py3',\n",
    "                       framework_version='2.1.0',\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "                                        'run_validation': run_validation,\n",
    "                                        'run_test': run_test,\n",
    "                                        'run_sample_predictions': run_sample_predictions},\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions,\n",
    "#                       rules=rules,\n",
    "#                       debugger_hook_config=hook_config,                       \n",
    "                       train_max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.fit(inputs={'train': s3_input_train_data, \n",
    "#                       'validation': s3_input_validation_data,\n",
    "#                       'test': s3_input_test_data\n",
    "#                      },\n",
    "#                      experiment_config=experiment_config,                   \n",
    "#                      wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pipeline with the Step Functions SDK\n",
    "\n",
    "A typical task for a data scientist is to train a model and deploy that model to an endpoint. Without the Step Functions SDK, this is a four step process on SageMaker that includes the following.\n",
    "\n",
    "1. Training the model\n",
    "2. Creating the model on SageMaker\n",
    "3. Creating an endpoint configuration\n",
    "4. Deploying the trained model to the configured endpoint\n",
    "\n",
    "The Step Functions SDK provides the [TrainingPipeline](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/pipelines.html#stepfunctions.template.pipeline.train.TrainingPipeline) API to simplify this procedure. The following configures `pipeline` with the necessary parameters to define a training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-828802286385/TT0310826689/output/bert-train\n"
     ]
    }
   ],
   "source": [
    "print(train_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the StepFunctionsWorkflowExecutionRole ARN from above\n",
    "workflow_execution_role = 'arn:aws:iam::828802286385:role/StepFunctionsWorkflowExecutionRole' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-828802286385/sagemaker/tensorflow-mnist/training-runs\n"
     ]
    }
   ],
   "source": [
    "model_output_s3_bucket = '{}/sagemaker/tensorflow-mnist/training-runs'.format(bucket)\n",
    "print(model_output_s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No file named \"tf_bert_reviews.py\" was found in directory \"src\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-03238d240d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkflow_execution_role\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_s3_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0ms3_bucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_output_s3_bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/stepfunctions/template/pipeline/train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, role, inputs, s3_bucket, client, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training-pipeline-{date}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_workflow_definition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_template\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_input_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/stepfunctions/template/pipeline/train.py\u001b[0m in \u001b[0;36mbuild_workflow_definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/estimator-source'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         )\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/stepfunctions/steps/sagemaker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_id, estimator, job_name, data, hyperparameters, mini_batch_size, experiment_config, wait_for_completion, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sagemaker/workflow/airflow.py\u001b[0m in \u001b[0;36mtraining_config\u001b[0;34m(estimator, inputs, job_name, mini_batch_size)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \"\"\"\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mtrain_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_base_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mtrain_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TrainingJobName\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sagemaker/workflow/airflow.py\u001b[0m in \u001b[0;36mtraining_base_config\u001b[0;34m(estimator, inputs, job_name, mini_batch_size)\u001b[0m\n\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_workflow_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mdefault_bucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_bucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mprepare_workflow_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mconstructor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mapplicable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_prepare_for_training\u001b[0;34m(self, job_name)\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# source directory. We are intentionally not handling it because this is a critical error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mvalidate_source_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# if we are in local mode with local_code=True. We want the container to just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sagemaker/fw_utils.py\u001b[0m in \u001b[0;36mvalidate_source_dir\u001b[0;34m(script, directory)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             raise ValueError(\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;34m'No file named \"{}\" was found in directory \"{}\".'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No file named \"tf_bert_reviews.py\" was found in directory \"src\"."
     ]
    }
   ],
   "source": [
    "pipeline = TrainingPipeline(\n",
    "    estimator=estimator,\n",
    "    role=workflow_execution_role,\n",
    "    inputs=train_s3_uri,\n",
    "    s3_bucket=model_output_s3_bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now view the workflow definition, and also visualize it as a graph. This workflow and graph represent your training pipeline.\n",
    "\n",
    "#### View the workflow definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.workflow.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the workflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and execute the pipeline on AWS Step Functions\n",
    "\n",
    "Create the pipeline in AWS Step Functions with [create](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the workflow with [execute](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.execute). A link will be provided after the following cell is executed. Following this link, you can monitor your pipeline execution on Step Functions' console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "events = execution.list_events()\n",
    "\n",
    "endpoint_name = json.loads(events[18]['taskScheduledEventDetails']['parameters'])['EndpointName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_output = json.loads(events[21]['stateExitedEventDetails']['output'])\n",
    "event_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_arn = event_output['EndpointArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Retieve the predictor from the pipeline/workflow above\n",
    "# predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.c5.2xlarge')\n",
    "\n",
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the Endpoint\n",
    "\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#train_data = np.load('{}/train_data.npy'.format(local_data_path))\n",
    "#train_labels = np.load('{}/train_labels.npy'.format(local_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formats of the input and the output data correspond directly to the request and response formats of the `Predict` method in the [TensorFlow Serving REST API](https://www.tensorflow.org/serving/api_rest). SageMaker's TensforFlow Serving endpoints can also accept additional input formats that are not part of the TensorFlow REST API, including the simplified JSON format, line-delimited JSON objects (\"jsons\" or \"jsonlines\"), and CSV data.\n",
    "\n",
    "In this example we are using a `numpy` array as input, which will be serialized into the simplified JSON format. In addition, TensorFlow Serving can also process multiple items at once as you can see in the following code. You can find the complete documentation on how to make predictions against a TensorFlow Serving SageMaker endpoint [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst#making-predictions-against-a-sagemaker-endpoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the prediction result from the TensorFlow 2.0 model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]\n",
    "    label = train_labels[i]\n",
    "    print('Prediction is {}, Label is {}, Matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
