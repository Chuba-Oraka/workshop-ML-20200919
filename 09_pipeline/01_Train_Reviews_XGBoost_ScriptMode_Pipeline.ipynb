{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q xgboost==0.90\n",
    "!pip install -q stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Add a policy to your SageMaker role in IAM\n",
    "\n",
    "**If you are running this notebook on an Amazon SageMaker notebook instance**, the IAM role assumed by your notebook instance needs permission to create and run workflows in AWS Step Functions. To provide this permission to the role, do the following.\n",
    "\n",
    "1. Open the Amazon [SageMaker console](https://console.aws.amazon.com/sagemaker/). \n",
    "2. Select **Notebook instances** and choose the name of your notebook instance\n",
    "3. Under **Permissions and encryption** select the role ARN to view the role on the IAM console\n",
    "4. Choose **Attach policies** and search for `AWSStepFunctionsFullAccess`.\n",
    "5. Select the check box next to `AWSStepFunctionsFullAccess` and choose **Attach policy**\n",
    "\n",
    "If you are running this notebook in a local environment, the SDK will use your configured AWS CLI configuration. For more information, see [Configuring the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html).\n",
    "\n",
    "Next, create an execution role in IAM for Step Functions. \n",
    "\n",
    "### Create an execution role for Step Functions\n",
    "\n",
    "You need an execution role so that you can create and execute workflows in Step Functions.\n",
    "\n",
    "1. Go to the [IAM console](https://console.aws.amazon.com/iam/)\n",
    "2. Select **Roles** and then **Create role**.\n",
    "3. Under **Choose the service that will use this role** select **Step Functions**\n",
    "4. Choose **Next** until you can enter a **Role name**\n",
    "5. Enter a name such as `StepFunctionsWorkflowExecutionRole` and then select **Create role**\n",
    "\n",
    "\n",
    "Attach a policy to the role you created. The following steps attach a policy that provides full access to Step Functions, however as a good practice you should only provide access to the resources you need.  \n",
    "\n",
    "1. Under the **Permissions** tab, click **Add inline policy**\n",
    "2. Enter the following in the **JSON** tab\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sagemaker:CreateTransformJob\",\n",
    "                \"sagemaker:DescribeTransformJob\",\n",
    "                \"sagemaker:StopTransformJob\",\n",
    "                \"sagemaker:CreateTrainingJob\",\n",
    "                \"sagemaker:DescribeTrainingJob\",\n",
    "                \"sagemaker:StopTrainingJob\",\n",
    "                \"sagemaker:CreateHyperParameterTuningJob\",\n",
    "                \"sagemaker:DescribeHyperParameterTuningJob\",\n",
    "                \"sagemaker:StopHyperParameterTuningJob\",\n",
    "                \"sagemaker:CreateModel\",\n",
    "                \"sagemaker:CreateEndpointConfig\",\n",
    "                \"sagemaker:CreateEndpoint\",\n",
    "                \"sagemaker:DeleteEndpointConfig\",\n",
    "                \"sagemaker:DeleteEndpoint\",\n",
    "                \"sagemaker:UpdateEndpoint\",\n",
    "                \"sagemaker:ListTags\",\n",
    "                \"lambda:InvokeFunction\",\n",
    "                \"sqs:SendMessage\",\n",
    "                \"sns:Publish\",\n",
    "                \"ecs:RunTask\",\n",
    "                \"ecs:StopTask\",\n",
    "                \"ecs:DescribeTasks\",\n",
    "                \"dynamodb:GetItem\",\n",
    "                \"dynamodb:PutItem\",\n",
    "                \"dynamodb:UpdateItem\",\n",
    "                \"dynamodb:DeleteItem\",\n",
    "                \"batch:SubmitJob\",\n",
    "                \"batch:DescribeJobs\",\n",
    "                \"batch:TerminateJob\",\n",
    "                \"glue:StartJobRun\",\n",
    "                \"glue:GetJobRun\",\n",
    "                \"glue:GetJobRuns\",\n",
    "                \"glue:BatchStopJobRun\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": \"sagemaker.amazonaws.com\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"events:PutTargets\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:DescribeRule\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTrainingJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTransformJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTuningJobsRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForECSTaskRule\",\n",
    "                \"arn:aws:events:*:*:rule/StepFunctionsGetEventsForBatchJobsRule\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "3. Choose **Review policy** and give the policy a name such as `StepFunctionsWorkflowExecutionPolicy`\n",
    "4. Choose **Create policy**. You will be redirected to the details page for the role.\n",
    "5. Copy the **Role ARN** at the top of the **Summary**\n",
    "\n",
    "### Import the required modules from the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r spark_processing_job_s3_output_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Spark Processing Job Name: amazon-reviews-spark-processor-2020-03-28-04-41-56\n"
     ]
    }
   ],
   "source": [
    "print('Previous Spark Processing Job Name: {}'.format(spark_processing_job_s3_output_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train\n",
      "s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation\n",
      "s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-test\n"
     ]
    }
   ],
   "source": [
    "prefix_train = '{}/output/tfidf-train'.format(spark_processing_job_s3_output_prefix)\n",
    "prefix_validation = '{}/output/tfidf-validation'.format(spark_processing_job_s3_output_prefix)\n",
    "prefix_test = '{}/output/tfidf-test'.format(spark_processing_job_s3_output_prefix)\n",
    "\n",
    "tfidf_train_path = './{}'.format(prefix_train)\n",
    "tfidf_validation_path = './{}'.format(prefix_validation)\n",
    "tfidf_test_path = './{}'.format(prefix_test)\n",
    "\n",
    "tfidf_train_s3_uri = 's3://{}/{}'.format(bucket, prefix_train)\n",
    "tfidf_validation_s3_uri = 's3://{}/{}'.format(bucket, prefix_validation)\n",
    "tfidf_test_s3_uri = 's3://{}/{}'.format(bucket, prefix_test)\n",
    "\n",
    "print(tfidf_train_s3_uri)\n",
    "print(tfidf_validation_s3_uri)\n",
    "print(tfidf_test_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-test', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "s3_input_train_data = sagemaker.s3_input(s3_data=tfidf_train_s3_uri, content_type='text/csv')\n",
    "s3_input_validation_data = sagemaker.s3_input(s3_data=tfidf_validation_s3_uri, content_type='text/csv')\n",
    "s3_input_test_data = sagemaker.s3_input(s3_data=tfidf_test_s3_uri, content_type='text/csv')\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-28 04:49:32          0 _SUCCESS\r\n",
      "2020-03-28 04:48:52 1839696670 part-00000-75daeb1d-1477-4fd5-8436-f52122d97da1-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $tfidf_train_s3_uri/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-28 04:50:27          0 _SUCCESS\r\n",
      "2020-03-28 04:50:25  102405623 part-00000-870d4bbb-d00e-4572-ac1e-9fa130c60189-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $tfidf_validation_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-28 04:51:04          0 _SUCCESS\r\n",
      "2020-03-28 04:51:01  102471944 part-00000-5ca41884-1bc3-41dd-a1d1-869b714e36f6-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $tfidf_test_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train/_SUCCESS to amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train/_SUCCESS\n",
      "download: s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train/part-00000-75daeb1d-1477-4fd5-8436-f52122d97da1-c000.csv to amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train/part-00000-75daeb1d-1477-4fd5-8436-f52122d97da1-c000.csv\n",
      "download: s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation/_SUCCESS to amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation/_SUCCESS\n",
      "download: s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation/part-00000-870d4bbb-d00e-4572-ac1e-9fa130c60189-c000.csv to amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation/part-00000-870d4bbb-d00e-4572-ac1e-9fa130c60189-c000.csv\n",
      "download: s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-test/_SUCCESS to amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-test/_SUCCESS\n",
      "download: s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-test/part-00000-5ca41884-1bc3-41dd-a1d1-869b714e36f6-c000.csv to amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-test/part-00000-5ca41884-1bc3-41dd-a1d1-869b714e36f6-c000.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $tfidf_train_s3_uri $tfidf_train_path\n",
    "!aws s3 cp --recursive $tfidf_validation_s3_uri $tfidf_validation_path\n",
    "!aws s3 cp --recursive $tfidf_test_s3_uri $tfidf_test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\r\n",
      "import argparse\r\n",
      "import pickle as pkl\r\n",
      "import pandas as pd\r\n",
      "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\r\n",
      "from sklearn import metrics\r\n",
      "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
      "import nltk\r\n",
      "import re\r\n",
      "import xgboost as xgb\r\n",
      "from xgboost import XGBClassifier\r\n",
      "import glob\r\n",
      "\r\n",
      "\r\n",
      "# Note:  header=None\r\n",
      "def load_dataset(path, sep, header):\r\n",
      "    data = pd.concat([pd.read_csv(f, sep=sep, header=header) for f in glob.glob('{}/*.csv'.format(path))], ignore_index = True)\r\n",
      "\r\n",
      "    labels = data.iloc[:,0]\r\n",
      "    features = data.drop(data.columns[0], axis=1)\r\n",
      "    \r\n",
      "    if header==None:\r\n",
      "        # Adjust the column names after dropped the 0th column above\r\n",
      "        # New column names are 0 (inclusive) to len(features.columns) (exclusive)\r\n",
      "        new_column_names = list(range(0, len(features.columns)))\r\n",
      "        features.columns = new_column_names\r\n",
      "\r\n",
      "    return features, labels\r\n",
      "\r\n",
      "\r\n",
      "def model_fn(model_dir):\r\n",
      "    \"\"\"\r\n",
      "    :param: model_dir The directory where model files are stored.\r\n",
      "    :return: a model\r\n",
      "    \"\"\"\r\n",
      "    model = pkl.load(open(model_dir, 'rb'))\r\n",
      "\r\n",
      "    print(type(model))\r\n",
      "    \r\n",
      "    return model\r\n",
      "\r\n",
      "\r\n",
      "def input_fn(request_body, request_content_type):\r\n",
      "    \"\"\"\r\n",
      "    Deserialize the Invoke request body into an object we can perform prediction on\r\n",
      "    \"\"\"\r\n",
      "    \"\"\"An input_fn that loads a pickled object\"\"\"\r\n",
      "    if request_content_type == \"application/json\":\r\n",
      "        pass\r\n",
      "    else:\r\n",
      "        # Handle other content-types here or raise an Exception\r\n",
      "        # if the content type is not supported.\r\n",
      "        pass\r\n",
      "\r\n",
      "    print(request_body)    \r\n",
      "    return [1]\r\n",
      "\r\n",
      "\r\n",
      "def predict_fn(input_object, model):\r\n",
      "    \"\"\"\r\n",
      "    Perform prediction on the deserialized object, with the loaded model\r\n",
      "    \"\"\"\r\n",
      "    return [1]\r\n",
      "\r\n",
      "\r\n",
      "def output_fn(output, output_content_type):\r\n",
      "    \"\"\"\r\n",
      "    Serialize the prediction result into the desired response content type\r\n",
      "    \"\"\"\r\n",
      "    #return json.dumps({'output':output.reshape(-1).tolist()}), output_content_type\r\n",
      "    print(output)\r\n",
      "    return [1]\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument('--objective', type=str, default='binary:logistic')\r\n",
      "    parser.add_argument('--max-depth', type=int, default=5)\r\n",
      "    parser.add_argument('--num-round', type=int, default=1)   \r\n",
      "    parser.add_argument('--train-data', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\r\n",
      "    parser.add_argument('--validation-data', type=str, default=os.environ['SM_CHANNEL_VALIDATION'])\r\n",
      "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\r\n",
      "\r\n",
      "    args, _ = parser.parse_known_args()   \r\n",
      "    objective  = args.objective    \r\n",
      "    max_depth  = args.max_depth\r\n",
      "    num_round  = args.num_round\r\n",
      "    train_data   = args.train_data\r\n",
      "    validation_data = args.validation_data    \r\n",
      "    model_dir  = args.model_dir\r\n",
      "    \r\n",
      "    # Load transformed features (is_positive_sentiment, f0, f1, ...)    \r\n",
      "    X_train, y_train = load_dataset(train_data, ',', header=None)\r\n",
      "    X_validation, y_validation = load_dataset(validation_data, ',', header=None)\r\n",
      "\r\n",
      "    xgb_estimator = XGBClassifier(objective=objective,\r\n",
      "                                  num_round=num_round,\r\n",
      "                                  max_depth=max_depth)\r\n",
      "\r\n",
      "    xgb_estimator.fit(X_train, y_train)\r\n",
      "\r\n",
      "    # TODO:  use the model_dir that is passed in through args\r\n",
      "    #        (currently SM_MODEL_DIR)\r\n",
      "    os.makedirs(model_dir, exist_ok=True)\r\n",
      "    model_path = os.path.join(model_dir, 'xgboost-model')\r\n",
      "\r\n",
      "    pkl.dump(xgb_estimator, open(model_path, 'wb'))\r\n",
      "    print('Wrote model to {}'.format(model_path))\r\n",
      "    \r\n",
      "    xgb_estimator_restored = pkl.load(open(model_path, 'rb'))\r\n",
      "    type(xgb_estimator_restored) \r\n",
      "    \r\n",
      "    preds_validation = xgb_estimator_restored.predict(X_validation)\r\n",
      "    print('Validation Accuracy: ', accuracy_score(y_validation, preds_validation))\r\n",
      "    print('Validation Precision: ', precision_score(y_validation, preds_validation, average=None))\r\n",
      "        \r\n",
      "    print(classification_report(y_validation, preds_validation))\r\n",
      "\r\n",
      "    # TODO:  Convert to preds_validation_0_or_1\r\n",
      "    \r\n",
      "    ##############\r\n",
      "#   Note:  roc_auc is causing the following:\r\n",
      "#   ValueError: multiclass format is not supported\r\n",
      "#     Traceback (most recent call last):\r\n",
      "#   File \"/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n",
      "#     \"__main__\", mod_spec)\r\n",
      "#   File \"/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\r\n",
      "#     exec(code, run_globals)\r\n",
      "#   File \"/opt/ml/code/xgboost_reviews.py\", line 75, in <module>\r\n",
      "#     auc = round(metrics.roc_auc_score(y_validation, preds_validation), 4)\r\n",
      "#   File \"/miniconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\", line 356, in roc_auc_score\r\n",
      "#     sample_weight=sample_weight)\r\n",
      "#   File \"/miniconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\", line 74, in _average_binary_score\r\n",
      "#     raise ValueError(\"{0} format is not supported\".format(y_type))\r\n",
      " \r\n",
      "#    auc = round(metrics.roc_auc_score(y_validation, preds_validation), 4)\r\n",
      "#    print('AUC is ' + repr(auc))\r\n",
      "    ##############"
     ]
    }
   ],
   "source": [
    "!cat src/xgboost_reviews.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost import XGBoost\n",
    "\n",
    "# TODO:  Bug re: s3://s3://?  in just pipelines?  doesn't seem to be in ScriptMode\n",
    "#        See here for more info:  https://github.com/aws/aws-step-functions-data-science-sdk-python/issues/32\n",
    "#model_output_path = 's3://{}/models/amazon-reviews/script-mode/training-runs'.format(bucket)\n",
    "model_output_path = 's3://{}/models/amazon-reviews/script-mode/training-runs'.format(bucket)\n",
    "\n",
    "xgb_estimator = XGBoost(entry_point='xgboost_reviews.py', \n",
    "                        source_dir='src/',\n",
    "                        role=role,\n",
    "                        train_instance_count=1, \n",
    "#                        train_instance_type='local',\n",
    "                        train_instance_type='ml.c5.4xlarge',\n",
    "                        framework_version='0.90-2',\n",
    "                        py_version='py3',\n",
    "                        output_path=model_output_path,\n",
    "                        hyperparameters={'objective':'binary:logistic',\n",
    "                                         'num_round': 1,\n",
    "                                         'max_depth': 5},\n",
    "                        enable_cloudwatch_metrics=True,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a training pipeline with the Step Functions SDK\n",
    "\n",
    "A typical task for a data scientist is to train a model and deploy that model to an endpoint. Without the Step Functions SDK, this is a four step process on SageMaker that includes the following.\n",
    "\n",
    "1. Training the model\n",
    "2. Creating the model on SageMaker\n",
    "3. Creating an endpoint configuration\n",
    "4. Deploying the trained model to the configured endpoint\n",
    "\n",
    "The Step Functions SDK provides the [TrainingPipeline](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/pipelines.html#stepfunctions.template.pipeline.train.TrainingPipeline) API to simplify this procedure. The following configures `pipeline` with the necessary parameters to define a training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the StepFunctionsWorkflowExecutionRole ARN from above\n",
    "workflow_execution_role = \"arn:aws:iam::835319576252:role/StepFunctionsWorkflowExecutionRole\"\n",
    "#workflow_execution_role = \"XXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.template.pipeline import TrainingPipeline\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    estimator=xgb_estimator,\n",
    "    role=workflow_execution_role,\n",
    "    inputs={'train': s3_input_train_data, \n",
    "            'validation': s3_input_validation_data},\n",
    "    s3_bucket=bucket)\n",
    "#    s3_bucket=model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the pipeline\n",
    "You can now view the workflow definition, and also visualize it as a graph. This workflow and graph represent your training pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"StartAt\": \"Training\",\n",
      "    \"States\": {\n",
      "        \"Training\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\",\n",
      "            \"Parameters\": {\n",
      "                \"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\",\n",
      "                \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\",\n",
      "                \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\",\n",
      "                \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\",\n",
      "                \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\",\n",
      "                \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\",\n",
      "                \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\",\n",
      "                \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\",\n",
      "                \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Create Model\"\n",
      "        },\n",
      "        \"Create Model\": {\n",
      "            \"Parameters\": {\n",
      "                \"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\",\n",
      "                \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\",\n",
      "                \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"\n",
      "            },\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createModel\",\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Configure Endpoint\"\n",
      "        },\n",
      "        \"Configure Endpoint\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\",\n",
      "                \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"Next\": \"Deploy\"\n",
      "        },\n",
      "        \"Deploy\": {\n",
      "            \"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\",\n",
      "            \"Parameters\": {\n",
      "                \"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\",\n",
      "                \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"\n",
      "            },\n",
      "            \"Type\": \"Task\",\n",
      "            \"End\": true\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.workflow.definition.to_json(pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the pipeline graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-514\" class=\"workflowgraph\">\n",
       "    \n",
       "    <svg></svg>\n",
       "    \n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var options = {\n",
       "        width: $('#graph-514').width(),\n",
       "        height: 600,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Training\", \"States\": {\"Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\", \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\", \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\", \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\", \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\", \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\", \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\", \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\", \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"}, \"Type\": \"Task\", \"Next\": \"Create Model\"}, \"Create Model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\", \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\", \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Configure Endpoint\"}, \"Configure Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\", \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"}, \"Type\": \"Task\", \"Next\": \"Deploy\"}, \"Deploy\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\", \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-514';\n",
       "\n",
       "    var graph = new sfn.StateMachineGraph(definition, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.render_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and execute the pipeline on AWS Step Functions\n",
    "\n",
    "Create the pipeline in AWS Step Functions with [create](https://aws-step-functions-data-science-sdk.readthedocs.io/en/latest/workflow.html#stepfunctions.workflow.Workflow.create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:states:us-east-1:835319576252:stateMachine:training-pipeline-2020-03-28-21-21-26'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline \n",
    "\n",
    "A link will be provided after the following cell is executed. Following this link, you can monitor your pipeline execution on Step Functions' console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://do0of8uwbahzz.cloudfront.net/graph.css\">\n",
       "<div id=\"graph-379\" class=\"workflowgraph\">\n",
       "    \n",
       "    <style>\n",
       "        .graph-legend ul {\n",
       "            list-style-type: none;\n",
       "            padding: 10px;\n",
       "            padding-left: 0;\n",
       "            margin: 0;\n",
       "            position: absolute;\n",
       "            top: 0;\n",
       "            background: transparent;\n",
       "        }\n",
       "\n",
       "        .graph-legend li {\n",
       "            margin-left: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend li > div {\n",
       "            width: 10px;\n",
       "            height: 10px;\n",
       "            display: inline-block;\n",
       "        }\n",
       "\n",
       "        .graph-legend .success { background-color: #2BD62E }\n",
       "        .graph-legend .failed { background-color: #DE322F }\n",
       "        .graph-legend .cancelled { background-color: #DDDDDD }\n",
       "        .graph-legend .in-progress { background-color: #53C9ED }\n",
       "        .graph-legend .caught-error { background-color: #FFA500 }\n",
       "    </style>\n",
       "    <div class=\"graph-legend\">\n",
       "        <ul>\n",
       "            <li>\n",
       "                <div class=\"success\"></div>\n",
       "                <span>Success</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"failed\"></div>\n",
       "                <span>Failed</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"cancelled\"></div>\n",
       "                <span>Cancelled</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"in-progress\"></div>\n",
       "                <span>In Progress</span>\n",
       "            </li>\n",
       "            <li>\n",
       "                <div class=\"caught-error\"></div>\n",
       "                <span>Caught Error</span>\n",
       "            </li>\n",
       "        </ul>\n",
       "    </div>\n",
       "\n",
       "    <svg></svg>\n",
       "    <a href=\"https://console.aws.amazon.com/states/home?region=us-east-1#/executions/details/arn:aws:states:us-east-1:835319576252:execution:training-pipeline-2020-03-28-21-21-26:training-pipeline-2020-03-28-21-21-27\" target=\"_blank\"> Inspect in AWS Step Functions </a>\n",
       "</div>\n",
       "\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "require.config({\n",
       "    paths: {\n",
       "        sfn: \"https://do0of8uwbahzz.cloudfront.net/sfn\",\n",
       "    }\n",
       "});\n",
       "\n",
       "require(['sfn'], function(sfn) {\n",
       "    var options = {\n",
       "        width: $('#graph-379').width(),\n",
       "        height: 1000,\n",
       "        layout: 'LR',\n",
       "        resizeHeight: true\n",
       "    };\n",
       "\n",
       "    var definition = {\"StartAt\": \"Training\", \"States\": {\"Training\": {\"Resource\": \"arn:aws:states:::sagemaker:createTrainingJob.sync\", \"Parameters\": {\"AlgorithmSpecification.$\": \"$$.Execution.Input['Training'].AlgorithmSpecification\", \"OutputDataConfig.$\": \"$$.Execution.Input['Training'].OutputDataConfig\", \"StoppingCondition.$\": \"$$.Execution.Input['Training'].StoppingCondition\", \"ResourceConfig.$\": \"$$.Execution.Input['Training'].ResourceConfig\", \"RoleArn.$\": \"$$.Execution.Input['Training'].RoleArn\", \"InputDataConfig.$\": \"$$.Execution.Input['Training'].InputDataConfig\", \"HyperParameters.$\": \"$$.Execution.Input['Training'].HyperParameters\", \"TrainingJobName.$\": \"$$.Execution.Input['Training'].TrainingJobName\", \"DebugHookConfig.$\": \"$$.Execution.Input['Training'].DebugHookConfig\"}, \"Type\": \"Task\", \"Next\": \"Create Model\"}, \"Create Model\": {\"Parameters\": {\"ModelName.$\": \"$$.Execution.Input['Create Model'].ModelName\", \"PrimaryContainer.$\": \"$$.Execution.Input['Create Model'].PrimaryContainer\", \"ExecutionRoleArn.$\": \"$$.Execution.Input['Create Model'].ExecutionRoleArn\"}, \"Resource\": \"arn:aws:states:::sagemaker:createModel\", \"Type\": \"Task\", \"Next\": \"Configure Endpoint\"}, \"Configure Endpoint\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpointConfig\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Configure Endpoint'].EndpointConfigName\", \"ProductionVariants.$\": \"$$.Execution.Input['Configure Endpoint'].ProductionVariants\"}, \"Type\": \"Task\", \"Next\": \"Deploy\"}, \"Deploy\": {\"Resource\": \"arn:aws:states:::sagemaker:createEndpoint\", \"Parameters\": {\"EndpointConfigName.$\": \"$$.Execution.Input['Deploy'].EndpointConfigName\", \"EndpointName.$\": \"$$.Execution.Input['Deploy'].EndpointName\"}, \"Type\": \"Task\", \"End\": true}}};\n",
       "    var elementId = '#graph-379';\n",
       "    var events = { 'events': [{\"timestamp\": 1585430487.977, \"type\": \"ExecutionStarted\", \"id\": 1, \"previousEventId\": 0, \"executionStartedEventDetails\": {\"input\": \"{\\n    \\\"Training\\\": {\\n        \\\"AlgorithmSpecification\\\": {\\n            \\\"TrainingImage\\\": \\\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3\\\",\\n            \\\"TrainingInputMode\\\": \\\"File\\\"\\n        },\\n        \\\"OutputDataConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/models\\\"\\n        },\\n        \\\"StoppingCondition\\\": {\\n            \\\"MaxRuntimeInSeconds\\\": 86400\\n        },\\n        \\\"ResourceConfig\\\": {\\n            \\\"InstanceCount\\\": 1,\\n            \\\"InstanceType\\\": \\\"ml.c5.4xlarge\\\",\\n            \\\"VolumeSizeInGB\\\": 30\\n        },\\n        \\\"RoleArn\\\": \\\"arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\\\",\\n        \\\"InputDataConfig\\\": [\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ContentType\\\": \\\"text/csv\\\",\\n                \\\"ChannelName\\\": \\\"train\\\"\\n            },\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ContentType\\\": \\\"text/csv\\\",\\n                \\\"ChannelName\\\": \\\"validation\\\"\\n            }\\n        ],\\n        \\\"HyperParameters\\\": {\\n            \\\"objective\\\": \\\"\\\\\\\"binary:logistic\\\\\\\"\\\",\\n            \\\"num_round\\\": \\\"1\\\",\\n            \\\"max_depth\\\": \\\"5\\\",\\n            \\\"sagemaker_submit_directory\\\": \\\"\\\\\\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\",\\n            \\\"sagemaker_program\\\": \\\"\\\\\\\"xgboost_reviews.py\\\\\\\"\\\",\\n            \\\"sagemaker_enable_cloudwatch_metrics\\\": \\\"false\\\",\\n            \\\"sagemaker_container_log_level\\\": \\\"20\\\",\\n            \\\"sagemaker_job_name\\\": \\\"\\\\\\\"training-pipeline-2020-03-28-21-21-26/estimator-source\\\\\\\"\\\",\\n            \\\"sagemaker_region\\\": \\\"\\\\\\\"us-east-1\\\\\\\"\\\"\\n        },\\n        \\\"TrainingJobName\\\": \\\"estimator-training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"DebugHookConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-835319576252/models/amazon-reviews/script-mode/training-runs\\\"\\n        }\\n    },\\n    \\\"Create Model\\\": {\\n        \\\"ModelName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"PrimaryContainer\\\": {\\n            \\\"Image\\\": \\\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3\\\",\\n            \\\"Environment\\\": {\\n                \\\"SAGEMAKER_PROGRAM\\\": \\\"xgboost_reviews.py\\\",\\n                \\\"SAGEMAKER_SUBMIT_DIRECTORY\\\": \\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/estimator-source/source/sourcedir.tar.gz\\\",\\n                \\\"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\\\": \\\"false\\\",\\n                \\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\": \\\"20\\\",\\n                \\\"SAGEMAKER_REGION\\\": \\\"us-east-1\\\"\\n            },\\n            \\\"ModelDataUrl\\\": \\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/models/estimator-training-pipeline-2020-03-28-21-21-27/output/model.tar.gz\\\"\\n        },\\n        \\\"ExecutionRoleArn\\\": \\\"arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\\\"\\n    },\\n    \\\"Configure Endpoint\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"ProductionVariants\\\": [\\n            {\\n                \\\"InitialInstanceCount\\\": 1,\\n                \\\"InstanceType\\\": \\\"ml.c5.4xlarge\\\",\\n                \\\"ModelName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n                \\\"VariantName\\\": \\\"AllTraffic\\\"\\n            }\\n        ]\\n    },\\n    \\\"Deploy\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"EndpointName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\"\\n    }\\n}\", \"roleArn\": \"arn:aws:iam::835319576252:role/StepFunctionsWorkflowExecutionRole\"}}, {\"timestamp\": 1585430488.015, \"type\": \"TaskStateEntered\", \"id\": 2, \"previousEventId\": 0, \"stateEnteredEventDetails\": {\"name\": \"Training\", \"input\": \"{\\n    \\\"Training\\\": {\\n        \\\"AlgorithmSpecification\\\": {\\n            \\\"TrainingImage\\\": \\\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3\\\",\\n            \\\"TrainingInputMode\\\": \\\"File\\\"\\n        },\\n        \\\"OutputDataConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/models\\\"\\n        },\\n        \\\"StoppingCondition\\\": {\\n            \\\"MaxRuntimeInSeconds\\\": 86400\\n        },\\n        \\\"ResourceConfig\\\": {\\n            \\\"InstanceCount\\\": 1,\\n            \\\"InstanceType\\\": \\\"ml.c5.4xlarge\\\",\\n            \\\"VolumeSizeInGB\\\": 30\\n        },\\n        \\\"RoleArn\\\": \\\"arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\\\",\\n        \\\"InputDataConfig\\\": [\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ContentType\\\": \\\"text/csv\\\",\\n                \\\"ChannelName\\\": \\\"train\\\"\\n            },\\n            {\\n                \\\"DataSource\\\": {\\n                    \\\"S3DataSource\\\": {\\n                        \\\"S3DataType\\\": \\\"S3Prefix\\\",\\n                        \\\"S3Uri\\\": \\\"s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation\\\",\\n                        \\\"S3DataDistributionType\\\": \\\"FullyReplicated\\\"\\n                    }\\n                },\\n                \\\"ContentType\\\": \\\"text/csv\\\",\\n                \\\"ChannelName\\\": \\\"validation\\\"\\n            }\\n        ],\\n        \\\"HyperParameters\\\": {\\n            \\\"objective\\\": \\\"\\\\\\\"binary:logistic\\\\\\\"\\\",\\n            \\\"num_round\\\": \\\"1\\\",\\n            \\\"max_depth\\\": \\\"5\\\",\\n            \\\"sagemaker_submit_directory\\\": \\\"\\\\\\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\",\\n            \\\"sagemaker_program\\\": \\\"\\\\\\\"xgboost_reviews.py\\\\\\\"\\\",\\n            \\\"sagemaker_enable_cloudwatch_metrics\\\": \\\"false\\\",\\n            \\\"sagemaker_container_log_level\\\": \\\"20\\\",\\n            \\\"sagemaker_job_name\\\": \\\"\\\\\\\"training-pipeline-2020-03-28-21-21-26/estimator-source\\\\\\\"\\\",\\n            \\\"sagemaker_region\\\": \\\"\\\\\\\"us-east-1\\\\\\\"\\\"\\n        },\\n        \\\"TrainingJobName\\\": \\\"estimator-training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"DebugHookConfig\\\": {\\n            \\\"S3OutputPath\\\": \\\"s3://sagemaker-us-east-1-835319576252/models/amazon-reviews/script-mode/training-runs\\\"\\n        }\\n    },\\n    \\\"Create Model\\\": {\\n        \\\"ModelName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"PrimaryContainer\\\": {\\n            \\\"Image\\\": \\\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3\\\",\\n            \\\"Environment\\\": {\\n                \\\"SAGEMAKER_PROGRAM\\\": \\\"xgboost_reviews.py\\\",\\n                \\\"SAGEMAKER_SUBMIT_DIRECTORY\\\": \\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/estimator-source/source/sourcedir.tar.gz\\\",\\n                \\\"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\\\": \\\"false\\\",\\n                \\\"SAGEMAKER_CONTAINER_LOG_LEVEL\\\": \\\"20\\\",\\n                \\\"SAGEMAKER_REGION\\\": \\\"us-east-1\\\"\\n            },\\n            \\\"ModelDataUrl\\\": \\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/models/estimator-training-pipeline-2020-03-28-21-21-27/output/model.tar.gz\\\"\\n        },\\n        \\\"ExecutionRoleArn\\\": \\\"arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\\\"\\n    },\\n    \\\"Configure Endpoint\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"ProductionVariants\\\": [\\n            {\\n                \\\"InitialInstanceCount\\\": 1,\\n                \\\"InstanceType\\\": \\\"ml.c5.4xlarge\\\",\\n                \\\"ModelName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n                \\\"VariantName\\\": \\\"AllTraffic\\\"\\n            }\\n        ]\\n    },\\n    \\\"Deploy\\\": {\\n        \\\"EndpointConfigName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\",\\n        \\\"EndpointName\\\": \\\"training-pipeline-2020-03-28-21-21-27\\\"\\n    }\\n}\"}}, {\"timestamp\": 1585430488.015, \"type\": \"TaskScheduled\", \"id\": 3, \"previousEventId\": 2, \"taskScheduledEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"region\": \"us-east-1\", \"parameters\": \"{\\\"HyperParameters\\\":{\\\"objective\\\":\\\"\\\\\\\"binary:logistic\\\\\\\"\\\",\\\"num_round\\\":\\\"1\\\",\\\"max_depth\\\":\\\"5\\\",\\\"sagemaker_submit_directory\\\":\\\"\\\\\\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/estimator-source/source/sourcedir.tar.gz\\\\\\\"\\\",\\\"sagemaker_program\\\":\\\"\\\\\\\"xgboost_reviews.py\\\\\\\"\\\",\\\"sagemaker_enable_cloudwatch_metrics\\\":\\\"false\\\",\\\"sagemaker_container_log_level\\\":\\\"20\\\",\\\"sagemaker_job_name\\\":\\\"\\\\\\\"training-pipeline-2020-03-28-21-21-26/estimator-source\\\\\\\"\\\",\\\"sagemaker_region\\\":\\\"\\\\\\\"us-east-1\\\\\\\"\\\"},\\\"DebugHookConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-835319576252/models/amazon-reviews/script-mode/training-runs\\\"},\\\"AlgorithmSpecification\\\":{\\\"TrainingImage\\\":\\\"683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-2-cpu-py3\\\",\\\"TrainingInputMode\\\":\\\"File\\\"},\\\"StoppingCondition\\\":{\\\"MaxRuntimeInSeconds\\\":86400},\\\"TrainingJobName\\\":\\\"estimator-training-pipeline-2020-03-28-21-21-27\\\",\\\"OutputDataConfig\\\":{\\\"S3OutputPath\\\":\\\"s3://sagemaker-us-east-1-835319576252/training-pipeline-2020-03-28-21-21-26/models\\\"},\\\"ResourceConfig\\\":{\\\"InstanceCount\\\":1,\\\"InstanceType\\\":\\\"ml.c5.4xlarge\\\",\\\"VolumeSizeInGB\\\":30},\\\"InputDataConfig\\\":[{\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-train\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\"}},\\\"ContentType\\\":\\\"text/csv\\\",\\\"ChannelName\\\":\\\"train\\\"},{\\\"DataSource\\\":{\\\"S3DataSource\\\":{\\\"S3DataType\\\":\\\"S3Prefix\\\",\\\"S3Uri\\\":\\\"s3://sagemaker-us-east-1-835319576252/amazon-reviews-spark-processor-2020-03-28-04-41-56/output/tfidf-validation\\\",\\\"S3DataDistributionType\\\":\\\"FullyReplicated\\\"}},\\\"ContentType\\\":\\\"text/csv\\\",\\\"ChannelName\\\":\\\"validation\\\"}],\\\"RoleArn\\\":\\\"arn:aws:iam::835319576252:role/service-role/AmazonSageMaker-ExecutionRole-20191006T135881\\\",\\\"Tags\\\":[{\\\"Key\\\":\\\"MANAGED_BY_AWS\\\",\\\"Value\\\":\\\"STARTED_BY_STEP_FUNCTIONS\\\"}]}\"}}, {\"timestamp\": 1585430488.072, \"type\": \"TaskStarted\", \"id\": 4, \"previousEventId\": 3, \"taskStartedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\"}}, {\"timestamp\": 1585430488.272, \"type\": \"TaskSubmitted\", \"id\": 5, \"previousEventId\": 4, \"taskSubmittedEventDetails\": {\"resourceType\": \"sagemaker\", \"resource\": \"createTrainingJob.sync\", \"output\": \"{\\\"SdkHttpMetadata\\\":{\\\"HttpHeaders\\\":{\\\"Content-Length\\\":\\\"122\\\",\\\"Content-Type\\\":\\\"application/x-amz-json-1.1\\\",\\\"Date\\\":\\\"Sat, 28 Mar 2020 21:21:27 GMT\\\",\\\"x-amzn-RequestId\\\":\\\"eab6c818-73dd-49a2-bede-005e310f4675\\\"},\\\"HttpStatusCode\\\":200},\\\"SdkResponseMetadata\\\":{\\\"RequestId\\\":\\\"eab6c818-73dd-49a2-bede-005e310f4675\\\"},\\\"TrainingJobArn\\\":\\\"arn:aws:sagemaker:us-east-1:835319576252:training-job/estimator-training-pipeline-2020-03-28-21-21-27\\\"}\"}}] };\n",
       "\n",
       "    var graph = new sfn.StateMachineExecutionGraph(definition, events, elementId, options);\n",
       "    graph.render();\n",
       "});\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Waiting for this:  https://github.com/aws/aws-step-functions-data-science-sdk-python/issues/32\n",
    "\n",
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *** YOU MUST WAIT FOR THE ABOVE PIPELINE TO COMPLETE BEFORE CONTINUING! ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the execution events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-9a4966021433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mevent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stateExitedEventDetails'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mendpoint_arn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EndpointArn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import json\n",
    "events = execution.list_events()\n",
    "\n",
    "event_output = json.loads(events[21]['stateExitedEventDetails']['output'])\n",
    "endpoint_arn = event_output['EndpointArn']\n",
    "\n",
    "endpoint_name = json.loads(events[18]['taskScheduledEventDetails']['parameters'])['EndpointName']\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Retieve the predictor from the pipeline/workflow above\n",
    "# predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.c5.2xlarge')\n",
    "\n",
    "#predictor = sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name)\n",
    "predictor = sagemaker.xgboost.model.XGBoostPredictor(endpoint_name=endpoint_name)\n",
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Endpoint\n",
    "\n",
    "From an external application, you can use the following code to make a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  This is erroring out with `Please provide a model_fn implementation.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd\n",
    "# from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# xgb_endpoint_name = 'xgboost-script-pipeline-{}'.format(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime()))\n",
    "# xgb_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Deploy trained XGBoost model endpoint to perform predictions\n",
    "# xgb_predictor = xgb_estimator.deploy(initial_instance_count = 1, \n",
    "#                                      instance_type = 'ml.m4.xlarge',\n",
    "#                                      endpoint_name=xgb_endpoint_name)\n",
    "\n",
    "# xgb_predictor.content_type = 'text/csv'\n",
    "# xgb_predictor.serializer = csv_serializer\n",
    "# xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "#payload_500_samples = X_test[:500].to_csv(index=False, header=False).rstrip()\n",
    "\n",
    "# response_500_samples = sm_runtime.invoke_endpoint(\n",
    "#     EndpointName=endpoint_name,\n",
    "#     Body=payload.encode('utf-8'),\n",
    "#     ContentType='text/csv')['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_500_samples = np.fromstring(response_500_samples, sep=',')\n",
    "# predictions_500_samples_0_or_1 = np.where(predictions_500_samples > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Test Accuracy: ', accuracy_score(y_test[:500], predictions_500_samples_0_or_1))\n",
    "# print('Test Precision: ', precision_score(y_test[:500], predictions_500_samples_0_or_1, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sn\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# df_cm_test = confusion_matrix(y_test[:500], predictions_500_samples_0_or_1)\n",
    "# df_cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# def plot_conf_mat(cm, classes, title, cmap = plt.cm.Greens):\n",
    "#     print(cm)\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     fmt = 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, format(cm[i, j], fmt),\n",
    "#         horizontalalignment=\"center\",\n",
    "#         color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.ylabel('True label')\n",
    "#         plt.xlabel('Predicted label')\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# fig, ax = plt.subplots(figsize=(6,4))\n",
    "# plot_conf_mat(df_cm_test, classes=['Not Positive Sentiment', 'Positive Sentiment'], \n",
    "#                           title='Confusion matrix')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "# auc = round(metrics.roc_auc_score(y_test, preds_test), 4)\n",
    "# print('AUC is ' + repr(auc))\n",
    "\n",
    "# fpr, tpr, _ = metrics.roc_curve(y_test, preds_test)\n",
    "\n",
    "# plt.title('ROC Curve')\n",
    "# plt.plot(fpr, tpr, 'b',\n",
    "# label='AUC = %0.2f'% auc)\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.plot([0,1],[0,1],'r--')\n",
    "# plt.xlim([-0.1,1.1])\n",
    "# plt.ylim([-0.1,1.1])\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint training-pipeline-2020-03-28-15-52-56 of account 835319576252 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0ff4aaae6eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m      \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m      ContentType='text/csv')['Body'].read()\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint training-pipeline-2020-03-28-15-52-56 of account 835319576252 not found."
     ]
    }
   ],
   "source": [
    "payload = \"\"\"Very funny. A typical mid 50's comedy.\"\"\"\n",
    "sm_runtime.invoke_endpoint(\n",
    "     EndpointName=endpoint_name,\n",
    "     Body=payload.encode('utf-8'),\n",
    "     ContentType='text/csv')['Body'].read()\n",
    "    \n",
    "\n",
    "#predictions, raw_outputs = xgb_predictor.predict([\"\"\"Very funny. A typical mid 50's comedy.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-52494d5f241f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\"That movie was absolutely awful.\"\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predictions: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Raw outputs: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = xgb_predictor.predict([\"\"\"That movie was absolutely awful.\"\"\"])\n",
    "print('Predictions: {}'.format(predictions))\n",
    "print('Raw outputs: {}'.format(raw_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
