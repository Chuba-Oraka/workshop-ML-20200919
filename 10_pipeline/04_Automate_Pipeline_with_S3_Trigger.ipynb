{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup AWS EventBridge To Trigger a Pipeline Execution with S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "1. Create S3 Buckets\n",
    "2. Enable CloudTrail Logging\n",
    "3. Get StepFunctions Pipeline\n",
    "4. Create EventBridge Rule\n",
    "5. Test Trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create S3 Data Upload Bucket (watched) & S3 Bucket for CloudTrail Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_bucket = 'dsoaws-test-upload-{}'.format(account_id)\n",
    "print(watched_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 mb s3://$watched_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $watched_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudtrail_bucket = 'cloudtrail-dsoaws-{}'.format(account_id)\n",
    "print(cloudtrail_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 mb s3://$cloudtrail_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $cloudtrail_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach an S3 Policy to the Cloud Trail ^^ Logging Bucket ^^ Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AWSCloudTrailAclCheck20150319\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"cloudtrail.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"s3:GetBucketAcl\",\n",
    "            \"Resource\": \"arn:aws:s3:::{}\".format(cloudtrail_bucket)\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"AWSCloudTrailWrite20150319\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"cloudtrail.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"s3:PutObject\",\n",
    "            \"Resource\": \"arn:aws:s3:::{}/AWSLogs/{}/*\".format(cloudtrail_bucket, account_id),\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"s3:x-amz-acl\": \"bucket-owner-full-control\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"AWSCloudTrailHTTPSOnly20180329\",\n",
    "            \"Effect\": \"Deny\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"cloudtrail.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"s3:*\",\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}/AWSLogs/{}/*\".format(cloudtrail_bucket, account_id),\n",
    "                \"arn:aws:s3:::{}\".format(cloudtrail_bucket)\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"Bool\": {\n",
    "                    \"aws:SecureTransport\": \"false\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_json = json.dumps(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"policy.json\", \"w\") as outfile: \n",
    "    json.dump(policy, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat policy.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3api put-bucket-policy --bucket $cloudtrail_bucket --policy file://policy.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Default Cloud Trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudtrail = boto3.client('cloudtrail')\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trails = cloudtrail.describe_trails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trails['trailList']) > 0:\n",
    "    trail_name = trails['trailList'][0]['Name']\n",
    "    trail_arn = trails['trailList'][0]['TrailARN']\n",
    "    print(trail_name)\n",
    "    print(trail_arn)\n",
    "else:\n",
    "    print(\"No existing Cloud Trail.\")\n",
    "    cloudtrail_bucket = 'cloudtrail-dsoaws-{}'.format(account_id)\n",
    "    s3.create_bucket(ACL='private', Bucket=cloudtrail_bucket)\n",
    "    t = cloudtrail.create_trail(Name='dsoaws', S3BucketName=cloudtrail_bucket)\n",
    "    trail_name = t['Name']\n",
    "    trail_arn = t['TrailARN']\n",
    "    cloudtrail.start_logging(Name=trail_arn)\n",
    "    print(\"Cloud Trail created. Started logging.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default EventBridge EventBus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = boto3.client('events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = events.describe_event_bus(Name='default')\n",
    "eventbus_arn = response['Arn']\n",
    "print(eventbus_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Event Logging on CloudTrail for our S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws cloudtrail get-event-selectors --trail-name $trail_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watched_bucket_arn = \"arn:aws:s3:::{}/\".format(watched_bucket)\n",
    "print(watched_bucket_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = '\\'[{ \"ReadWriteType\": \"WriteOnly\", \"IncludeManagementEvents\":true, \"DataResources\": [{ \"Type\": \"AWS::S3::Object\", \"Values\": [\"' + watched_bucket_arn + '\"] }] }]\\''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws cloudtrail put-event-selectors --trail-name $trail_name --event-selectors $command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Custom EventBridge Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = {\n",
    "  \"source\": [\n",
    "    \"aws.s3\"\n",
    "  ],\n",
    "  \"detail-type\": [\n",
    "    \"AWS API Call via CloudTrail\"\n",
    "  ],\n",
    "  \"detail\": {\n",
    "    \"eventSource\": [\n",
    "      \"s3.amazonaws.com\"\n",
    "    ],\n",
    "    \"eventName\": [\n",
    "      \"PutObject\"\n",
    "    ],\n",
    "    \"requestParameters\": {\n",
    "      \"bucketName\": [\n",
    "        \"{}\".format(watched_bucket)\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_json = json.dumps(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = events.put_rule(\n",
    "    Name='S3-Trigger',\n",
    "    EventPattern=pattern_json,\n",
    "    State='ENABLED',\n",
    "    Description='Triggers an event on S3 PUT',\n",
    "    EventBusName='default'\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_arn = response['RuleArn']\n",
    "print(rule_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create IAM Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_role_name_eventbridge = 'DSOAWS_EventBridge_Invoke_StepFunctions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AssumeRolePolicyDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_role_policy_doc = {\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"events.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    iam_role_eventbridge = iam.create_role(\n",
    "        RoleName=iam_role_name_eventbridge,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_doc),\n",
    "        Description='DSOAWS EventBridge Role'\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Role already exists\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Role ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_eventbridge = iam.get_role(RoleName=iam_role_name_eventbridge)\n",
    "iam_role_eventbridge_arn = role_eventbridge['Role']['Arn']\n",
    "print(iam_role_eventbridge_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the StepFunctions ARN and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r stepfunction_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stepfunction_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r stepfunction_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stepfunction_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Eventbridge Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventbridge_sfn_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"states:StartExecution\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(eventbridge_sfn_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Policy Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    policy_eventbridge_sfn = iam.create_policy(\n",
    "      PolicyName='DSOAWS_EventBridgeInvokeStepFunction',\n",
    "      PolicyDocument=json.dumps(eventbridge_sfn_policy)\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Policy already exists\")\n",
    "        policy_eventbridge_sfn_arn = f'arn:aws:iam::{account_id}:policy/DSOAWS_EventBridgeInvokeStepFunction'\n",
    "        iam.create_policy_version(\n",
    "            PolicyArn=policy_eventbridge_sfn_arn,\n",
    "            PolicyDocument=json.dumps(eventbridge_sfn_policy),\n",
    "            SetAsDefault=True)\n",
    "        print(\"Policy updated.\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_eventbridge_sfn_arn = f'arn:aws:iam::{account_id}:policy/DSOAWS_EventBridgeInvokeStepFunction'\n",
    "print(policy_eventbridge_sfn_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Policy To Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = iam.attach_role_policy(\n",
    "        PolicyArn=policy_eventbridge_sfn_arn,\n",
    "        RoleName=iam_role_name_eventbridge\n",
    "    )\n",
    "    print(\"Done.\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'EntityAlreadyExists':\n",
    "        print(\"Policy is already attached. This is ok.\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup EventBridge Rule Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfn = boto3.client('stepfunctions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Pipeline Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_name = 'run-{}'.format(timestamp)\n",
    "print(execution_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Input Data S3 Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r processed_train_data_s3_uri\n",
    "%store -r processed_validation_data_s3_uri\n",
    "%store -r processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are using the created Training Pipeline from notebook 02 and start a new run\n",
    "We do this because we need the trained model from this previous run.  We could also choose to depend on a previously-trained model from an earlier section (ie. 07_train/) or we could manually copy the source to an S3 bucket and invoke that way.  This is exactly what the client-side SageMaker Python SDK does for us when we use `sagemaker.estimator.TensorFlow.fit()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "  \"Training\": {\n",
    "    \"AlgorithmSpecification\": {\n",
    "      \"TrainingImage\": \"763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-training:2.1.0-cpu-py3\".format(region),\n",
    "      \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"OutputDataConfig\": {\n",
    "      \"S3OutputPath\": \"s3://{}/training-pipeline-{}/models\".format(bucket, execution_name)\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "      \"MaxRuntimeInSeconds\": 7200\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "      \"InstanceCount\": 1,\n",
    "      \"InstanceType\": \"ml.c5.2xlarge\",\n",
    "      \"VolumeSizeInGB\": 1024\n",
    "    },\n",
    "    \"RoleArn\": \"{}\".format(role),\n",
    "    \"InputDataConfig\": [\n",
    "      {\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": \"{}\".format(processed_train_data_s3_uri),\n",
    "            \"S3DataDistributionType\": \"ShardedByS3Key\"\n",
    "          }\n",
    "        },\n",
    "        \"ChannelName\": \"train\"\n",
    "      },\n",
    "      {\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": \"{}\".format(processed_validation_data_s3_uri),\n",
    "            \"S3DataDistributionType\": \"ShardedByS3Key\"\n",
    "          }\n",
    "        },\n",
    "        \"ChannelName\": \"validation\"\n",
    "      },\n",
    "      {\n",
    "        \"DataSource\": {\n",
    "          \"S3DataSource\": {\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3Uri\": \"{}\".format(processed_test_data_s3_uri),\n",
    "            \"S3DataDistributionType\": \"ShardedByS3Key\"\n",
    "          }\n",
    "        },\n",
    "        \"ChannelName\": \"test\"\n",
    "      }\n",
    "    ],\n",
    "    \"HyperParameters\": {\n",
    "      \"epochs\": \"1\",\n",
    "      \"learning_rate\": \"1e-05\",\n",
    "      \"epsilon\": \"1e-08\",\n",
    "      \"train_batch_size\": \"128\",\n",
    "      \"validation_batch_size\": \"128\",\n",
    "      \"test_batch_size\": \"128\",\n",
    "      \"train_steps_per_epoch\": \"50\",\n",
    "      \"validation_steps\": \"50\",\n",
    "      \"test_steps\": \"50\",\n",
    "      \"use_xla\": \"true\",\n",
    "      \"use_amp\": \"true\",\n",
    "      \"max_seq_length\": \"128\",\n",
    "      \"freeze_bert_layer\": \"true\",\n",
    "      \"enable_sagemaker_debugger\": \"false\",\n",
    "      \"enable_checkpointing\": \"false\",\n",
    "      \"enable_tensorboard\": \"false\",        \n",
    "      \"run_validation\": \"true\",\n",
    "      \"run_test\": \"true\",\n",
    "      \"run_sample_predictions\": \"true\",\n",
    "      \"sagemaker_submit_directory\": \"\\\"s3://{}/{}/estimator-source/source/sourcedir.tar.gz\\\"\".format(bucket, stepfunction_name),\n",
    "      \"sagemaker_program\": \"\\\"tf_bert_reviews.py\\\"\",\n",
    "      \"sagemaker_enable_cloudwatch_metrics\": \"false\",\n",
    "      \"sagemaker_container_log_level\": \"20\",\n",
    "      \"sagemaker_job_name\": \"\\\"training-pipeline-{}/estimator-source\\\"\".format(execution_name),\n",
    "      \"sagemaker_region\": \"\\\"{}\\\"\".format(region),\n",
    "      \"model_dir\": \"\\\"s3://{}/training-pipeline-{}/estimator-source/model\\\"\".format(bucket, execution_name)\n",
    "    },  \n",
    "    \"TrainingJobName\": \"estimator-training-pipeline-{}\".format(execution_name),\n",
    "    \"DebugHookConfig\": {\n",
    "      \"S3OutputPath\": \"s3://{}/\".format(bucket)\n",
    "    }\n",
    "  },\n",
    "  \"Create Model\": {\n",
    "    \"ModelName\": \"training-pipeline-{}\".format(execution_name),\n",
    "    \"PrimaryContainer\": {\n",
    "      \"Image\": \"763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-inference:2.1-cpu\".format(region),\n",
    "      \"Environment\": {\n",
    "        \"SAGEMAKER_PROGRAM\": \"null\",\n",
    "        \"SAGEMAKER_SUBMIT_DIRECTORY\": \"null\",\n",
    "        \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": \"false\",\n",
    "        \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
    "        \"SAGEMAKER_REGION\": \"{}\".format(region)\n",
    "      },\n",
    "      \"ModelDataUrl\": \"s3://{}/training-pipeline-{}/models/estimator-training-pipeline-{}/output/model.tar.gz\".format(bucket, execution_name, execution_name)\n",
    "    },\n",
    "    \"ExecutionRoleArn\": \"{}\".format(role)\n",
    "  },\n",
    "  \"Configure Endpoint\": {\n",
    "    \"EndpointConfigName\": \"training-pipeline-{}\".format(execution_name),\n",
    "    \"ProductionVariants\": [\n",
    "      {\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m4.xlarge\",\n",
    "        \"ModelName\": \"training-pipeline-{}\".format(execution_name),\n",
    "        \"VariantName\": \"AllTraffic\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"Deploy\": {\n",
    "    \"EndpointConfigName\": \"training-pipeline-{}\".format(execution_name),\n",
    "    \"EndpointName\": \"training-pipeline-{}\".format(execution_name)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_json = json.dumps(inputs)\n",
    "\n",
    "print(inputs_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create EventBridge Rule Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for exsting targets\n",
    "targets = events.list_targets_by_rule(\n",
    "    Rule='S3-Trigger',\n",
    "    EventBusName='default'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_targets = len(targets['Targets'])\n",
    "\n",
    "if number_targets > 0:\n",
    "    for target in targets['Targets']:\n",
    "        print(target['Id'])\n",
    "        events.remove_targets(\n",
    "            Rule='S3-Trigger',\n",
    "            EventBusName='default',\n",
    "            Ids=[target['Id']],\n",
    "        Force=True\n",
    ")\n",
    "    print(\"Target: \" +target['Id']+ \" removed.\")\n",
    "else:\n",
    "    print(\"No targets defined yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "target_id = str(uuid.uuid4())\n",
    "\n",
    "response = events.put_targets(\n",
    "    Rule='S3-Trigger',\n",
    "    EventBusName='default',\n",
    "    Targets=[\n",
    "        {\n",
    "            'Id': target_id,\n",
    "            'Arn': stepfunction_arn,\n",
    "            'RoleArn': iam_role_eventbridge_arn,\n",
    "            'Input': inputs_json\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Number of StepFunction Invocations **Before** the S3 Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_before_uploading = sfn.list_executions(stateMachineArn=stepfunction_arn)\n",
    "number_of_executions_before_uploading = len(response_before_uploading['executions'])\n",
    "print(number_of_executions_before_uploading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3 and Trigger a StepFunction Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp  ./src/requirements.txt s3://$watched_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Number of StepFunction Invocations **After** the S3 Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_after_uploading = sfn.list_executions(stateMachineArn=stepfunction_arn)\n",
    "number_of_executions_after_uploading = len(response_after_uploading['executions'])\n",
    "print(number_of_executions_after_uploading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
