{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a BERT SageMaker Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/kubeflow/pipelines/blob/master/samples/contrib/aws-samples/mnist-kmeans-sagemaker/mnist-classification-pipeline.py\n",
    "\n",
    "https://github.com/aws-samples/eks-kubeflow-workshop/blob/master/notebooks/05_Kubeflow_Pipeline/05_04_Pipeline_SageMaker.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install AWS Python SDK (`boto3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (1.11.8)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.3.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.8 in /opt/conda/lib/python3.6/site-packages (from boto3) (1.14.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.8->boto3) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.8->boto3) (1.24.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.8->boto3) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.8->boto3) (1.11.0)\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Kubeflow Pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz\n",
      "  Using cached https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.15 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (5.2)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<=9.0.0,>=8.0.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (9.0.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.6.4 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.6.4)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: requests_toolbelt>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<=0.1.25,>=0.1.18 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (0.1.18.3)\n",
      "Requirement already satisfied, skipping upgrade: argo-models==2.2.1a in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (2.2.1a0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate==0.8.3 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: click==7.0 in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Deprecated in /opt/conda/lib/python3.6/site-packages (from kfp==0.1.29) (1.2.10)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.2.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.29) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media<0.6dev,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.29) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (39.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.29) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: idna>=2.1 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.29) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.4.2->kfp==0.1.29) (1.11.5)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.29) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.29) (3.4.2)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.6.1->kfp==0.1.29) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp==0.1.29) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp==0.1.29) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema>=3.0.1->kfp==0.1.29) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in /opt/conda/lib/python3.6/site-packages (from Deprecated->kfp==0.1.29) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.16.0 in /opt/conda/lib/python3.6/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (1.16.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.29) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.7->cryptography>=2.4.2->kfp==0.1.29) (2.18)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==0.1.29) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp==0.1.29) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp==0.1.29) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /opt/conda/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp==0.1.29) (8.1.0)\n",
      "Building wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-4l0092do/wheels/81/b7/33/00ef9dd992b13add014c4875a2c130d9d70288127a793c4af6\n",
      "Successfully built kfp\n",
      "Installing collected packages: kfp\n",
      "  Found existing installation: kfp 0.1.29\n",
      "    Uninstalling kfp-0.1.29:\n",
      "      Successfully uninstalled kfp-0.1.29\n",
      "Successfully installed kfp-0.1.29\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install https://storage.googleapis.com/ml-pipeline/release/0.1.29/kfp.tar.gz --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart the kernel to pick up pip installed libraries\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-east-1\n",
      "Account ID: 835319576252\n",
      "S3 Bucket: sagemaker-us-east-1-835319576252\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "AWS_REGION_AS_SLIST=!curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/\\(.*\\)[a-z]/\\1/'\n",
    "AWS_REGION = AWS_REGION_AS_SLIST.s\n",
    "print('Region: {}'.format(AWS_REGION))\n",
    "\n",
    "AWS_ACCOUNT_ID=boto3.client('sts').get_caller_identity().get('Account')\n",
    "print('Account ID: {}'.format(AWS_ACCOUNT_ID))\n",
    "\n",
    "S3_BUCKET='sagemaker-{}-{}'.format(AWS_REGION, AWS_ACCOUNT_ID)\n",
    "print('S3 Bucket: {}'.format(S3_BUCKET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy `data` and `valid_data.csv` into your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://kubeflow-pipeline-data/mnist_kmeans_example/data to s3://sagemaker-us-east-1-835319576252/mnist_kmeans_example/data\n",
      "copy: s3://kubeflow-pipeline-data/mnist_kmeans_example/input/valid_data.csv to s3://sagemaker-us-east-1-835319576252/mnist_kmeans_example/input/valid_data.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://kubeflow-pipeline-data/mnist_kmeans_example/data s3://$S3_BUCKET/mnist_kmeans_example/data\n",
    "!aws s3 cp s3://kubeflow-pipeline-data/mnist_kmeans_example/input/valid_data.csv s3://$S3_BUCKET/mnist_kmeans_example/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import components\n",
    "from kfp import dsl\n",
    "from kfp.aws import use_aws_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_process_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/3ebd075212e0a761b982880707ec497c36a99d80/components/aws/sagemaker/process/component.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_train_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/3ebd075212e0a761b982880707ec497c36a99d80/components/aws/sagemaker/train/component.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_model_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/3ebd075212e0a761b982880707ec497c36a99d80/components/aws/sagemaker/model/component.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_deploy_op = components.load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/3ebd075212e0a761b982880707ec497c36a99d80/components/aws/sagemaker/deploy/component.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAGEMAKER_ROLE_ARN='arn:aws:iam::{}:role/TeamRole'.format(AWS_ACCOUNT_ID)\n",
    "\n",
    "# Configure your s3 bucket.\n",
    "S3_PIPELINE_PATH='s3://{}/bert-kubeflow-pipeline'.format(S3_BUCKET)\n",
    "\n",
    "# TODO:  Implement the other region checks\n",
    "if AWS_REGION == 'us-west-2':\n",
    "    AWS_ECR_REGISTRY='174872318107.dkr.ecr.us-west-2.amazonaws.com'\n",
    "\n",
    "if AWS_REGION == 'us-east-1':\n",
    "    AWS_ECR_REGISTRY='382416733822.dkr.ecr.us-east-1.amazonaws.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pre-Processing Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/processing_code/preprocess-scikit-text-to-bert.py\n",
      "upload: ./preprocess-scikit-text-to-bert.py to s3://sagemaker-us-east-1-835319576252/processing_code/preprocess-scikit-text-to-bert.py\n"
     ]
    }
   ],
   "source": [
    "processing_code_s3_uri = 's3://{}/processing_code/preprocess-scikit-text-to-bert.py'.format(S3_BUCKET)\n",
    "print(processing_code_s3_uri)\n",
    "\n",
    "!aws s3 cp ./preprocess-scikit-text-to-bert.py $processing_code_s3_uri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\r\n",
      "./inference.py\r\n",
      "./requirements.txt\r\n",
      "./tf_bert_reviews.py\r\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf sourcedir.tar.gz -C code ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/training_code/\n",
      "upload: ./sourcedir.tar.gz to s3://sagemaker-us-east-1-835319576252/training_code/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "training_code_s3_uri = 's3://{}/training_code/'.format(S3_BUCKET)\n",
    "print(training_code_s3_uri)\n",
    "\n",
    "!aws s3 cp sourcedir.tar.gz $training_code_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_input(input_name, s3_uri, local_path):\n",
    "    return {\n",
    "        \"InputName\": input_name,\n",
    "        \"S3Input\": {\n",
    "            \"S3Uri\": s3_uri,\n",
    "            \"LocalPath\": local_path,\n",
    "            \"S3DataType\": \"S3Prefix\",\n",
    "            \"S3InputMode\": \"File\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "def processing_output(output_name, s3_uri, local_path):\n",
    "    return {\n",
    "        \"OutputName\": output_name,\n",
    "        \"S3Output\": {\n",
    "            \"S3Uri\": s3_uri,\n",
    "            \"LocalPath\": local_path,\n",
    "            \"S3UploadMode\": \"EndOfJob\",\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_input(input_name, s3_uri):\n",
    "    return {\n",
    "        \"ChannelName\": input_name,\n",
    "        \"DataSource\": {\"S3DataSource\": {\"S3Uri\": s3_uri, \"S3DataType\": \"S3Prefix\"}},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"BERT Pipeline\",\n",
    "    description=\"BERT Pipeline\",\n",
    ")\n",
    "def bert_pipeline(role_arn=SAGEMAKER_ROLE_ARN, bucket_name=S3_BUCKET, region=AWS_REGION):\n",
    "    \n",
    "    processing_image='763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-training:1.15.2-gpu-py36-cu100-ubuntu18.04'.format(region)\n",
    "    train_image='763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-training:1.15.2-gpu-py36-cu100-ubuntu18.04'.format(region)\n",
    "    serve_image='763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-inference:1.15.2-cpu'.format(region)\n",
    "\n",
    "    import time\n",
    "    pipeline_name = 'kubeflow-pipeline-sagemaker-{}'.format(int(time.time()))\n",
    "\n",
    "    network_isolation=False\n",
    "\n",
    "    max_seq_length=64\n",
    "    train_split_percentage=0.90\n",
    "    validation_split_percentage=0.05\n",
    "    test_split_percentage=0.05\n",
    "    balance_dataset=True\n",
    "    processing_instance_count=2\n",
    "    processing_instance_type='ml.c5.2xlarge'\n",
    "\n",
    "    raw_input_data_s3_uri = 's3://{}/amazon-reviews-pds/tsv/'.format(S3_BUCKET)\n",
    "\n",
    "    processed_train_data_s3_uri = 's3://{}/{}/processing/output/bert-train'.format(S3_BUCKET, pipeline_name)\n",
    "    processed_validation_data_s3_uri = 's3://{}/{}/processing/output/bert-validation'.format(S3_BUCKET, pipeline_name)\n",
    "    processed_test_data_s3_uri = 's3://{}/{}/processing/output/bert-test'.format(S3_BUCKET, pipeline_name)\n",
    "\n",
    "    processing_instance_type = 'ml.c5.2xlarge'\n",
    "    processing_instance_count = 2    \n",
    "\n",
    "    # Training input and output location based on bucket name\n",
    "    process = sagemaker_process_op(\n",
    "        role=role_arn,\n",
    "        region=region,\n",
    "        image=processing_image, #\"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.5.0-cpu-py36-ubuntu16.04\",\n",
    "        network_isolation=network_isolation,\n",
    "        instance_type=processing_instance_type,\n",
    "        instance_count=processing_instance_count,\n",
    "        container_arguments=['--train-split-percentage', str(train_split_percentage),\n",
    "                             '--validation-split-percentage', str(validation_split_percentage),\n",
    "                             '--test-split-percentage', str(test_split_percentage),\n",
    "                             '--max-seq-length', str(max_seq_length),\n",
    "                             '--balance-dataset', str(balance_dataset)],\n",
    "        container_entrypoint=[\n",
    "            \"python3\",\n",
    "            \"/opt/ml/processing/input/code/preprocess-scikit-text-to-bert.py\",\n",
    "        ],\n",
    "        input_config=[\n",
    "            processing_input(\n",
    "                \"raw_input\",\n",
    "                \"{}\".format(raw_input_data_s3_uri),\n",
    "                \"/opt/ml/processing/input\",\n",
    "                # TODO:  Add ShardedByS3Key                \n",
    "            ),\n",
    "            processing_input(\n",
    "                \"code\",\n",
    "                \"{}\".format(processing_code_s3_uri),\n",
    "                \"/opt/ml/processing/input/code\",\n",
    "            ),\n",
    "        ],\n",
    "        output_config=[\n",
    "            processing_output(\n",
    "                \"bert-train\",\n",
    "                \"{}\".format(processed_train_data_s3_uri),\n",
    "                \"/opt/ml/processing/output/bert/train\",\n",
    "                # TODO:  Add EndOfJob                \n",
    "            ),\n",
    "            processing_output(\n",
    "                \"bert-validation\",\n",
    "                \"{}\".format(processed_validation_data_s3_uri),\n",
    "                \"/opt/ml/processing/output/bert/validation\",\n",
    "                # TODO:  Add EndOfJob\n",
    "            ),\n",
    "            processing_output(\n",
    "                \"bert-test\",\n",
    "                \"{}\".format(processed_test_data_s3_uri),\n",
    "                \"/opt/ml/processing/output/bert/test\",\n",
    "                # TODO:  Add EndOfJob                \n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    train_channels = [\n",
    "        training_input(\"train\", \n",
    "                       processed_train_data_s3_uri\n",
    "                       # TODO:  Add ShardedByS3Key                \n",
    "        ),\n",
    "        training_input(\"validation\", \n",
    "                       processed_validation_data_s3_uri\n",
    "                       # TODO:  Add ShardedByS3Key\n",
    "        ),                       \n",
    "        training_input(\"test\", \n",
    "                       processed_test_data_s3_uri\n",
    "                       # TODO:  Add ShardedByS3Key                       \n",
    "        )\n",
    "    ]\n",
    "\n",
    "    train_output_location = \"s3://{}/{}/output\".format(S3_BUCKET, pipeline_name)\n",
    "\n",
    "    epochs=3\n",
    "    learning_rate=0.00001\n",
    "    epsilon=0.00000001\n",
    "    train_batch_size=128\n",
    "    validation_batch_size=128\n",
    "    test_batch_size=128\n",
    "    train_steps_per_epoch=100\n",
    "    validation_steps=100\n",
    "    test_steps=100\n",
    "    train_volume_size=1024\n",
    "    use_xla=True\n",
    "    use_amp=True\n",
    "    freeze_bert_layer=False\n",
    "    enable_sagemaker_debugger=False\n",
    "    enable_checkpointing=False\n",
    "    enable_tensorboard=False\n",
    "    input_mode='Pipe'\n",
    "    run_validation=True\n",
    "    run_test=True\n",
    "    run_sample_predictions=True\n",
    "    \n",
    "    metrics_definitions = [\n",
    "        {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "        {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "    ]\n",
    "    \n",
    "    train_instance_count=1\n",
    "    train_instance_type='ml.c5.9xlarge'\n",
    "    \n",
    "    # .after(process) is explicitly appended below\n",
    "    training = sagemaker_train_op(\n",
    "        region=region,\n",
    "        image=train_image,\n",
    "        network_isolation=network_isolation,        \n",
    "        instance_type=train_instance_type,\n",
    "        instance_count=train_instance_count,\n",
    "        hyperparameters={'epochs': '{}'.format(epochs),\n",
    "                         'learning_rate': '{}'.format(learning_rate),\n",
    "                         'epsilon': '{}'.format(epsilon),\n",
    "                         'train_batch_size': '{}'.format(train_batch_size),\n",
    "                         'validation_batch_size': '{}'.format(validation_batch_size),\n",
    "                         'test_batch_size': '{}'.format(test_batch_size),                                             \n",
    "                         'train_steps_per_epoch': '{}'.format(train_steps_per_epoch),\n",
    "                         'validation_steps': '{}'.format(validation_steps),\n",
    "                         'test_steps': '{}'.format(test_steps),\n",
    "                         'use_xla': '{}'.format(use_xla),\n",
    "                         'use_amp': '{}'.format(use_amp),                                             \n",
    "                         'max_seq_length': '{}'.format(max_seq_length),\n",
    "                         'freeze_bert_layer': '{}'.format(freeze_bert_layer),\n",
    "                         'enable_sagemaker_debugger': '{}'.format(enable_sagemaker_debugger),\n",
    "                         'enable_checkpointing': '{}'.format(enable_checkpointing),\n",
    "                         'enable_tensorboard': '{}'.format(enable_tensorboard),                                        \n",
    "                         'run_validation': '{}'.format(run_validation),\n",
    "                         'run_test': '{}'.format(run_test),\n",
    "                         'run_sample_predictions': '{}'.format(run_sample_predictions)\n",
    "                        },\n",
    "        training_input_mode=input_mode,    \n",
    "        channels=train_channels,        \n",
    "        model_artifact_path=train_output_location,\n",
    "        # TODO:  Add metric definitions and overcome this error\n",
    "        # for key, val in args['metric_definitions'].items():\n",
    "        # AttributeError: 'list' object has no attribute 'items'        \n",
    "#        metric_definitions=metrics_definitions,\n",
    "        # TODO:  Add rules\n",
    "        role=role_arn,\n",
    "        \n",
    "    ).after(process)\n",
    "\n",
    "    # .after(process) is implied because we depend on training.outputs[]\n",
    "    create_model = sagemaker_model_op(\n",
    "        region=region,\n",
    "        model_name=training.outputs[\"job_name\"],\n",
    "        image=serve_image, # training.outputs[\"training_image\"],\n",
    "        model_artifact_url=training.outputs[\"model_artifact_url\"],\n",
    "        role=role_arn,\n",
    "    )\n",
    "\n",
    "    deploy_instance_count=1\n",
    "    deploy_instance_type='ml.m5.4xlarge'\n",
    "\n",
    "    # .after(process) is implied because we depend on create_model.outputs\n",
    "    sagemaker_deploy_op(\n",
    "        region=region,\n",
    "        model_name_1=create_model.output,\n",
    "        instance_type_1=deploy_instance_type,\n",
    "        initial_instance_count_1=deploy_instance_count        \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(bert_pipeline, 'bert-pipeline.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root users 2240 Aug 29 05:14 ./bert-pipeline.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al ./bert-pipeline.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./bert-pipeline.zip\r\n",
      "  inflating: pipeline.yaml           \r\n"
     ]
    }
   ],
   "source": [
    "!unzip -o ./bert-pipeline.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: argoproj.io/v1alpha1\r\n",
      "kind: Workflow\r\n",
      "metadata:\r\n",
      "  annotations:\r\n",
      "    pipelines.kubeflow.org/pipeline_spec: '{\"description\": \"BERT Pipeline\", \"inputs\":\r\n",
      "      [{\"default\": \"arn:aws:iam::835319576252:role/TeamRole\", \"name\": \"role_arn\"},\r\n",
      "      {\"default\": \"sagemaker-us-east-1-835319576252\", \"name\": \"bucket_name\"}, {\"default\":\r\n",
      "      \"us-east-1\", \"name\": \"region\"}], \"name\": \"BERT Pipeline\"}'\r\n",
      "  generateName: bert-pipeline-\r\n",
      "spec:\r\n",
      "  arguments:\r\n",
      "    parameters:\r\n",
      "    - name: role-arn\r\n",
      "      value: arn:aws:iam::835319576252:role/TeamRole\r\n",
      "    - name: bucket-name\r\n",
      "      value: sagemaker-us-east-1-835319576252\r\n",
      "    - name: region\r\n",
      "      value: us-east-1\r\n",
      "  entrypoint: bert-pipeline\r\n",
      "  serviceAccountName: pipeline-runner\r\n",
      "  templates:\r\n",
      "  - dag:\r\n",
      "      tasks:\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: region\r\n",
      "            value: '{{inputs.parameters.region}}'\r\n",
      "          - name: role-arn\r\n",
      "            value: '{{inputs.parameters.role-arn}}'\r\n",
      "          - name: sagemaker-training-job-job-name\r\n",
      "            value: '{{tasks.sagemaker-training-job.outputs.parameters.sagemaker-training-job-job-name}}'\r\n",
      "          - name: sagemaker-training-job-model-artifact-url\r\n",
      "            value: '{{tasks.sagemaker-training-job.outputs.parameters.sagemaker-training-job-model-artifact-url}}'\r\n",
      "        dependencies:\r\n",
      "        - sagemaker-training-job\r\n",
      "        name: sagemaker-create-model\r\n",
      "        template: sagemaker-create-model\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: region\r\n",
      "            value: '{{inputs.parameters.region}}'\r\n",
      "          - name: sagemaker-create-model-model-name\r\n",
      "            value: '{{tasks.sagemaker-create-model.outputs.parameters.sagemaker-create-model-model-name}}'\r\n",
      "        dependencies:\r\n",
      "        - sagemaker-create-model\r\n",
      "        name: sagemaker-deploy-model\r\n",
      "        template: sagemaker-deploy-model\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: region\r\n",
      "            value: '{{inputs.parameters.region}}'\r\n",
      "          - name: role-arn\r\n",
      "            value: '{{inputs.parameters.role-arn}}'\r\n",
      "        name: sagemaker-processing-job\r\n",
      "        template: sagemaker-processing-job\r\n",
      "      - arguments:\r\n",
      "          parameters:\r\n",
      "          - name: region\r\n",
      "            value: '{{inputs.parameters.region}}'\r\n",
      "          - name: role-arn\r\n",
      "            value: '{{inputs.parameters.role-arn}}'\r\n",
      "        dependencies:\r\n",
      "        - sagemaker-processing-job\r\n",
      "        name: sagemaker-training-job\r\n",
      "        template: sagemaker-training-job\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: region\r\n",
      "      - name: role-arn\r\n",
      "    name: bert-pipeline\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - create_model.py\r\n",
      "      - --region\r\n",
      "      - '{{inputs.parameters.region}}'\r\n",
      "      - --endpoint_url\r\n",
      "      - ''\r\n",
      "      - --assume_role\r\n",
      "      - ''\r\n",
      "      - --model_name\r\n",
      "      - '{{inputs.parameters.sagemaker-training-job-job-name}}'\r\n",
      "      - --role\r\n",
      "      - '{{inputs.parameters.role-arn}}'\r\n",
      "      - --container_host_name\r\n",
      "      - ''\r\n",
      "      - --image\r\n",
      "      - 763104351884.dkr.ecr.{{inputs.parameters.region}}.amazonaws.com/tensorflow-inference:1.15.2-cpu\r\n",
      "      - --model_artifact_url\r\n",
      "      - '{{inputs.parameters.sagemaker-training-job-model-artifact-url}}'\r\n",
      "      - --environment\r\n",
      "      - '{}'\r\n",
      "      - --model_package\r\n",
      "      - ''\r\n",
      "      - --secondary_containers\r\n",
      "      - '[]'\r\n",
      "      - --vpc_security_group_ids\r\n",
      "      - ''\r\n",
      "      - --vpc_subnets\r\n",
      "      - ''\r\n",
      "      - --network_isolation\r\n",
      "      - 'True'\r\n",
      "      - --tags\r\n",
      "      - '{}'\r\n",
      "      - --model_name_output_path\r\n",
      "      - /tmp/outputs/model_name/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      image: amazon/aws-sagemaker-kfp-components:0.8.0\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: region\r\n",
      "      - name: role-arn\r\n",
      "      - name: sagemaker-training-job-job-name\r\n",
      "      - name: sagemaker-training-job-model-artifact-url\r\n",
      "    name: sagemaker-create-model\r\n",
      "    outputs:\r\n",
      "      parameters:\r\n",
      "      - name: sagemaker-create-model-model-name\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/model_name/data\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - deploy.py\r\n",
      "      - --region\r\n",
      "      - '{{inputs.parameters.region}}'\r\n",
      "      - --endpoint_url\r\n",
      "      - ''\r\n",
      "      - --assume_role\r\n",
      "      - ''\r\n",
      "      - --endpoint_config_name\r\n",
      "      - ''\r\n",
      "      - --variant_name_1\r\n",
      "      - variant-name-1\r\n",
      "      - --model_name_1\r\n",
      "      - '{{inputs.parameters.sagemaker-create-model-model-name}}'\r\n",
      "      - --initial_instance_count_1\r\n",
      "      - '1'\r\n",
      "      - --instance_type_1\r\n",
      "      - ml.m5.4xlarge\r\n",
      "      - --initial_variant_weight_1\r\n",
      "      - '1.0'\r\n",
      "      - --accelerator_type_1\r\n",
      "      - ''\r\n",
      "      - --variant_name_2\r\n",
      "      - variant-name-2\r\n",
      "      - --model_name_2\r\n",
      "      - ''\r\n",
      "      - --initial_instance_count_2\r\n",
      "      - '1'\r\n",
      "      - --instance_type_2\r\n",
      "      - ml.m4.xlarge\r\n",
      "      - --initial_variant_weight_2\r\n",
      "      - '1.0'\r\n",
      "      - --accelerator_type_2\r\n",
      "      - ''\r\n",
      "      - --variant_name_3\r\n",
      "      - variant-name-3\r\n",
      "      - --model_name_3\r\n",
      "      - ''\r\n",
      "      - --initial_instance_count_3\r\n",
      "      - '1'\r\n",
      "      - --instance_type_3\r\n",
      "      - ml.m4.xlarge\r\n",
      "      - --initial_variant_weight_3\r\n",
      "      - '1.0'\r\n",
      "      - --accelerator_type_3\r\n",
      "      - ''\r\n",
      "      - --resource_encryption_key\r\n",
      "      - ''\r\n",
      "      - --endpoint_config_tags\r\n",
      "      - '{}'\r\n",
      "      - --endpoint_name\r\n",
      "      - ''\r\n",
      "      - --endpoint_tags\r\n",
      "      - '{}'\r\n",
      "      - --endpoint_name_output_path\r\n",
      "      - /tmp/outputs/endpoint_name/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      image: amazon/aws-sagemaker-kfp-components:0.8.0\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: region\r\n",
      "      - name: sagemaker-create-model-model-name\r\n",
      "    name: sagemaker-deploy-model\r\n",
      "    outputs:\r\n",
      "      parameters:\r\n",
      "      - name: sagemaker-deploy-model-endpoint-name\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/endpoint_name/data\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - process.py\r\n",
      "      - --region\r\n",
      "      - '{{inputs.parameters.region}}'\r\n",
      "      - --endpoint_url\r\n",
      "      - ''\r\n",
      "      - --assume_role\r\n",
      "      - ''\r\n",
      "      - --job_name\r\n",
      "      - ''\r\n",
      "      - --role\r\n",
      "      - '{{inputs.parameters.role-arn}}'\r\n",
      "      - --image\r\n",
      "      - 763104351884.dkr.ecr.{{inputs.parameters.region}}.amazonaws.com/tensorflow-training:1.15.2-gpu-py36-cu100-ubuntu18.04\r\n",
      "      - --instance_type\r\n",
      "      - ml.c5.2xlarge\r\n",
      "      - --instance_count\r\n",
      "      - '2'\r\n",
      "      - --volume_size\r\n",
      "      - '30'\r\n",
      "      - --resource_encryption_key\r\n",
      "      - ''\r\n",
      "      - --output_encryption_key\r\n",
      "      - ''\r\n",
      "      - --max_run_time\r\n",
      "      - '86400'\r\n",
      "      - --environment\r\n",
      "      - '{}'\r\n",
      "      - --container_entrypoint\r\n",
      "      - '[\"python3\", \"/opt/ml/processing/input/code/preprocess-scikit-text-to-bert.py\"]'\r\n",
      "      - --container_arguments\r\n",
      "      - '[\"--train-split-percentage\", \"0.9\", \"--validation-split-percentage\", \"0.05\",\r\n",
      "        \"--test-split-percentage\", \"0.05\", \"--max-seq-length\", \"64\", \"--balance-dataset\",\r\n",
      "        \"True\"]'\r\n",
      "      - --output_config\r\n",
      "      - '[{\"OutputName\": \"bert-train\", \"S3Output\": {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/processing/output/bert-train\",\r\n",
      "        \"LocalPath\": \"/opt/ml/processing/output/bert/train\", \"S3UploadMode\": \"EndOfJob\"}},\r\n",
      "        {\"OutputName\": \"bert-validation\", \"S3Output\": {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/processing/output/bert-validation\",\r\n",
      "        \"LocalPath\": \"/opt/ml/processing/output/bert/validation\", \"S3UploadMode\":\r\n",
      "        \"EndOfJob\"}}, {\"OutputName\": \"bert-test\", \"S3Output\": {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/processing/output/bert-test\",\r\n",
      "        \"LocalPath\": \"/opt/ml/processing/output/bert/test\", \"S3UploadMode\": \"EndOfJob\"}}]'\r\n",
      "      - --input_config\r\n",
      "      - '[{\"InputName\": \"raw_input\", \"S3Input\": {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/amazon-reviews-pds/tsv/\",\r\n",
      "        \"LocalPath\": \"/opt/ml/processing/input\", \"S3DataType\": \"S3Prefix\", \"S3InputMode\":\r\n",
      "        \"File\"}}, {\"InputName\": \"code\", \"S3Input\": {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/processing_code/preprocess-scikit-text-to-bert.py\",\r\n",
      "        \"LocalPath\": \"/opt/ml/processing/input/code\", \"S3DataType\": \"S3Prefix\", \"S3InputMode\":\r\n",
      "        \"File\"}}]'\r\n",
      "      - --vpc_security_group_ids\r\n",
      "      - ''\r\n",
      "      - --vpc_subnets\r\n",
      "      - ''\r\n",
      "      - --network_isolation\r\n",
      "      - 'False'\r\n",
      "      - --traffic_encryption\r\n",
      "      - 'False'\r\n",
      "      - --tags\r\n",
      "      - '{}'\r\n",
      "      - --job_name_output_path\r\n",
      "      - /tmp/outputs/job_name/data\r\n",
      "      - --output_artifacts_output_path\r\n",
      "      - /tmp/outputs/output_artifacts/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      image: amazon/aws-sagemaker-kfp-components:0.8.0\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: region\r\n",
      "      - name: role-arn\r\n",
      "    name: sagemaker-processing-job\r\n",
      "    outputs:\r\n",
      "      parameters:\r\n",
      "      - name: sagemaker-processing-job-job-name\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/job_name/data\r\n",
      "      - name: sagemaker-processing-job-output-artifacts\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/output_artifacts/data\r\n",
      "  - container:\r\n",
      "      args:\r\n",
      "      - train.py\r\n",
      "      - --region\r\n",
      "      - '{{inputs.parameters.region}}'\r\n",
      "      - --endpoint_url\r\n",
      "      - ''\r\n",
      "      - --assume_role\r\n",
      "      - ''\r\n",
      "      - --job_name\r\n",
      "      - ''\r\n",
      "      - --role\r\n",
      "      - '{{inputs.parameters.role-arn}}'\r\n",
      "      - --image\r\n",
      "      - 763104351884.dkr.ecr.{{inputs.parameters.region}}.amazonaws.com/tensorflow-training:1.15.2-gpu-py36-cu100-ubuntu18.04\r\n",
      "      - --algorithm_name\r\n",
      "      - ''\r\n",
      "      - --metric_definitions\r\n",
      "      - '{}'\r\n",
      "      - --training_input_mode\r\n",
      "      - Pipe\r\n",
      "      - --hyperparameters\r\n",
      "      - '{\"epochs\": \"3\", \"learning_rate\": \"1e-05\", \"epsilon\": \"1e-08\", \"train_batch_size\":\r\n",
      "        \"128\", \"validation_batch_size\": \"128\", \"test_batch_size\": \"128\", \"train_steps_per_epoch\":\r\n",
      "        \"100\", \"validation_steps\": \"100\", \"test_steps\": \"100\", \"use_xla\": \"True\",\r\n",
      "        \"use_amp\": \"True\", \"max_seq_length\": \"64\", \"freeze_bert_layer\": \"False\", \"enable_sagemaker_debugger\":\r\n",
      "        \"False\", \"enable_checkpointing\": \"False\", \"enable_tensorboard\": \"False\", \"run_validation\":\r\n",
      "        \"True\", \"run_test\": \"True\", \"run_sample_predictions\": \"True\"}'\r\n",
      "      - --channels\r\n",
      "      - '[{\"ChannelName\": \"train\", \"DataSource\": {\"S3DataSource\": {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/processing/output/bert-train\",\r\n",
      "        \"S3DataType\": \"S3Prefix\"}}}, {\"ChannelName\": \"validation\", \"DataSource\": {\"S3DataSource\":\r\n",
      "        {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/processing/output/bert-validation\",\r\n",
      "        \"S3DataType\": \"S3Prefix\"}}}, {\"ChannelName\": \"test\", \"DataSource\": {\"S3DataSource\":\r\n",
      "        {\"S3Uri\": \"s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/processing/output/bert-test\",\r\n",
      "        \"S3DataType\": \"S3Prefix\"}}}]'\r\n",
      "      - --instance_type\r\n",
      "      - ml.c5.9xlarge\r\n",
      "      - --instance_count\r\n",
      "      - '1'\r\n",
      "      - --volume_size\r\n",
      "      - '30'\r\n",
      "      - --resource_encryption_key\r\n",
      "      - ''\r\n",
      "      - --max_run_time\r\n",
      "      - '86400'\r\n",
      "      - --model_artifact_path\r\n",
      "      - s3://sagemaker-us-east-1-835319576252/kubeflow-pipeline-sagemaker-1598678071/output\r\n",
      "      - --output_encryption_key\r\n",
      "      - ''\r\n",
      "      - --vpc_security_group_ids\r\n",
      "      - ''\r\n",
      "      - --vpc_subnets\r\n",
      "      - ''\r\n",
      "      - --network_isolation\r\n",
      "      - 'False'\r\n",
      "      - --traffic_encryption\r\n",
      "      - 'False'\r\n",
      "      - --debug_hook_config\r\n",
      "      - '{}'\r\n",
      "      - --debug_rule_config\r\n",
      "      - '[]'\r\n",
      "      - --spot_instance\r\n",
      "      - 'False'\r\n",
      "      - --max_wait_time\r\n",
      "      - '86400'\r\n",
      "      - --checkpoint_config\r\n",
      "      - '{}'\r\n",
      "      - --tags\r\n",
      "      - '{}'\r\n",
      "      - --model_artifact_url_output_path\r\n",
      "      - /tmp/outputs/model_artifact_url/data\r\n",
      "      - --job_name_output_path\r\n",
      "      - /tmp/outputs/job_name/data\r\n",
      "      - --training_image_output_path\r\n",
      "      - /tmp/outputs/training_image/data\r\n",
      "      command:\r\n",
      "      - python3\r\n",
      "      image: amazon/aws-sagemaker-kfp-components:0.8.0\r\n",
      "    inputs:\r\n",
      "      parameters:\r\n",
      "      - name: region\r\n",
      "      - name: role-arn\r\n",
      "    name: sagemaker-training-job\r\n",
      "    outputs:\r\n",
      "      parameters:\r\n",
      "      - name: sagemaker-training-job-job-name\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/job_name/data\r\n",
      "      - name: sagemaker-training-job-model-artifact-url\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/model_artifact_url/data\r\n",
      "      - name: sagemaker-training-job-training-image\r\n",
      "        valueFrom:\r\n",
      "          path: /tmp/outputs/training_image/data\r\n"
     ]
    }
   ],
   "source": [
    "!cat pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Pipeline on Kubernetes Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/e3353775-57cf-43cf-915d-3b489ef06d3b\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/be327a79-13df-43bb-b56a-78f2aa5bd99c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = kfp.Client()\n",
    "\n",
    "aws_experiment = client.create_experiment(name='aws')\n",
    "\n",
    "my_run = client.run_pipeline(aws_experiment.id, \n",
    "                             'bert-pipeline', \n",
    "                             'bert-pipeline.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "_Note:  The above training job may take 5-10 minutes.  Please be patient._\n",
    "\n",
    "In the meantime, open the SageMaker Console to monitor the progress of your training job.\n",
    "\n",
    "![SageMaker Training Job Console](img/sagemaker-training-job-console.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Name of the Deployed Prediction Endpoint\n",
    "First, we need to get the endpoint name of our newly-deployed SageMaker Prediction Endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open AWS console and enter SageMaker service, find the endpoint name as the following picture shows.\n",
    "\n",
    "![download-pipeline](images/sm-endpoint.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _YOU MUST COPY/PASTE THE `ENDPOINT_NAME` BEFORE CONTINUING_\n",
    "Make sure to include preserve the single-quotes as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle, gzip, numpy, urllib.request, json\n",
    "# from urllib.parse import urlparse\n",
    "# import json\n",
    "# import io\n",
    "# import boto3\n",
    "\n",
    "# #################################\n",
    "# #################################\n",
    "# # Replace ENDPOINT_NAME with the endpoint name in the SageMaker console.\n",
    "# # Surround with single quotes.\n",
    "# ENDPOINT_NAME= # 'Endpoint-<your-endpoint-name>'\n",
    "# #################################\n",
    "# #################################\n",
    "\n",
    "# # Load the dataset\n",
    "# urllib.request.urlretrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "# with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "#     train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# # Simple function to create a csv from our numpy array\n",
    "# def np2csv(arr):\n",
    "#     csv = io.BytesIO()\n",
    "#     numpy.savetxt(csv, arr, delimiter=',', fmt='%g')\n",
    "#     return csv.getvalue().decode().rstrip()\n",
    "\n",
    "# runtime = boto3.Session(region_name=AWS_REGION).client('sagemaker-runtime')\n",
    "\n",
    "# payload = np2csv(train_set[0][30:31])\n",
    "\n",
    "# response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "#                                    ContentType='text/csv',\n",
    "#                                    Body=payload)\n",
    "# result = json.loads(response['Body'].read().decode())\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Go to Sagemaker console and delete `endpoint` and `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
